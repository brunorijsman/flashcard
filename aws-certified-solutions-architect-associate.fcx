Course: AWS Certified Solutions Architect Associate

Topic: Introduction to the course

SubTopic: Introduction & overview

Q: What are the two types of AWS partners?
A: Technology partners and consulting partners.

Q: What are the three levels of AWS consulting partners?
A: Standard, advanced, and premier.

Q: What are the certs requirements for a standard level AWS consulting partner?
A: 2 associate and 0 professional.

Q: What are the certs requirements for a advanced level AWS consulting partner?
A: 4 associate and 4 professional.

Q: What are the certs requirements for a premier level AWS consulting partner?
A: 20 associate and 8 professional.

Q: What are the four tiers of AWS certification?
A: Practitioner, Associate, Speciality, Professional.

Q: What is the one AWS practitioner certification?
A: Cloud.

Q: What are the three AWS associate certifications?
A: Solutions architect, developer, sysops administrator.

Q: What are the two AWS professional certifications?
A: Solutions architect, devops.

Q: Give three examples of AWS speciality certifications.
A: Security, big data, advanced networking

SubTopic: 10,000 Foot Overview - Part 1

SubSubTopic: Global Infrastructure

Q: What is a region?
A: A geographical area.

Q: What is an availability zone?
A: One or more data centers that form an independent failure domain.

Q: What does AZ stand for?
A: Availability zone.

Q: What is the relation between a region and an availability zone?
A: A region consists of 2 or more availability zones.

Q: How many regions are there?
A: 16 regions in 2017, 6 more planned for 2018.

Q: How many availability zones are there?
A: 44 availability zones in 2017, 17 more planned for 2018.

Q: Name 6 regions in North America
A: US East (Northern Virginia), US East (Ohio), US West (Oregon), US West (Northern California), US West (GovCloud), Canada (Central).

Q: What is the secret region?
A: A region in the US for the intelligence community that can operate workloads up to secret classification.

Q: What is an edge location?
A: AWS endpoints that are used for caching content.

Q: What is the most prevalent caching service?
A: CloudFront, which is the AWS Content Delivery Network (CDN).

Q: How many edge locations are there?
A: Over 96 edge locations as of 2017.

SubTopic: 10,000 Foot Overview - Part 2

SubSubTopic: Compute services

Q: What service does EC2 provide?
A: virtual machines (and bare metal servers).

Q: What does EC2 stand for?
A: Elastic Compute Cloud.

Q: What services provides virtual machines?
A: Elastic Compute Cloud (EC2).

Q: What services provides bare metal servers?
A: Elastic Compute Cloud (EC2).

Q: What service does EC2 container service provide?
A: Docker containers.

Q: What services provides docker containers?
A: EC2 container service.

Q: What service does Elastic Beanstalk provide?
A: Simplified web application deployment.

Q: What service provides simplified web application deployment?
A: Elastic Beanstalk.

Q: What service does Lambda provide?
A: Serverless compute service.

Q: What service provides serverless compute?
A: Lambda.

Q: What service does does LightSail provide?
A: Virtual private server deployment (simplified version of EC2).

Q: What server provides virtual private server deployment?
A: LightSail.

Q: What server provides a simplified version of EC2?
A: LightSail.

Q: What service does Batch provide?
A: Batch computing.

Q: What service provides batch computing?
A: Batch.

Q: Name 6 compute services.
A: EC2, EC2 container service, Elastic Beanstalk, Lambda, LightSail, Batch.

SubSubTopic: Storage services

Q: What service does S3 provide?
A: Object storage.

Q: What service provides object storage?
A: Simple Storage Service (S3).

Q: What does S3 stand for?
A: Simple Storage Service.

Q: What service does EFS provide?
A: Network Attached Storage (NAS).

Q: What service provides Network Attached Storage (NAS)?
A: Elastic File Service (EFS).

Q: What does EFS stand for?
A: Elastic File Service.

Q: What does NAS stand for?
A: Network Attached Storage.

Q: What service does Glacier provide?
A: Data archival (low-cost long-term storage).

Q: What service provides data archival?
A: Glacier.

Q: What service provides low-cost long-term storage?
A: Glacier.

Q: What service does Snowball provide?
A: Large-scale data transfer.

Q: What service offers large-scale data transfer?
A: Snowball.

Q: What services does Storage Gateway provide?
A: Connect an on-site appliance to cloud-based storage.

Q: What service connects on on-site appliance to cloud-based storage?
A: Storage Gateway.

Q: Name 5 storage services.
A: S3, EFS, Glacier, Snowball, Storage Gateway.

SubSubTopic: Database services

Q: What services does RDS provide?
A: Relational databases.

Q: What service provides relational databases?
A: Relational Database Service (RDS).

Q: What does RDS stand for?
A: Relational Database Service.

Q: What service does DynamoDB provide?
A: Non-relational databases.

Q: What service provides non-relational databases?
A: DynamoDB.

Q: What service does Elasticache provide?
A: Database caching.

Q: What service provides database caching?
A: Elasticache.

Q: What services does Redshift provide?
A: Data warehousing and business intelligence.

Q: What service provides data warehousing and business intelligence?
A: Redshift

Q: Name 4 database services.
A: RDS, DynamoDB, Elasticache, Redshift.

SubSubTopic: Migration services

Q: What service does Migration Hub provide?
A: Track application migrations.

Q: What service tracks application migrations?
A: Migration Hub.

Q: What service does Application Discovery Service provide?
A: Collect and present server configuration, usage, and behavior data.

Q: What service collects and presents server configuration, usage, and behavior data.
A: Application Discovery Service.

Q: What service automatically discovers applications and their dependencies?
A: Application Discovery Service.

Q: What service does Database Migration Service provide?
A: Migrate on-premises databases to the cloud.

Q: What service migrates on-premises databases to the cloud?
A: Database Migration Service?

Q: What service does Server Migration Service provide?
A: Migrate on-premises virtual machines and bare metal servers to the cloud.

Q: What service migrates on-premises virtual machines and bare metal servers to the cloud?
A: Server Migration Service.

Q: Name 5 migration services.
A: Migration Hub, Application Discovery Service, Database Migration Service, Server Migration Service, Snowball.

SubSubTopic: Networking and content delivery services

Q: What service does VPC provide?
A: Virtual data centers and advanced virtual networking.

Q: What service provides virtual data centers?
A: Virtual Private Cloud (VPC).

Q: What service provides advanced virtual networking?
A: Virtual Private Cloud (VPC).

Q: What does VPC stand for?
A: Virtual Private Cloud.

Q: What service does CloudFront provide?
A: Content Delivery Network (CDN) and content caching.

Q: What service provides a Content Delivery Network (CDN)?
A: CloudFront.

Q: What service provides a content caching?
A: CloudFront.

Q: What does CDN stand for?
A: Content Delivery Network.

Q: What service does Route53 provide?
A: Domain Name Service (DNS).

Q: What service provides Domain Name Service (DNS)?
A: Route53.

Q: What does DNS stand for?
A: Domain Name Service.

Q: What does Domain Name Service (DNS) do?
A: Domain name to IP address translation.

Q: What service does API gateway provide?
A: Connect web and mobile applications to business logic hosted in the cloud through APIs.

Q: What service connects web and mobile applications to business logic hosted in the cloud through APIs?
A: API Gateway.

Q: What service does Direct Connect provide?
A: Direct connection from on-premises data center to VPC in cloud.

Q: What service provides a direct connection from on-premises data center to VPC in cloud?
A: Direct Connect.

Q: Name 5 networking and content delivery services.
A: VPC, CloudFront, Route53, API Gateway, Direct Connect.

SubSubTopic: Developer tools services

Q: What service does CodeStar provide?
A: Software development project management.

Q: What service provides software development project management?
A: CodeStar.

Q: What service does CodeCommit provide?
A: Asset version control (Git).

Q: What service provides asset version control?
A: CodeCommit.

Q: What service provides Git?
A: CodeCommit.

Q: What service does CodeBuild provide?
A: Compile, test, and package software.

Q: What services compiles, tests, and packages software?
A: CodeBuild.

Q: What service does CodeDeploy provide?
A: Automates application deployment.

Q: What service automates application deployment?
A: CodeDeploy.

Q: What service does CodePipeline provide?
A: Continuous delivery.

Q: What service provides continuous delivery?
A: CodePipeline.

Q: What service does X-Ray provide?
A: Debug and analyze serverless applications.

Q: What service debugs and analyzes serverless applications?
A: X-Ray.

Q: What service does Cloud9 provide?
A: Cloud-based Integrated Development Environment (IDE).

Q: What services provides a cloud-based Integrated Development Environment (IDE).
A: Cloud9.

Q: Name 7 developer tool services.
A: CodeStar, CodeCommit, CodeBuid, CodeDeploy, CodePipeline, X-Ray, Cloud9.

SubTopic: 10,000 Foot Overview - Part 3

SubSubTopic: Management tools services

Q: What service does CloudWatch provide?
A: Monitor resources and applications.

Q: What services monitors resources and applications?
A: CloudWatch.

Q: What service does CloudFormation provide?
A: Deploy AWS resources using scripts.

Q: What service deploys AWS resources using scripts?
A: CloudFormation.

Q: What service embodies "infrastructure as code"?
A: CloudFormation.

Q: What service does CloudTrail provide?
A: Audit trail for AWS API calls.

Q: What service provides an audit trail for AWS API calls?
A: CloudTrail.

Q: What service will tell you what happened when you AWS account gets hacked?
A: CloudTrail.

Q: What service does Config provide?
A: Continuously monitors, records, and evaluates configurations.

Q: What service continuously monitors, records, and evaluates configurations?
A: Config.

Q: What service allows you to restore a previous snapshot of the configuration?
A: Config.

Q: What services does OpsWorks provide?
A: Chef and Puppet.

Q: What service provides Chef and Puppet?
A: OpsWorks.

Q: What service provides automation configuration, deployment, and management of servers?
A: OpsWorks.

Q: What service does Service Catalog provide?
A: Create and manage IT services catalogs.

Q: What service creates and manages IT services catalogs?
A: Service Catalog.

Q: What service does Systems Manager provide?
A: Automate operational actions, such as patches, updates, and configuration changes.

Q: What service automates operational actions, such as patches, updates, and configuration changes?
A: Systems Manager.

Q: What service does Trusted Advisor provide?
A: Provide advise on how to save money, improve performance, improve security, etc.

Q: What service provides advise on how to save money, improve performance, improve security, etc.?
A: Trusted Advisor.

Q: What service does Managed Services provide?
A: Let Amazon manage your AWS infrastructure.

Q: What service lets Amazon manage your AWS infrastructure?
A: Managed Services.

Q: Name 9 management tools services.
A: CloudWatch, CloudFormation, CloudTrail, Config, OpsWorks, Service Catalog, Systems Manager, Trusted Advisor, Managed Services.

SubSubTopic: Media services

Q: What service does Elastic Transcoder provide?
A: File-based media transcoding.

Q: What service does MediaConvert provide?
A: File-based media transcoding.

Q: What services provide file-based media transcoding?
A: Elastic Transcoder and MediaConvert.

Q: What service does MediaLive provide?
A: Broadcast-grade live video processing.

Q: What service provides broadcast-grade live video processing?
A: MediaLive.

Q: What service does MediaPackage provide?
A: Just-in-time video packaging and origination.

Q: What service provides just-in-time video packaging and origination?
A: MediaPackage.

Q: What service does MediaStore provide?
A: Video origination and storage.

Q: What service provides video origination and storage?
A: MediaStore.

Q: What service does MediaTailor provide?
A: Insert targeted advertising into video streams.

Q: What service inserts targeted advertising into video streams.
A: MediaTailor.

Q: Name 6 media services.
A: Elastic Transcode, MediaConvert, MediaLive, MediaPackage, MediaStore, MediaTailor.

SubSubTopic: Machine learning services

Q: What service does SageMaker provide?
A: Deep learning using neural networks.

Q: What service provides deep learning using neural networks?
A: SageMaker.

Q: What service does Comprehend provide?
A: Natural Language Processing (NLP) for sentiment analysis of text.

Q: What service provides Natural Language Processing (NLP) for sentiment analysis of text?
A: Comprehend.

Q: What does NLP stand for?
A: Natural Language Processing.

Q: What service does DeepLens provide?
A: A physical wireless video camera device with built-in image recognition.

Q: What service provides a physical wireless video camera device with built-in image recognition?
A: DeepLens.

Q: What service does Lex provide?
A: Conversational application interfaces using voice and text.

Q: What service provides conversational application interfaces using voice and text?
A: Lex.

Q: What service does Machine Learning provide?
A: Machine learning using traditional (non neural-network) methods.

Q: What service provides machine learning using traditional (non neural-network) methods?
A: Machine Learning.

Q: What service does Polly provide?
A: Text to speech conversion.

Q: What service provides text to speech conversion?
A: Polly.

Q: What service does Rekognition provide?
A: Recognize objects in images and videos.

Q: What service recognizes objects in images and videos?
A: Rekognition.

Q: What service does Translate provide?
A: Text language translation.

Q: What service provides text language translation?
A: Translate.

Q: What service does Transcribe provide?
A: Speech to text conversion.

Q: What service provides speech to text conversion.
A: Transcribe.

Q: Name 9 machine learning services.
A: SageMaker, Comprehend, DeepLens, Lex, Machine Learning, Polly, Rekognition, Translate, Transcribe.

SubSubTopic: Analytics services

Q: What service does Athena provide?
A: Analyze data in S2 using SQL.

Q: What service analyzes data in S2 using SQL?
A: Athena.

Q: What service does Elastic Map Reduce (EMR) provide?
A: Big data analysis.

Q: What service provides big data analysis?
A: Elastic Map Reduce (EMR).

Q: What does EMR stand for?
A: Elastic Map Reduce.

Q: What service does CloudSearch provide?
A: Provide search capability to applications.

Q: What service provides search capability to applications?
A: CloudSearch.

Q: What service does ElasticSearch provide?
A: Operational search and analysis (e.g. logs).

Q: What service provides operational search and analysis (e.g. logs)?
A: ElasticSearch.

Q: What service does Kinesis provide?
A: Real-time collection, processing, and analysis of data streams.

Q: What service provides real-time collection, processing, and analysis of data streams?
A: Kinesis.

Q: What service does Kinesis Video Streams provide?
A: Real-time collection, processing, and analysis of video streams.

Q: What service provides real-time collection, processing, and analysis of video streams?
A: Kinesis Video Streams.

Q: What service does QuickSight provide?
A: Business intelligence.

Q: What service provides business intelligence.
A: QuickSight.

Q: What service does Data Pipeline provide?
A: Data-driven workflows to automate the movement and transformation of data.

Q: What service provides data-driven workflows to automate the movement and transformation of data?
A: Data Pipeline.

Q: What service does Glue provide?
A: Extract, Transform, and Load (ETL) for cleaning up date.

Q: What service provides Extract, Transform, and Load (ETL) for cleaning up date?
A: Glue.

Q: What doe ETL stand for?
A: Extract, Transform, and Load.

Q: Name 9 analytics services.
A: Athena, EMR, CloudSearch, ElasticSearch, Kinesis, Kinesis Video Streams, QuickSight, Data Pipeline, Glue.

SubTopic: 10,000 Foot Overview - Part 4

SubSubTopic: Security, identity, and compliance services

Q: What service does Identity Access Management (IAM) provide?
A: Control user access to services and resources.

Q: What service controls user access to services and resources.
A: Identity Access Management (IAM).

Q: What does IAM stand for?
A: Identity Access Management.

Q: What service does Cognito provide?
A: User authentication and access for mobile applications on internet-connected devices.

Q: What service provides user authentication and access for mobile applications on internet-connected devices?
A: Cognito.

Q: What service does GuardDuty provide?
A: Threat detection for AWS account.

Q: What service provides threat detection for AWS account?
A: GuardDuty.

Q: What service does Inspector provide?
A: Agent in virtual machines for security and compliance assessment.

Q: What service provides an agent in virtual machines for security and compliance assessment?
A: Inspector.

Q: What service does Macie provide?
A: Automatically discover, classify, and protect sensitive data.

Q: What service automatically discovers, classifies, and protects sensitive data?
A: Macie.

Q: What service does Certificate Manager provide?
A: Generate, manage, and deploy security certificates for SSL/TLS.

Q: What service generates, manages, and deploys security certificates for SSL/TLS?
A: Certificate Manager.

Q: What service does CloudHSM provide?
A: Access to a Hardware Security Module (HSM) for storing sensitive data (e.g. private keys).

Q: What service provides access to a Hardware Security Module (HSM) for storing sensitive data (e.g. private keys)?
A: CloudHSM.

Q: What does HSM stand for?
A: Hardware Security Module.

Q: What service does Directory Service Provide
A: Microsoft Active Directory (AD).

Q: What service provides Microsoft Active Directory (AD)?
A: Service Directory.

Q: What does AD stand for?
A: (Microsoft) Active Directory.

Q: What service does Web Application Firewall (WAF) provide?
A: Application layer firewall.

Q: What service provides an application layer firewall?
A: Web Application Firewall (WAF).

Q: What does WAF stand for?
A: Web Application Firewall.

Q: What service does Shield provide?
A: DDoS mitigation.

Q: What service provides DDoS mitigation?
A: Shield.

Q: What is the difference between Shield and Shield Advanced?
A: Shield Advanced provides a 24/7 team and does not charge you for extra resource usage due to a DDoS attack.

Q: What service does Artifact provide?
A: Generate compliance reports.

Q: What service generates compliance reports?
A: Artifact.

Q: Name 12 security, identity, and compliance services.
A: Identity Access Management (IAM), Cognito, GuardDuty, Inspector, Macie, Certificate Manager, CloudHSM, Directory Service, Web Application Framework (WAF), Shield, Artifact.

SubSubTopic: Mobile services

Q: What service does Mobile Hub provide?
A: A collection of tools to build, test, configure and release mobile applications.

Q: What service provides a collection of tools to build, test, configure and release mobile applications?
A: Mobile hub.

Q: What service does Pinpoint provide?
A: Multi-channel user engagement messaging.

Q: What service provides multi-channel user engagement messaging?
A: Pinpoint

Q: What service does AppSync provide?
A: GraphQL and on-line off-line data synchronization.

Q: What service provides GraphQL and on-line off-line data synchronization?
A: AppSync.

Q: What service does DeviceFarm provide?
A: Test mobile apps on real mobile devices.

Q: What service tests mobile apps on real mobile devices?
A: DeviceFarm.

Q: What service does Mobile Analytic provide?
A: Collect and analyze mobile application usage data.

Q: What service collects and analyzes mobile application usage data?
A: Mobile Analytics.

Q: Name 5 mobile services.
A: Mobile Hub, Pinpoint, AppSync, Device Farm, Mobile Analytics.

SubSubTopic: Augmented Reality (AR) and Virtual Reality (VR)

Q: What service does Sumerian provide?
A: Set of tools for creating AR/VR applications.

Q: What service provides a set of tools for creating AR/VR applications?
A: Sumerian.

Q: What does AR/VR stand for?
A: Augmented Reality / Virtual Reality.

Q: Name 1 AR/VR service.
A: Sumerian.

SubSubTopic: Application integration

Q: What service does Step Functions provide?
A: Managing workflows for serverless applications.

Q: What service manages workflows for serverless applications?
A: Step Functions.

Q: What service does Message Queue (MQ) provide?
A: Message queues.

Q: What service offers message queues?
A: Message Queue (MQ).

Q: What does MQ stand for?
A: Message Queue.

Q: What service does Simple Notification Service (SNS) provide?
A: Send messages to subscribing endpoints (e.g email or SMS).

Q: What service sends messages to subscribing endpoints (e.g. email or SMS)?
A: Simple Notification Service (SNS).

Q: What does SNS stand for?
A: Simple Notification Service.

Q: What service does Simple Queueing Service (SQS) provide?
A: Message queues.

Q: What services provide message queues.
A: Old: Simple Queueing Service (SQS). New: Message Queue (MQ).

Q: What service does Simple WorkFlow (SWF) provide?
A: Manage workflows that may include human steps.

Q: What service manages workflows that may include human steps?
A: Simple WorkFlow.

Q: What does SWF stand for?
A: Simple WorkFlow.

Q: Name 5 application integration services.
A: Step Functions, Message Queue (MQ), Simple Notification Service (SNS), Simple Queueing Service (SQS), Simple WorkfFlow (SWF).

SubSubTopic: Customer engagement services.

Q: What service does Connect provide?
A: Contact center (call center) that integrates with CRM.

Q: What service provides a contact center (call center) that integrates with CRM.
A: Connect.

Q: What does CRM stand for?
A: Customer Relationship Management.

Q: What service does Simple Email Service provide?
A: Send large numbers of emails.

Q: What service manages sending large numbers of emails?
A: Simple Email Service.

Q: Name 2 customer engagement services.
A: Connect, Simple Email Service.

SubSubTopic: Business productivity

Q: What service does Alexa for Business provide?
A: Manage Alexa-enabled devices in a business environment.

Q: What service manages Alexa-enabled devices in a business environment?
A: Alexa for Business.

Q: What service does Chime provide?
A: Video conferencing (unified communications). Amazon's version of Google Hangouts.

Q: What service offers video conferencing (unified communications)?
A: Chime.

Q: What is Amazon's version of Google Hangouts?
A: Chime.

Q: What service does WorkDocs provide?
A: File storage and sharing (Amazon's version of Dropbox).

Q: What service provides file storage and sharing?
A: WorkDocs.

Q: What service is Amazon's version of Dropbox?
A: WorkDocs.

Q: What service does WorkMail provide?
A: Email and calendar. Amazon's version of Gmail.

Q: What service provides email and calendar?
A: WorkMail.

Q: What service is Amazon's version of Gmail?
A: WorkMail.

Q: Name 4 business productivity services.
A: Alexa for Business, Chime, WorkDocs, WorkMail.

SubSubTopic: Desktop and app streaming

Q: What service does Workspaces provide?
A: Virtual Desktop Infrastructure (VDI).

Q: What service provides Virtual Desktop Infrastructure (VDI)?
A: Workspaces.

Q: What does VDI stand for?
A: Virtual Desktop Infrastructure.

Q: What service does AppStream 2.0 provide?
A: Host legacy applications in cloud and stream display to browser.

Q: What services hosts legacy applications in cloud and streams display to browser?
A: AppStream 2.0

Q: What is the difference between Workspaces and AppStream 2.0?
A: Workspaces stream an entire desktop environment, AppStream 2.0 streams individual applications.

Q: Name 2 desktop and app streaming services.
A: Workspaces, AppStream 2.0.

SubSubTopic: Internet of Things (IoT)

Q: What service does IoT Core provide?
A: Platform for building IoT applications.

Q: What service is a platform for building IoT applications?
A: IoT Core.

Q: What service does IoT Device Management provide?
A: Manage IoT devices.

Q: What service manages IoT devices?
A: IoT Device Management.

Q: What service does Greengrass provide?
A: Edge computing for IoT: run local compute, messaging, data caching, sync, and ML inference capabilities for connected devices in a secure way).

Q: What service provides edge computing for IoT: run local compute, messaging, data caching, sync, and ML inference capabilities for connected devices in a secure way)?
A: Greengrass.

Q: What service does IoT analytics provide?
A: Analytics for IoT data.

Q: What service provides analytics for IoT data?
A: IoT Analytics.

Q: What service does FreeRTOS provide?
A: Operating system for microcontrollers.

Q: What service provides an operating system for microcontrollers?
A: FreeRTOS.

Q: Name 5 IoT services.
A: IoT Core, IoT Device Management, Greengrass, IoT Analytics, FreeRTOS.

SubSubTopic: Game development services

Q: What service does GameLift provide?
A: Gameserver hosting.

Q: What service provides gameserver hosting?
A: GameLift.

Q: Name 1 game development service.
A: GameLift.

Topic: Identity Access Management (IAM)

SubTopic: IAM 101

Q: What does IAM stand for?
A: Identity and Access Management.

Q: What is identity federation?
A: Integration with Active Directory, Facebook, LinkedIn, etc. for authentication.

Q: What does PCI DSS stand for?
A: Payment Card Industry Data Security Standard.

Q: What is an IAM user?
A: A person (or service) that interacts with AWS.

Q: What is an IAM group?
A: A collection of users.

Q: What is an IAM role?
A: A set of permissions that can permanently or temporarily be assigned to users, applications, and services.

Q: What is an IAM policy?
A: A document that defines one or more permissions.

Q: What language is used to define policy document?
A: JSON.

Q: What is the root account?
A: The default account created when the AWS account was setup.

Q: What are the default permissions for a user?
A: Full administrator access for root. No permissions for all other users.

SubTopic: IAM Lab

Q: Name two considerations for choosing a region.
A: Proximity, available services.

Q: Is IAM global or per-region?
A: Global.

Q: What is the IAM users sign-in link?
A: https://xxx.signin.aws.amazon.com/console where xxx is the account ID or alias.

Q: What are the 5 recommended security practices for a new account?
A: Delete root access keys, enable MFA, create individual IAM users, use groups to assign permissions, apply an IAM password policy.

Q: What does MFA stand for?
A: Multi Factor Authentication.

Q: What are the two types of MFA devices?
A: Physical and virtual.

Q: What are the two types of access for an IAM user?
A: Console and programmatic.

Q: How is console access authenticated?
A: User name and password and optional MFA.

Q: How is programmatic access authenticated?
A: Access key and access secret.

Q: What are the access key id and secret used for?
A: Programmatic access: API, SDK, command-line, etc. Not for the console.

Q: How can you recover your access key secret?
A: You cannot. You must generate a new access key.

Q: What is the difference between policy AdministratorAccess and policy SystemAdministrator.
A: AdministratorAccess allows everything. SystemAdministrator allows almost everything (everything needed for development).

Lab: Identity and Access Management (IAM) 101
Step: Log into AWS console.
Step: Select region.
Step: Select IAM service.
Step: Customize the IAM users sign-in link.
Step: Create an administrator group with full access.
Step: Create two users (john and mary) with programmatic and console access and assign them to the administrator group.
Step: Create an HR group with S3 read-only access.
Step: Move john to the HR group.
Step: Attach glacier read-only access directly to john.
Step: De-active john's access key and create a new one.
Step: Change the password policy.
Step: Create a role that allows EC2 instances to write to S3.
Step: Cleanup: delete the created users, groups, and roles.

SubTopic: Create a Billing Alarm Lab

Lab: Create a Billing Alarm
Step: Log into AWS console as root.
Step: Open billing dashboard.
Step: Enable monitoring of estimated charges.
Step: Enable billing alerts.
Step: Create a billing alarm for estimated charges more than $10.

Topic: AWS object storage and CDN - S3, Glacier, and CloudFront

SubTopic: S3 101

Q: What does S3 stand for?
A: Simple Storage Service.

Q: What service does S3 provide?
A: Object store.

Q: What service would you use for block storage?
A: Elastic Block Store (EBS).

Q: How does S3 achieve reliability?
A: By replicating the data across multiple devices and AZs.

Q: Why can you not use S3 as a virtual disk?
A: You need block store for that, and S3 is object store.

Q: What does object store really mean?
A: You can upload entire files.

Q: What is the minimum size of an S3 object?
A: Zero bytes.

Q: What is the maximum size of a single S3 object?
A: 5 TB.

Q: What is the maximum total size of all S3 objects?
A: Unlimited.

Q: Into what are S3 objects stored?
A: Into buckets.

Q: What is a bucket?
A: S3 objects are stored in buckets, which are similar to top-level folders.

Q: What is the scope of a bucket name?
A: Global, i.e. it must be globally unique.

Q: What are the naming rules for buckets?
A: Globally unique (universal namespace), must follow DNS naming rules.

Q: What does the URL for a bucket look like?
A: https://s3-<region-name>.amazonaws.com/<bucket-name> 

Q: How do you know uploading a file to S3 was succesful?
A: HTTP response code 200.

Q: What is the S3 data consistency model for PUT of new object?
A: Read after write consistency.

Q: What is the S3 data consistency model for overwrite PUT of existing object?
A: Eventual consistency.

Q: What is the S3 data consistency model for DELETE object?
A: Eventual consistency.

Q: What is the consistency model for S3 objects?
A: Read afer write consistency for PUT new, eventual consistency for PUT modify and DELETE.

Q: What does read after write consistency mean?
A: After writing a change, reading always immediately returns the new state, never the old state.

Q: What does eventually consistency mean?
A: After writing a change, reading may for some time return the old state, but eventually returns the new state.

Q: What is the underlying cause for eventual consistency?
A: It takes time to propagate a change across a devices where the data is replicated.

Q: What are the components of an S3 object?
A: Key, value, version ID, metadata, sub-resources.

Q: What is the S3 object key?
A: The name.

Q: What is the S3 object value?
A: The contents, which is a sequence of bytes.

Q: What is the S3 object value?
A: The contents.

Q: What is the S3 object metadata?
A: Tags, which are key-value pairs.

Q: What are S3 object sub-resources?
A: Access Control Lists (ACLs), torrent.

Q: What does ACL stand for?
A: Access Control List.

Q: For which reliability is the S3 platform built?
A: The target reliability is 99.99% (4 nines).

Q: What availability does AWS guarantee for standard S3?
A: The Service Level Agreement (SLA) guarantees 99.9% (3 nines) reliability.

Q: What durability does AWS guarantee for standard S3?
A: 99.999999999% (11 nines).

Q: What is the difference between availability and durability?
A: Availability is probability of losing access to a file temporarily, durability is probability of losing the file forever.

Q: What is tiered storage?
A: There are multiple storage classes (aka storage tiers) with different cost, retrieval latency, and reliability characteristics.

Q: What is lifecycle management?
A: Automatically move a file from one tier to another, based on age of the file etc.

Q: What is versioning?
A: After changes, keep multiple versions of a file, plus the ability to restore older versions.

Q: Name 2 mechanisms for securing S3 data.
A: Access Control Lists (ACLs) and bucket policies.

Q: Name 4 S3 storage tiers / classes.
A: Standard, Standard-IA (Infrequenty Accessed), One-Zone-IA, Reduced Redundancy.

Q: When would you use the Reduced Redundancy Storage class (RRS)?
A: Never, it is deprecated. Use One-Zone-IA instead. (It was originally intended for non-critical reproducable data).

Q: What does RRS stand for?
A: Reduced Redundancy Storage.

Q: What is the target availability of the S3 standard storage tier?
A: 99.99% (4 nines).

Q: What is the guaranteed availability of the S3 standard storage tier?
A: 99.9% (3 nines)

Q: What is the durability of the S3 standard storage tier?
A: 99.999999999% (11 nines).

Q: What is the redundancy of the S3 standard storage tier?
A: Replicated across at least 3 availability zones.

Q: The loss of how many data centers can the S3 standard storage tier sustain?
A: The lost of at least 2 data centers (AZs).

Q: What is the retrieval latency of the S3 standard storage tier?
A: Milliseconds.

Q: Is there a retrieval fee for the S3 standard storage tier?
A: No, retrieval is free.

Q: What is the target availability of the S3 IA storage tier?
A: 99.9% (3 nines).

Q: What is the guaranteed availability of the S3 IA storage tier?
A: 99% (2 nines).

Q: What is the durability of the S3 IA storage tier?
A: 99.999999999% (11 nines).

Q: What is the redundancy of the S3 IA storage tier?
A: Replicated across at least 3 availability zones.

Q: What is the retrieval latency of the S3 IA storage tier?
A: Milliseconds.

Q: Is there a retrieval fee for the S3 IA storage tier?
A: Yes, charged per GB retrieved.

Q: What does IA stand for?
A: Infrequently Accessed.

Q: What is the main difference between the S3 standard and IA storage tiers?
A: Lower capacity cost, but adds retrieval cost.

Q: What is the target availability of the S3 one-zone IA storage tier?
A: 99.5%.

Q: What is the guaranteed availability of the S3 one-zone IA storage tier?
A: 99% (two nines).

Q: What is the durability of the S3 one-zone IA storage tier?
A: 99.999999999% (11 nines).

Q: What is the redundancy of the S3 one-zone IA storage tier?
A: No replication across zones, only one zone.

Q: What is the retrieval latency of the S3 one-zone IA storage tier?
A: Milliseconds.

Q: Is there a retrieval fee for the S3 one-zone IA storage tier?
A: Yes, charged per GB retrieved.

Q: What is the main difference between the S3 IA and one-zone IA storage tiers?
A: Lower capacity cost, but no replication across zones.

Q: What is the target availability of Glacier?
A: Not specified.

Q: What is the guaranteed availability of Glacier?
A: Not specified.

Q: What is the durability of the Glacier?
A: 99.999999999% (11 nines).

Q: What is the redundancy of the Glacier?
A: Replicated across at least 3 availability zones.

Q: What is the retrieval latency of the Glacier?
A: 3-5 hours for standard, minutes for expedited.

Q: Is there a retrieval fee for the Glacier?
A: Yes, charged per GB retrieved.

Q: What is the difference between the S3 IA and Glacier?
A: Lower capacity cost, but much longer retrieval latency (hours vs milliseconds).

Q: What are the three variations of Glacier?
A: Standard, expedited, bulk.

Q: What storage would you choose if you simply want the lowest cost possible and you don't care about retrieval latency?
A: Glacier.

Q: How are you charged for S3 storage?
A: Storage capacity, number of requests, storage management (e.g. tags), data transfer (retrieval, replication), transfer acceleration.

Q: What is S3 transfer acceleration?
A: Users transfer data to and from edge locations, and transfer to the region is accelerated over the AWS backbone. It is faster.

SubTopic: Lab: Create an S3 Bucket

Lab: Create an S3 bucket
Step: Log into the AWS console.
Step: Choose a region.
Step: Go to the S3 console.
Step: Create a bucket.
Step: Look at versioning properties for the bucket.
Step: Look at logging properties for the bucket.
Step: Look at static website hosting properties for the bucket.
Step: Look at tags properties for the bucket.
Step: Look at transfer acceleration properties for the bucket.
Step: Look at events properties for the bucket.
Step: Look at requester pays properties for the bucket.
Step: Look at the permissions for the bucket.
Step: Look at the policy generator for the bucket.
Step: Look at lifecycle management for the bucket.
Step: Look at replication management for the bucket.
Step: Look at analytics management for the bucket.
Step: Look at metrics management for the bucket.
Step: Look at inventory management for the bucket.
Step: Set tag department to value engineering, and tag environment to value development for the bucket.
Step: Give another AWS account read-write access to the bucket.
Step: Make the bucket publicly readable.
Step: Upload two files to the bucket.
Step: Monitor the progress of the upload.
Step: Try to download the contents of an object using its URL and get an access denied error.
Step: Make the object public.
Step: Again, try to download the contents of the object using its URL, which succeeds this time.
Step: Look at the permissions for an object.
Step: Look at the storage class properties for the object.
Step: Look at the encryption properties for the object.
Step: Look at the Metadata properties for the object.
Step: Look at the Tags properties for the object.
Step: Clean up: delete objects and bucket.

Q: What is the default permission for a bucket?
A: Only the owner (the creator) has full access, and everyone else has no access.

Q: What is the default permission for an object?
A: Only the owner (the creator) has full access, and everyone else has no access.

Q: Does an object inherit the tags from the bucket?
A: No.

Q: Name 2 ways to control access to a bucket.
A: Access Control Lists (ACLs) and Bucket Policy.

Q: What does ARN stand for?
A: Amazon Resource Name.

Q: What is the scope of bucket names?
A: The bucket name must be globally unique.

Q: What is the scope of the bucket contents?
A: The contents of a bucket local to a specific region.

Q: What indicates success for uploading a file to an S3 bucket?
A: HTTP status code 200.

Q: Name the 4 tiers (classes) of S3 storage?
A: Standard, Infrequent Access (IA), One Zone IA, Reduced Redundancy.

Q: Name 2 locations where encryption can be performed.
A: Client-side encryption and server-side encryption.

Q: Name 3 types of server-side encryption.
A: SSE-S3, SSE-KMS, SSE-C.

Q: What does SSE-S3 stand for?
A: Server-Side Encryption with amazon S3 managed keys.

Q: What does SSE-KMS stand for?
A: Server-Side Encryption with amazon Key Management Service managed keys.

Q: What is an additional benefit of SSE-KMS?
A: It provides an audit trail of when your keys were used and by whom.

Q: What does SSE-C stand for?
A: Server-Side Encryption with Customer managed keys.

SubTopic: Lab: S3 Version Control

Lab: S3 Version Control
Step: Log into the AWS console.
Step: Choose a region.
Step: Go to the S3 console.
Step: Create a bucket.
Step: Enable versioning.
Step: Upload a small text file to the bucket; make it publicly readable.
Step: Make a change in the text file, and upload the changed version.
Step: In the S3 console, click on the object, and use the dropdown menu to look at the two versions.
Step: Delete the latest version of the object using the same dropdown menu.
Step: Delete the object itself (not a version of it).
Step: Enable displaying all versions of the object.
Step: Observe the delete marker version.
Step: Restore the object by deleting the delete marker.
Step: Make a change in the text file, and upload the changed version.
Step: Observe the total size of all versions (you will be charged for the total)
Step: Clean up: delete objects and bucket.

Q: How do you disable versioning on a bucket?
A: You cannot. Once versioning is enabled, you can only suspend it.

Q: What is the main disadvantage of versioning?
A: You use and pay for a lot more storage capacity because all versions are kept as a whole file.

Q: What happens if an object is deleted (if versioning is enabled)?
A: A delete marker is added to the version list.

Q: How can you restore a deleted object (if versioning is enabled)?
A: Show all versions and delete the delete marker.

Q: What is MFA delete?
A: Require Multi Factor Authentication (MFS) for permanently deleting an object and changing the versioning state of a bucket.

SubTopic: Lab: Cross-region Replication

Q: What is the requirement for cross-region replication?
A: Versioning must be anabled on both the source and destination bucket.

Q: What feature would you typically enable if you use cross-region replication for backup?
A: Set the storage class of the replicated objects to Infrequently Accessed (IA), which is cheaper.

Q: When you enable cross-region replication, are existing object replicated?
A: No, only changes from that point onwards are replicated.

Q: What are the options for installing the AWS command line tools on Mac?
A: A bundled installer or pip instal.

Q: What is the first step after installing the AWS command line tools?
A: aws configure.

Q: What do you need to run the command line "aws configure"?
A: The access key id and the access key secret.

Q: What can you do if you want to use the command line tools but don't have the access key secret?
A: Create a new user for the command line tools.

Q: What is the command line to show all buckets?
A: aws s3 ls

Q: What is the command line to copy all objects in one bucket to another bucket?
A: aws s3 cp --recursive s3://source-bucket-name s3://dest-bucket-name

Q: If cross-region replication is enabled, and you delete an object, what happens?
A: The delete marker is replicated. 

Q: If cross-region replication is enabled, and you delete a delete marker, what happens?
A: This change is NOT replicated, the delete marker is still there in the destination bucket.

Q: If cross-region replication is enabled, and you delete a version, what happens?
A: This change is NOT replicated, the version is still there in the destination bucket.

Q: If cross-regione replication is enabled, what happens with the permissions?
A: The permissions are also replicated.

Q: Does cross-region replication allow you to replicate from one bucket to another bucket in the same region?
A: No, the regions must be different.

Q: Is daisy chaining cross-region replication (B1 -> B2 -> B3) allowed?
A: No, not at this time (this may change)

Q: Is cross-region replication to multiple destination buckets (B1 -> B2 and B1 -> B3) allowed?
A: No, not at this time (this may change)

Q: Can you do cross-region replication to a bucket in another account?
A: Yes.

Q: Does cross-region replication require replicating all files in a bucket?
A: No, you can replicate a subset of files with a given prefix (i.e. in a given folder).

Q: What is a main application for cross-region replication?
A: Backup and disaster recovery.

Q: What does RPO stand for?
A: Recovery Point Objective.

Q: Is cross-region replication synchronous or asynchronous?
A: Asynchronous; the replication happens can take some time after the change, depending on object size and network conditions.

Q: How can you be sure that objects are actually replicated in a timely manner to meet the RPO?
A: Use cross-region replication monitor (CRR monitor).

Lab: S3 Version Control
Step: Log into the AWS console.
Step: Go to the S3 console.
Step: Create a bucket B1 in one region and enable versioning.
Step: Create another bucket B2 in another region and do not enable versioning.
Step: Upload two files F1 and F2 to bucket B1.
Step: Upload a change to file F1 and upload it to bucket B1.
Step: Observe the files in bucket B1: file F1 (2 versions) and file F2 (1 version).
Step: Enable cross-region replication from bucket B1 to bucket B2. Observe that versioning must be enabled on bucket B2.
Step: Change the cross-region replication to change the storage class in B2 to Infrequently Accessed (IA).
Step: Observe that the existing objects in bucket B1 have not been replicated to bucket B2.
Step: Install the AWS command command line tools.
Step: Do the initial configuration of the AWS command line tools (create a new user if needed).
Step: Use the AWS command line to list all files in bucket B1 (to make sure it works).
Step: Use the AWS command line to copy all existing objects in bucket B1 to bucket B2.
Step: In source bucket B1, delete object F1.
Step: Observe that a delete marker for object F1 has been placed in source bucket B1.
Step: Observe that a delete marker for object F1 has been replicated to destination bucket B2.
Step: In source bucket B1, delete the delete marker for object F1.
Step: Observe that a delete marker for object F1 has been deleted in source bucket B1, and the object is restored.
Step: Observe that this change has NOT been replicated to bucket B2; the delete marker is still there.
Step: Manually delete the delete marker in bucket B2.
Step: Make a change to file F1, and upload the change to bucket B1.
Step: Observe that file F1 now has 3 versions in bucket B1.
Step: Observe that the change has been replicated to bucket B2, and that bucket B2 now also has the newest version of file F1.
Step: In bucket B1, delete version 3 of object F1.
Step: Observe that in bucket B1, only versions 1 and 2 remain.
Step: Observe that this change has NOT been replicated to bucket B2; there are still 3 versions there.
Step: Clean up: delete objects and buckets in both regions.

SubTopic: Lab: Lifecyle Management, S3-IA, and Glacier

Lab: Lifecyle Management, S3-IA, and Glacier
Step: Log into the AWS console.
Step: Go to the S3 console.
Step: Make sure you are in a region where Glacier is available.
Step: Create a bucket.
Step: Initiate the creation of a lifecyle rule (details in next steps)
Step: Configure the lifecyle rule to apply to both current and previous versions.
Step: Configure the lifecyle rule to transition the current version to Standard-IA after 50 days.
Step: Configure the lifecyle rule to transition the current version to Glacier after 100 days.
Step: Configure the lifecyle rule to transition previous versions to Standard-IA after 30 days.
Step: Configure the lifecyle rule to transition previous versions to Glacier after 60 days.
Step: Configure the lifecyle rule to expire the current version after 465 days.
Step: Configure the lifecyle rule to expire previous versions after 425 days.
Step: Note that we cannot observe the lifecycle rule in action because it would require us to wait 30 days.
Step: Clean up: delete the bucket.

Q: What does lifecycle management do?
A: Move old files to a lower storage tier or delete them, based on a defined policy.

Q: What are the possible destination lower storage tiers for lifecycle management?
A: S3 Standard-IA, S3 One-Zone-IA, Glacier, retire.

Q: What does expiring an object mean?
A: Permanently deleting it.

Q: Is Glacier available in every region?
A: No, there are a few regions where it is not available.

Q: Is versioning compatible with life cycle management?
A: Yes, versioning is allowed but not required: versioning can be enabled or disabled.

Q: Is versioning compatible with MFA delete?
A: No, life cycle management cannot be enabled on buckets with MFA delete.

Q: Can lifecycle management manage a subset of objects in a folder?
A: Yes, you can filter objects on prefix (folder) and/or tags.

Q: Which versions does lifecycle management apply to?
A: You can choose to apply it to current version and/or previous versions.

Q: What is the minimum size of an object to be subject to lifecycle management?
A: 128 KB.

Q: In lifecycle management, what is the minimum time interval for the transition to Standard-IA or One-Zone-IA?
A: 30 days after object creation.

Q: In lifecycle management, what is the minimum time interval for the transition to Glacier?
A: 30 days after transition to Standard-IA or One-Zone-IA.

Q: In lifecycle management, what is the minimum time interval for the expiry from Standard-IA or One-Zone-IA?
A: 30 days (if less, you are charged for 30 days of storage)

Q: In lifecycle management, what is the minimum time interval for the expiry from Glacier?
A: 90 days (if less, you are charged for 90 days of storage)

Q: What is the main use case for life cycle management?
A: Reduce storage cost by moving old files to a lower storage tier and/or deleting them.

SubTopic: CloudFront CDN Overview

Q: What does CDN stand for?
A: Content Delivery Network.

Q: What service does CloudFront provide?
A: Faster access to content by caching content at edge locations.

Q: What is an Edge Location?
A: A location where content is cached.

Q: What is the relation between an edge location and a region or AZ?
A: They are unrelated. There are more edge locations than regions, and they are located at difference places.

Q: What is a CloudFront origin?
A: The original location of delivered content.

Q: What are possible CloudFront origins within AWS?
A: S3 bucket, EC2 instance, Elastic Load Balancer, Route53.

Q: Does CloudFront support third-party origins (non-AWS origins)?
A: Yes.

Q: What is a CloudFront distribution?
A: The name given to a CDN, wich consists of a collection of Edge Locations.

Q: Can CloudFront deliver dynamic, interactive, and streaming websites?
A: Yes.

Q: Name two types of CloudFront distributions?
A: Web distribution and RTMP distribution.

Q: What does RTMP stand for?
A: Real Time Messaging Protocol.

Q: When would you use a CloudFront RTMP distribution.
A: For media streaming using Adobe Flash.

Q: Are CloudFront edge locations read-only?
A: No, you can also PUT or POST to edge locations.

Q: How long does CloudFront cache content at an edge location?
A: For the configured Time To Live (TTL).

Q: Can you manually clear an object from a CloudFront edge location cache?
A: Yes, you can, but you will be charged for it.

Q: Why would you manually clear an object from a CloudFront edge location cache?
A: To make sure that end-users see the most recent version of the object.

SubTopic: Lab: Create a CloudFront CDN

Lab: Create a CloudFront CDN
Step: Log into the AWS console.
Step: Create an S3 bucket in a very remote region (e.g. Syndney).
Step: Upload a very large image into the remote bucket. Make it publicly readable.
Step: Open the image (using force refresh on the browser). Observe it takes a long time to download.
Step: Initiate creation of a CloudFront distribution (details follow in next steps).
Step: Choose the S3 bucket as the origin.
Step: Enable Restrict Bucket Access. Create a new origin access identity. Update the bucket policy to grant read access.
Step: Redirect HTTP to HTTPS.
Step: Monitor the distribution to observe when the Status reaches Deployed.
Step: Observe that retrieving the image through S3 still is slow (remember to force the browser to hard refresh)
Step: Construct the URL to retrieve the image using the CDN
Step: Retrieve the image using the CDN. Observe that the first retrieval is still slow.
Step: Retrieve the image using the CDN again. Observe that the first retrieval is fast, even if you force a hard refresh.
Step: Remove read access for all users for the image in the bucket.
Step: Observe that retrieving the image using the URL for the S3 bucket returns an error.
Step: Observe that retrieving the image using the URL for the CloudFront distribution succeeds.
Step: Observe that retrieving the image using the URL for the CloudFront redirects HTTP to HTTPS.
Step: Clean up: delete the CloudFront distribution.
Step: Clean up: delete the S3 bucket.

Q: What type of CloudFront distribution would you use for static web content (e.g. HTML, CSS, client-side JavaScript, graphics)?
A: Web distribution.

Q: What type of CloudFront distribution would you use for dynamic web content (e.g. PHP)?
A: Web distribution.

Q: What type of CloudFront distribution would you use for distributing media files using HTTP or HTTPS?
A: Web distribution.

Q: What type of CloudFront distribution would you use for adding, updating, or deleting objects (PUT, POST, PATCH, DELETE, ...)?
A: Web distribution.

Q: What type of CloudFront distribution would you use for posting web forms?
A: Web distribution.

Q: What type of CloudFront distribution would you use for live streams?
A: Web distribution.

Q: What type of CloudFront distribution would you use for RTMP content?
A: RTMP distribution.

Q: What type of CloudFront distribution would you use for Adobe Flash content?
A: RTMP distribution.

Q: What is the "Origin Domain Name" for a CloudFront distribution?
A: An AWS resource name (S3 bucket, EC2 instance, Elastic Load Balancer, Route53) or non-AWS domain name.

Q: What is the "Origin Path" for a CloudFront distribution?
A: CloudFront appends this to the Origin Domain Name when forwarding the request to the origin server. Typically the name of a folder in an S3 bucket.

Q: Should you include slashes (/) in "Origin Path" for a CloudFront distribution?
A: Include the leading slash but not the trailing slash.

Q: What is the "Origin ID" for a CloudFront distribution?
A: A descriptive name for the origin within the distribution.

Q: What is "Restrict Bucket Access" for a CloudFront distribution?
A: Is set to "Yes, restrict" it forces users to get the content through CloudFront and they cannot get it directly from the S3 bucket.

Q: "Restrict Bucket Access" in CloudFront is typically used in combination with what other feature?
A: URL signing and cookie signing.

Q: "Restrict Bucket Access" in CloudFront requires what security feature?
A: An origin access identity with the proper permissions to access the origin.

Q: What is the most common mistake with enabling "Restrict Bucket Access"?
A: Forget setting "Yes, Update Bucket Policy" for "Grant Read Permissions on Bucket".

Q: What is "Path Pattern" in a CloudFront distribution behavior?
A: Matches on a file pattern (e.g. only jpeg extensions) to route a request to particular origin.

Q: What are the possible values for "Viewer Protocol Policy" in a CloudFront distribution behavior?
A: HTTP and HTTPS, Redirect HTTP to HTTPS, HTTPS Only.

Q: What do you need to do if you want to allow users to upload content?
A: Incude PUT, POST, PATCH, DELETE in "Allowed HTTP Methods" in a CloudFront distribution behavior.

Q: Name 2 options for controlling the TTL of cached objects.
A: Using the cache headers provided by the origin server, or customized values specified in the CloudFront configuration.

Q: What is the advantage of using a long TTL in CloudFront?
A: Fewer trips to the origin server.

Q: What is the disadvantage of using a long TTL in CloudFront?
A: It takes longer for end-users to see an updated version of the content.

Q: What is an alternative to flushing the cache when you want users to see a new version of content?
A: Encode a version into the content name (into the URL).

Q: What is "Restrict Viewer Access" in a CloudFront distribution behavior?
A: It enables URL signing and Cookie signing.

Q: What is "Restrict Viewer Access" typically used for in CloudFront?
A: To make sure that only authorized (paying) customers can access content.

Q: How would you make sure that only authorized (paying) customers can access content?
A: Enable "Restrict Viewer Access" in CloudFront to enable URL signing and cookie signing.

Q: What is "Price Class" in a CloudFront distribution distribution settings?
A: Determines the set of edge locations that will cache the content (US, Canada, Europe only, or also Asia, or all locations).

Q: What does WAF stand for?
A: Web Application Firewall.

Q: What is WAF used for in CloudFront?
A: To prevent application-layer attachs on the web server.

Q: What does the default URL for a CloudFront distribution look like?
A: xxx.cloudfront.net where xxx is a random string.

Q: What is "Alternate Domain Names" in a CloudFront distribution distribution settings?
A: Allows you to use your own domain name instead of the default CloudFront domain name.

Q: How does using your own domain name affect HTTPS?
A: You must provide your own certificate and store it in Amazon Certificate Manager (ACM).

Q: Does CloudFront support HTTP2?
A: Yes, it is enabled by default but it can be disabled.

Q: Does CloudFront support IPv6?
A: Yes, it is enabled by default but it can be disabled.

Q: How long does it take to create or delete a CloudFront distribution?
A: A long time, up to 15 minutes.

Q: Why does it take so long to create or delete a CloudFront distribution?
A: Because many edge locations need to be updated.

Q: How is the distribution domain name related to the distribution ID?
A: They are unrelated. They both contain random strings, but they are different random strings.

Q: Is it possible to have multiple origin servers for a single CloudFront distribution?
A: Yes.

Q: Is it possible to have multiple behaviors for a single CloudFront distribution?
A: Yes.

Q: What would you do if you want your CloudFront content only to be available in certain countries?
A: Enable Geo Restrictions.

Q: What are the two methods for configuring Geo Restrictions?
A: Either a white list or a black list of countries (but not both).

Q: What is a CloudFront invalidation?
A: A request to remove cached objects from edge locations.

Q: How would you remove CloudFront cached objects from edge locations?
A: Create an invalidation. Note there is a charge.

Q: What would you do if you create an updated version of content, and you want all users to see the new content immediately?
A: Create a CloudFront invalidation to flush cached content from the edge locations. Note there is a charge.

Q: What would you do if you accidentally put some confidential information on the web, and you want to remove it immediately?
A: Create a CloudFront invalidation to flush cached content from the edge locations. Note there is a charge.

SubTopic: S3 Security and Encryption

Q: What are the default permissions for an S3 bucket?
A: Private: only the owner (the creator) has full access, and everyone else has no access.

Q: Name 2 mechanisms for securing S3 buckets:
A: Bucket policies and Access Control Lists (ACLs).

Q: Name 1 mechanism for securing S3 buckets:
A: Access Control Lists (ACLs).

Q: What can Policies be attached to directly in S3?
A: Only buckets.

Q: What can Access Control Lists be attached to in S3?
A: Both buckets and objects.

Q: Whose access can be controlled by an S3 ACL?
A: The owner account, other accounts, public access, and (for buckets) the S3 log delivery group.

Q: What types of access are controlled by a an S3 bucket ACL?
A: List object, write objects, read bucket permissions, write bucket permissions.

Q: What types of access are controlled by a an S3 object ACL?
A: Read object, read object permissions, write object permissions.

Q: Where is the permission to write to an object controlled?
A: In the ACL of the bucket (not the ACL of the object).

Q: What does ACL stand for?
A: Access Control List.

Q: Describe S3 logging.
A: If Server Access Logging is enabled on a bucket, all requests for the bucket are written to a log file in S3 for auditing purposes.

Q: What does S3 offer for in-transit encryption?
A: HTTPS, which relies on SSL/TLS

Q: What are the two locations where at-rest encryptions can be performed?
A: Client-side encyrption and Server-Side Encryption (SSE)

Q: What 3 forms of Server Side Encryption (SEE) does S3 support?
A: S3 managed keys (SSE-S3), S3 Key Management Service (KMS) managed keys (SSE-KMS), Customer managed keys (SSE-C).

Q: What encryption algorithm does AWS SSE use?
A: Advanced Encryption Standard AES-256.

Q: How are the keys managed for SSE-S3?
A: Each object is encrypted with a unique key chosesn by AWS. The key is encrypted with a master key, which is rotated regularly.

Q: How are the keys managed for SSE-KMS?
A: The customer choses the keys and the key policies (e.g. rotation) and stores them securely in AWS using the Key Management Service (KMS).

Q: How are the keys managed for SSE-C?
A: The customer must provide the key in each request (only requests over HTTPS are allowed).

Q: Does AWS store the keys when using SSE-C?
A: No, Amamzon does not store the keys. For validation purposes it only stores a salt (a hash of the key) from which the key cannot be reconstructed.

SubTopic: Storage Gateway

Q: What service does Storage Gateway provide?
A: An on-site virtual appliance that connects on-site storage with AWS storage.

Q: What AWS service provides an on-site virtual appliance that connects on-site storage with AWS storage?
A: Storage Gateway.

Q: Which host platforms does Storage Gateway support?
A: VMware ESXi, Microsoft Hyper-V (2008 R2 and 2012), Amazon EC2.

Q: Name 4 types of Storage Gateway?
A: File gateway, Cached volumes gateway, Stored volumes gateway, Tape gateway (aka VTS gateway)

Q: What does VTS stand for?
A: Virtual Tape System.

Q: What does the "Cloud Tiering" use case for Storage Gateway mean?
A: Move infrequently used data to multi-tier storage in the cloud to save cost.

Q: What does the "Hybrid Cloud Backup" use case for Storage Gateway mean?
A: Store active data in on-prem storage (e.g. NAS or SAN) and automatically make backups which are stored in the cloud.

Q: What does the "Hybrid Cloud Workload" use case for Storage Gateway mean?
A: The legacy application can continue to access files using NAS or SAN, while the cloud-native application can use APIs to access S3 or EC2 EBS.

Q: What service does the File gateway provide?
A: The File Gateway offers NFS service to local clients, and maps NFS file shares to S3 objects in the AWS cloud.

Q: Where does the File gateway store the files?
A: The master copy is stored in S3, and there is a cache on the File gateway for efficiency.

Q: Does the File Gateway transparrently preserve the NFS permissions and attributes?
A: Yes, these are stored in S3 metadata.

Q: What storage protocol does the File gateway support?
A: Network File System (NFS).

Q: How does the File gateway store files in the cloud?
A: As S3 objects.

Q: How does the File gateway integrate with S3?
A: S3 features such as lifecycle management, cross-region replication, etc. are available for the S3 objects that represent files.

Q: How does the File gateway integrate with other AWS services?
A: Other services, such as Elastic Map Reduce (AMR), can read the S3 objects that represent files.

Q: How does the File gateway enable a migration to cloud-native applications?
A: The legacy application can continue to access files using NFS, while the cloud-native application can use APIs to access S3 objects.

Q: Name the 2 kinds of Volume gateway.
A: Cached volume gateway and Stored volume gateway.

Q: What storage protocol does a Volume gateway support?
A: iSCSI (Internet Small Computer System Interfaca)

Q: Where does the a Volume gateway store the files?
A: It periodically stores snapshots as objects in S3.

Q: Name 2 ways in which Volume gateway reduce storage cost in S3.
A: The snapshots are incremental and compressed.

Q: How does the Volume gateway integrate with EC2?
A: The snapshots stored in S3 can be mounted on virtual machines in EC2 as EBS volumes.

Q: What service does the Cached volume gateway provide?
A: Primary data is stored in S3 as snapshots (and presumably also live in EBS), local cache is stored in the on-prem SAN.

Q: What disk sizes does Cached volume gateway support?
A: 1 GB - 32 TB.

Q: What service does the Stored volume gateway provide?
A: Primary data is locally in the on-prem SAN, periodic snapshots are stored in S3 objects as a backup.

Q: Where does the a Stored volume gateway store the files?
A: It periodically stores snapshots as objects in S3.

Q: What disk sizes does Cached volume gateway support?
A: 1 GB - 16 TB.

Q: What service does the tape gateway provide:
A: The gateway offers a virtual tape device and a virtual media changer device. Tape contents are stored in S3 objects.

Q: Can you continue to use your existing tape backup software (such as NetBackup, Backup Exec, Veeam) with Tape gateway?
A: Yes.

Q: Which Storage gateways are used for block-based storage?
A: Volume gateway.

Q: How can the storage gateway connect to S3?
A: The Internet, Direct Connect, or Virtual Private Cloud (VPC). The latter is used if the gateway is hosted in EC2.

SubTopic: Snowball

Q: What service does Snowball provide?
A: Move large amounts of data into or out of the AWS cloud by shipping disks from and to Amazon.

Q: What is the predecessor service for Snowball?
A: Import/Export Disk.

Q: What is the main difference between Snowball and Import/Export Disk?
A: In Import/Export Disk you provide your own disk devices, whereas with Snowball Amazon provides the device.

Q: Is Import/Export Disk still available?
A: Yes, but it is deprecated an no longer advertised on the console.

Q: Name 3 types of Snowball.
A: Snowball, Snowball Edge, Snowmobile.

Q: What does a Snowball device look like?
A: A ruggedized disk the size of a large suitcase, with an integrated kindle screen and an Ethernet plug.

Q: How do you physically connect a Snowball device to your local storage?
A: Using an Ethernet cable (RJ45, SFP+ copper or SFP+ fiber).

Q: What software do you use to transfer content to and from the Snowball device?
A: The "snowball" utility that can be downloaded from Amazon is used to copy files to and from the Snowball device.

Q: How are Snowball devices secured?
A: Several layers, including: tamper resistent enclosures, 256-bit encryption, TPM module, full erasure after transfer, location tracking.

Q: What is the cost advantage of Snowball relative to sending the data over the Internet?
A: Up to 1/5th of the cost.

Q: What is the capacity of a Snowball?
A: 80 TB in all regions. 50 TB also availble in US.

Q: How is Snowball Edge different from regular Snowball?
A: It also provides compute in addition to storage. It provides 100 TB of storage. 

Q: How is Snowmobile different from regular Snowball?
A: Snowmobile is container mounted on a truck. It provides up to 100 Petabyte (= 100,000 TB) of storage.

Q: Where does Snowball store the imported data?
A: In S3.

Q: Can Snowball also export data?
A: Yes, it can export from S3.

Q: Can Snowball import to or export from Glacier?
A: Not directly, you have to go through S3.

Q: How do you get a Snowball device?
A: You create a job in the Snowball service console to request a Snowball device.

Q: How does Amazon make sure that the Snowball device was shipped to the right person?
A: The downloaded copy utility requires credentials (a manifest file and an unlock code) which are retrieved from the Snowball console.

Q: How does Snowball know in which S3 bucket to store the data?
A: You need to specify the bucket when you create the job before the Snowball is shipped and you also need to specify it when you run the copy utility.

SubTopic: Transfer Acceleration

Q: What does S3 Transfer Acceleration do?
A: It accelerates uploads to S3 by uploading to a CloudFront Edge Location and then using the optimized Amazon backbone between the Edge Location and the Region.

Q: How do you enable S3 Transfer Acceleration?
A: It is a simple Enabled / Disabled option in the bucket properties.

Q: How much of a performance improvement can you expect from S3 Transfer Acceleration?
A: If you are close the the S3 region, not much of a difference: 3% improvement or even worse performance. For remote regions up to 40% improvement.

Q: How do I know what the actual improvement will be from my current location to each region?
A: Use the "Want to compare your data transfer speed by region?" link in the bucket properties window on the console. It will make actual measurements.

Q: What is the URL for using Transfer Acceleration when uploading a file?
A: https://s3-accelerate.amazonaws.com

Q: What is another mechanism than Transfer Acceleration to speed up uploads to S3?
A: Multipart upload.

SubTopic: Create a Static Website using S3.

Lab: Create a Static Website using S3.
Step: Create a bucket.
Step: Enable static website hosting for the bucket.
Step: Create an HTML page index.html and upload it into the bucket.
Step: Create an HTML page error.html and upload it into the bucket.
Step: Upload both pages to the bucket.
Step: Using a browser, open the website home page.
Step: Force an error by making the index not publicly readable.
Step: Using a browser, open the website home page again and observe the error page.
Step: Clean up: delete the bucket.

Q: Who manages the web servers and load balancers when hosting a static website on S3?
A: Amazon does.

Q: What types of content cannot be hosted as a static website on S3?
A: Anything that is active on the server side: PHP, .net, etc.

Q: Can content that is active on the client side (e.g. JavaScript) be hosted as a static website on S3?
A: Yes.

Q: What service do you use to tie a domain name to a static website hosted in S3?
A: Route53.

Q: If you tie a domain name to a static website hosted in S3, what must be the name of the S3 bucket?
A: The bucket name must be exactly the same as the full domain name (e.g. "example.com")

Q: What is the default URL for a static website hosted in S3 (not using your own domain name)?
A: <bucket-name>.s3-website-<region>.amazonws.com

Q: What permissions should be set for S3 objects that are used as content for a static website on S3?
A: Readbable for everyone, i.e. enable public read access.

Q: Name 2 documents to be configured for a bucket that is used to host a static website on S3?
A: Index and error.

Q: Give an example of what redirection rules are used for with a static website on S3?
A: To redirect example.com (the naked domain name) to www.example.com.

SubTopic: S3 FAQ

Q: How many S3 buckets can you have per account by default?
A: 100

Q: Does S3 provide an SLA?
A: Yes, and a service credit if the SLA is violated.

Q: Is the cost for S3 the same in all regions?
A: No.

Q: Does it cost money to copy S3 data?
A: No within a region, yes accross regions.

Q: Does it cost money to transfer data between EC2 and S3?
A: No within a region, yes accross regions.

Q: Does it cost money to access S2 data from the console?
A: Yes.

Q: Who pays when S3 data is accessed from another account?
A: The owner account, unless requester pays is enabled.

Q: What is recommended for uploading very large files to S3?
A: Multipart upload.

Q: How much cheaper is the S3 One-Zone-IA storage class than the Standard-IA storage class?
A: 20%

Q: How do the S3 Standard, Standard-IA, One-Zone-IA differ in terms of performace?
A: They are all similar.

Q: What are the types of charges for S3 storage?
A: Charges for the amount of storage per month, bandwidth, requests, early delete and small object fees.

Q: What is a key difference between EC2 and S3 One-Zone-IA in terms of how they use AZs?
A: EC2 lets you pick the AZ, S3 One-Zone-IA picks the AZ for you.

# TODO Finish the S3 Storage FAQ, starting from S3

Topic: EC2

SubTopic: EC2 101

Q: What does EC2 stand for?
A: Elastic Compute Cloud.

Q: How does EC2 support scaling up and down?
A: By using different instance types (larger and smaller).

Q: How does EC2 support scaling in and out?
A: By increasing or decreasing the number of instances.

Q: How does EC2 improve the economic of compute?
A: By allowing you to pay only for the capacity that you actually use.

Q: Name the 4 pricing options for EC2 instances.
A: On-demand, Reserved, Spot, Dedicated Host.

Q: What is the pricing model for EC2 on-demand instances?
A: You pay a fixed price per second or per hour with no commitment.

Q: What is the use case for EC2 on-demand instances?
A: No up-front payment or long-term commitment, applications with spiky demands, newly developed applications.

Q: What determines whether you pay per-second or per-hour for EC2 on-demand instances?
A: Per-second for Linux and (currently) per-hour for Windows.

Q: What is the pricing model for EC2 reserved instances?
A: Provides a capacity reservation for a contractually committed 1 or 3 year term.

Q: What is the use case for EC2 reserved instances?
A: Applications with steady and predictable usage, applications that require reserved capacity.

Q: What does the discount of EC2 reserved instances relative to EC2 on-demand instances depend on?
A: Term duration (1 or 3 year), how much is paid up-front (all or part), and convertible or not.

Q: How do you achieve maximal savings with EC2 reserved instances?
A: 3 year contract, pay everything up-front, non-convertible.

Q: What is a convertible EC2 reserved instance?
A: The type of EC2 instance can be changed (increased value, not decreased value).

Q: How much can you expect to save by using EC2 reserved instances relative to standard instances?
A: Up to 75% for standard up to 54% for convertible.

Q: What is a scheduled EC2 reserved instance?
A: Reservation is only for certain times and certains days of week or month.

Q: What is the pricing model for EC2 spot instances?
A: You big a price, you get the EC2 instance when your bid exceeds the spot price.

Q: What is the use case for EC2 spot instances?
A: When you are flexible in terms of when the instance runs. When you require very low cost.

Q: What happens if the spot price for an EC2 instance drops below your bid?
A: Your spot instance may be terminated.

Q: If your EC2 spot instance is terminated by AWS because the spot price dropped below your bid, are you charged?
A: No, you are not charged for the partial hour in which your spot instance was terminated, not even the part you did use.

Q: If you terminate your EC2 spot instance yourself, are you charged for the partial hour?
A: You are charged for the complete hour, even the part of the hour you did not use.

Q: What is the pricing model for EC2 dedicated host instances?
A: You pay for a physical server that is reserved for you, upon which EC2 instances are hosted.

Q: Name 2 use cases for EC2 dedicated hosts.
A: Licenses bound to the physical server, regulatory requirements.

Q: How are EC2 dedicated hosts purchased?
A: On-demand per hour, or reserved for up to 70% off.

Q: In the instance type, what does the letter and digit stand for?
A: The letter indicates the speciality (family), the digit the generation.

Q: What is the mnemonic for remembering the EC2 instance types?
A: FIGHT Dr Mc PX (Brad Pit Fight Club, Dagobert Duck as a scottish Doctor handing out photos).

Q: What is the speciality of an F family instance type in EC2?
A: Field Programmable Gate Array (F for FPGA).

Q: What EC2 instance type provides FPGAs?
A: F family.

Q: What are some use cases for F family instance type in EC2?
A: Genomics research, financial analytics, real-time video processing, big data, ...

Q: What is the speciality of an I family instance type in EC2?
A: High speed storage.

Q: What EC2 instance type provides high speed storage?
A: I family.

Q: What are some use cases for I family instance type in EC2?
A: No-SQL database, data warehousing, ...

Q: What is the speciality of an G family instance type in EC2?
A: Graphics intensive (G for Graphics).

Q: What EC2 instance type provides intensive graphics?
A: G family.

Q: What are some use cases for G family instance type in EC2?
A: Video encoding, 3D application streaming, ...

Q: What is the speciality of an H family instance type in EC2?
A: High disk throughput (H for High).

Q: What EC2 instance type provides high disk throughput?
A: H family.

Q: What are some use cases for H family instance type in EC2?
A: MapReduce workloads, distributed file systems such as HDFS and MapR-FS.

Q: What is the speciality of an T family instance type in EC2?
A: Lowest cost general purpose (T for Tiny).

Q: What EC2 instance type provides the lowest cost general compute?
A: T family.

Q: What are some use cases for T family instance type in EC2?
A: Web servers, small databases.

Q: What is the speciality of an D family instance type in EC2?
A: Dense storage (D for Dense).

Q: What EC2 instance type provides dense storage?
A: D family.

Q: What are some use cases for D family instance type in EC2?
A: File servers, data warehousing, Hadoop, ...

Q: What is the speciality of an R family instance type in EC2?
A: Memory optimized (R for RAM).

Q: What EC2 instance type provides optimized (large) memory?
A: R family.

Q: What are some use cases for R family instance type in EC2?
A: Memory intensive applications, databases, ...

Q: What is the speciality of an M family instance type in EC2?
A: General purpose (M for Main).

Q: What EC2 instance type provides production-quality general purpose compute?
A: M family.

Q: What are some use cases for M family instance type in EC2?
A: Application servers.

Q: What is the speciality of an C family instance type in EC2?
A: Compute optimized (C for Compute).

Q: What EC2 instance type provides optimized (large) compute?
A: C family (C for Compute).

Q: What are some use cases for C family instance type in EC2?
A: CPU intensive applications, databases.

Q: What is the speciality of an P family instance type in EC2?
A: Graphics, general purpose GPU.

Q: What EC2 instance type provides genal purpose GPUs?
A: P family.

Q: What are some use cases for P family instance type in EC2?
A: Machine learning, BitCoin mining, ....

Q: What is the speciality of an X family instance type in EC2?
A: Memory very optimized (X for Xtreme RAM).

Q: What EC2 instance type provides very optimized (extreme) memory?
A: X family.

Q: What are some use cases for X family instance type in EC2?
A: SAP, Apache Spark, ...

Q: What does EBS stand for?
A: Elastic Block Store.

Q: What is an EBS volume?
A: A virtual disk (block store).

Q: What is an EBS volume attached to?
A: An EC2 instance.

Q: What are EBS volumes used for?
A: Virtual disk (block store) use cases: boot operating systems, databases.

Q: What is the scope of an EBS volume?
A: A specific Availability Zone (AZ) within a specifi region.

Q: How is the reliability of an EBS volume achieved?
A: By replicating the data across multiple physical disks within an AZ.

Q: What is the root device volume in EBS?
A: The volume (virtual disk) from which the operating system of an EC2 instance is booted.

Q: What do we call the volume (virtual disk) from which the operating system of an EC2 instance is booted.
A: The root device volume.

Q: Can an EC2 instance have multiple EBS volumes?
A: Yes, it has one root device volume and optionally additional volumes.

Q: What are the EBS volume types (families)?
A: GP2, IO1, ST1, SC1, Magnetic (aka Standard).

Q: Which EBS volume types use SSD?
A: GP2, IO1.

Q: Which EBS volume types use magnetic rotating disks?
A: ST1, SC1, Magnetic (aka Standard).

Q: What is the GP2 volume type in EBS?
A: General Purpose SSD, balancing performance and price.

Q: What EBS volume type provides general purpose SSD?
A: GP2.

Q: What are some use cases for the GP2 volume type in EC2?
A: Most use cases, when you need less than 10K IOPS.

Q: What IOPS performance does GP2 storage in EBS?
A: 3 IOPS per GB, up to 10K IOPS for 3334GB instances, ability to bust up to 3K IOPS for extended time.

Q: Can an GP2 type volume be a boot device for an EC2 instance?
A: Yes.

Q: What is the IO1 volume type in EBS?
A: Provisioned IOPS SSD, providing high performance.

Q: What EBS volume type provides provisioned IOPS and high performance?
A: IO1.

Q: What are some use cases for the IO1 volume type in EC2?
A: When you need more than 10K IOPS, I/O intensive applications such as large databases.

Q: What IOPS performance does IO1 storage in EBS?
A: You provision the required IOPS performance, up to 20K IOPS.

Q: Can an IO1 type volume be a boot device for an EC2 instance?
A: Yes.

Q: What is the ST1 volume type in EBS?
A: Performance optimized HDD (magnetic rotating disk).

Q: What EBS volume type provides performance optimized HDD (magnetic rotating disk).
A: ST1.

Q: What are some use cases for the ST1 volume type in EC2?
A: Big data, data warehousing, log processing.

Q: Can an ST1 type volume be a boot device for an EC2 instance?
A: No.

Q: What is the SC1 volume type in EBS?
A: Cold HDD (magnetic rotating disk).

Q: What EBS volume type provides cold HDD (magnetic rotating disk).
A: SC1.

Q: What are some use cases for the SC1 volume type in EC2?
A: Lowest cost storage for infrequently accessed workloads, e.g. file servers

Q: Can an SC1 type volume be a boot device for an EC2 instance?
A: No.

Q: What is the Magnetic volume type in EBS?
A: Lowest cost bootable HDD (magnetic rotating disk). Deprecated.

Q: What EBS volume type provides lowest cost bootable HDD (magnetic rotating disk).
A: Magnetic.

Q: What are some use cases for the Magnetic volume type in EC2?
A: Legacy only; use GP2 instead.

Q: Can a Magnetic type volume be a boot device for an EC2 instance?
A: Yes.

SubTopic: Lab: Launch an EC2 instance

Lab: Launch an EC2 instance
Step: Launch one Amazon Linux t2.micro instance, termination protected (everything else default).
Step: The security groups must allow SSH, HTTPS, and HTTP from any source.
Step: Create a key-pair and properly install it on your laptop.
Step: Observe the creation of the instance.
Step: SSH into the instance.
Step: Apply security patches.
Step: Install the Apache web server, create a small web page, and verify it works.
Step: Check both the system status and the instance status.
Step: Look at the CloudWatch metrics for the instance.
Step: Terminate the instance (demonstrate that you have to turn termination protection off first).
Step: Go through the steps to purchase a reserved instance (but don't complete).
Step: Clean up: delete EC2 instance, security group, and keypair.

Q: What does AMI stand for?
A: Amazon Machine Image.

Q: What is an AMI?
A: The image for for an EC2 instance (virtual machine).

Q: What does HVM stand for?
A: Hardware Virtual Machine.

Q: What does PV stand for?
A: Paravirtual.

Q: What are the two virtualization types supported by AWS?
A: Hardware Virtual Machine (HVM) and Paravirtual (PV).

Q: What is the difference between an HVM and PV AMI in EC2 in terms of hardware emulation?
A: HVM uses fully virtualized hardware; it can make use of all hardware extensions.

Q: What is the difference between an HVM and PV AMI in EC2 in terms of the guest OS?
A: HVM can run unmodified guest OS, as if running on bare metal. PV needs modified OS.

Q: What is the difference between an HVM and PV AMI in EC2 in terms of the boot loader.
A: HVM uses standard boot from master boot record. PV needs special PV-GRUB boot loader.

Q: Which is recommended for best performance: HVM or PV?
A: HVM provised better performance for current generation instances that make use of Intel Virtualization Technology (VT).

Q: Why does PV even exist if HVM is better in all respects?
A: Historically, PV used to provide better performance, but that is no longer true with virtualization advances in hardware (CPUs).

Q: What is the advantage of Amazon Linux AMIs over other Linux AMIs?
A: They come with AWS command-line tools, Python, Ruby, Perl, and Java.

Q: What do you need to specify for spot instances?
A: Maximum price, optional launch group, valid from and to time, persitent or not.

Q: How to you selected dedicated host for an instace?
A: Set tenancy to dedicated host.

Q: What default VPCs exist when you create your AWS account?
A: Each region has one default VPC.

Q: How do you choose the AZ when creating an instance?
A: Pick the subnet for the chosen AZ, or leave it to "no preference" (Amazon picks).

Q: What is the relation to subnets and AZs?
A: Each subnet is scoped (limited) to one AZ.

Q: What is the scope of a subnet?
A: Each subnet is scoped (limited) to one AZ.

Q: What is the relation between subnets and IP addresses?
A: The IP addresses of all instances in a subnet are in the same CIDR prefix of the subnet.

Q: What are the options for the EC2 instance shutdown behavior?
A: Stop or terminate.

Q: What is the default EC2 instance shutdown behavior?
A: Stop.

Q: What are the options for monitoring EC2 instances with CloudWatch?
A: Standard (5 minute samples) or detailed (1 minute samples) at an extra cost.

Q: What is termination protection?
A: Prevents accidental termination of the instance; you have to disable the protection before you can teminate the instance.

Q: By default, is termination protection enabled or disabled?
A: Disabled.

Q: What is EC2 instance user data used for?
A: To pass bootstrap scripts to the EC2 instance.

Q: By default, what happens to the root EBS volume when the EC2 instance is terminated?
A: By default, it is deleted.

Q: By default, what happens to the non-root EBS volumes when the EC2 instance is terminated?
A: By default, they are not deleted.

Q: How do you make sure only your laptop can SSH into an EC2 instance.
A: Set source to My IP for SSH in the security group for the instance (only if you have a static IP address).

Q: Where and with what permissions should the private key file (pem file) be stored?
A: In ~/.ssh, read-only by owner (400).

Q: What command-line option to you use the specify the private key file?
A: -i <private-key-file>.

Q: What is the username for Amazon Linux instances?
A: ec2-user.

Q: What is the first thing you should do after logging into a newly created EC2 instance?
A: Apply security patches (sudo yum update -y).

Q: How do you apply security patches to a Amazon Linux AMI?
A: sudo yum update -y

Q: How do you install the apache web server on an Amazon Linux AMI?
A: sudo yum install httpd -y

Q: Where do you put the index.html file for Apache?
A: /var/www/html

Q: How do you start the Apache web server on an Amazon Linux instance?
A: sudo service httpd start

Q: How do you configure Apache to automatically startup when the Linux instance boots?
A: sudo chkconfig httpd on

Q: What is the difference between the private and public DNS/IP of an EC2 instance?
A: The public is globally reachable, the private is only reachable from inside AWS.

Q: What is the difference between the system status and the instance status in EC2?
A: System status checks the health of the underlying amazon infra, instance status checks the instance itself.

Q: What does the EC2 system status check verify?
A: Whether traffic can make it to the instance (does not check that the instance processes the traffic).

Q: What does the EC2 instance status check verify?
A: Whether traffic is accepted by guest OS in the instance.

Q: If you reboot an EC2 instance, will it come back on the same host server?
A: No, that is not guaranteed.

Q: If you reboot an EC2 instance, will the IP address remain the same?
A: No, that is not guaranteed, neither for the public nor the private IP address.

Q: What can you do if you want the public IP address of an EC2 instance to remain the same across a reboot?
A: Use an elastic IP address.

Q: What can you do if you want the public IP address of an EC2 instance to remain the same across a reboot?
A: Attach the instance to a custom VPC or use an Elastic IP address.

Q: What can you do if you want the private IP address of an EC2 instance to remain the same across a reboot?
A: Attach the instance to a custom VPC.

Q: Can you encrypt the root volume when you create an EC2 instance?
A: No, not for standard AMIs. You can encrypt the root volume when you create your own AMI by taking a snapshot. Or you can use 3rd party software such as bitlocker.

Q: Can you encrypt a non-root volume when you create an EC2 instance?
A: Yes.

SubTopic: Lab: Security Group basics

Lab: Security Group basics
Step: Create a t2.micro Amazon Linux instance with a new security group that allows HTTP, HTTPS, and SSL from any IP address.
Step: SSH into the instance and update.
Step: Instal Apache, create a little website, start Apache, configure Apache to start at boot time, and verify it works.
Step: Inspect the inbound and outbound rules for the security group.
Step: Remove HTTP from the security group and verify that the webpage stops working. Add it back.
Step: Create an additional security group with additional rules, and also attach it to the instance. Show the resulting union of rules that apply.
Step: Clean up: delete EC2 instance, security group, and keypair.

Q: What is a security group?
A: A virtual stateful layer-4 firewall attached to EC2 instances.

Q: Can an EC2 instance be attached to multiple security groups?
A: Yes.

Q: Can 1 security group have multiple EC2 instances as members?
A: Yes.

Q: When does a change to a security group take effect?
A: Immediately, even for already running instances attached to the security group.

Q: Are security groups stateful or stateless?
A: Stateful.

Q: What does it mean that a security group is stateful?
A: If a flow is allows in by an inbound rule, the same flow is automatically allowed out regardless of the outbound rules.

Q: Name 2 differences between security groups and access control lists (ACLs)?
A: Security groups are stateful, ACLs are stateless. Security groups don't support deny rules, ACLs do.

Q: What is the default behavior of a security group traffic in the absence of an explicit allow rule?
A: Traffic is blocked (denied) by default; a rule is needed to explicitly allow it.

Q: What is the default behavior of a security group for inbound traffic?
A: Block all inbound traffic by default; there are no inbound rules by default (you can add rules if you want).

Q: What is the default behavior of a security group for outbound traffic?
A: Allow all outbound traffic by default; there is a default rule that allows all traffic (you can delete this rule if you want). 

Q: What does it mean that the source for the default security group of a VPC is the security group itself?
A: It specifies the rules for communications between instances that are attached to the same VPC.

Q: Can you block a specific IP address using a security group?
A: No, use an Access Control List (ACL) instead.

SubTopic: Lab: Upgrading EBS Volume Types

Lab: Upgrading EBS Volume Types
Step: Create a t2.micro Amazon Linux instance with 3 extra volumes: Magnetic, ST1, SC1.
Step: Take a note of the availability zone of the instance and the volumes.
Step: Try to change the size and type of each attached volume, and observe which changes are allowed and which not.
Step: Pick a non-root volume and create a copy of it in another AZ in the same region.
Step: Pick a non-root volume and create a copy of it in another region.
Step: Install and configure Apache to start at boot. Create a small website and verify it works.
Step: Create an AMI from the instance.
Step: Launch a new EC2 instance from the new AMI, and verify it behaves as a web server.
Step: Clean up: delete EC2 instances, security groups, keypairs, snapshots, and images in all regions.

Q: Can you mount an EBS volume in one AZ to an EC2 instance in a different AZ?
A: No.

Q: How can you see which volume in the volume list is the root volume?
A: It is based of a snapshot.

Q: Can you change the size of a volume on-the-fly (without affecting a running attached EC2 instance)?
A: Yes, but not for Magnetic (= Standard) volumes.

Q: Can you change the type of a volume on-the-fly (without affecting a running attached EC2 instance)?
A: Yes, but not for Magnetic (= Standard) volumes.

Q: How can you copy an EBS volume to a different AZ in the same region?
A: Create a snapshot of the volume, and create a new volume from the snapshot in the other AZ.

Q: How can you copy an EBS volume to a different region?
A: Create a snapshot of the volume, copy the snapshot to a different region, and create a new volume from the snapshot in the other region.

Q: How can you copy an EC2 instance to another region?
A: Create a image from the instance, copy the image to the other region, boot an instance from the copied image.

Q: How do you create a new AMI from a running EC2 instance?
A: Create a snapshot of the root volume, and convert the snapshot into an image.

Q: What is a snapshot?
A: A point in time copy of a volume.

Q: What happens if you take multiple snapshots of the same volume at different points in time?
A: Snapshots are incremental: only the deltas as stored.

Q: How long does it take to take a snapshot?
A: The first snapshot takes long (minutes). Subsequent snapshots are incremental and hence faster.

Q: Can you take a snapshot of the root volume while the instance is running?
A: It is technically possible but not wise; you should stop the instance.

Q: Name 2 things that you can use as the source for creating an AMI.
A: EC2 instance, EBS snapshot.

Q: Where are snapshots stored?
A: On S3 (although you don't see a bucket with the snapshots in them).

Q: If a snapshot is taken from an encrypted volume, is the snapshot encrypted?
A: Yes.

Q: If a volume is restored from an encrypted snapshot, is the volume encrypted?
A: Yes.

Q: Can you share an unencrypted snapshot with another user?
A: Yes, you can share it with another account or make it completely public.

Q: Can you share an encrypted snapshot with another user?
A: No, they will not be able to restore a volume from it.

SubTopic: Lab: Encrypt Root Device Volume and Create an AMI

Lab: Encrypt Root Device Volume and Create an AMI
Step: Create a t2.micro Amazon Linux instance.
Step: Stop the instance and take a snapshot.
Step: Copy the snapshot to a different region and encrypt it.
Step: In the destination region, create an image from the snapshot.
Step: Create an image from the newly created image.
Step: Observe that the root volume of the newly created instance is encrypted.
Step: SSH into the newly created instance.
Step: Clean up: delete EC2 instances, security groups, keypairs, snapshots, and images in all regions.

Q: Why are public and community AMIs never encrypted?
A: Because encrypted images and volumes use a key that is tied to the user.

SubTopic: AMIs, EBS Root Device Volumes vs Instance Store

Q: What are the two type of AMIs?
A: EBS Backed and Instance Store Backed (aka Ephemeral Store).

Q: Name 5 criteria that you can select an AMI on.
A: Region, operating system, architecture (32-bit or 64-bit), launch permissions, and root device volume.

Q: Can you add additional Instance Store Backed volumes after the EC2 instance has been launched?
A: No.

Q: Can you add additional EBS Backed volumes after the EC2 instance has been launched?
A: Yes.

Q: Can you encrypt additional Instance Store Backed volumes?
A: No.

Q: Can you encrypt additional EBS Backed volumes?
A: Yes.

Q: Can you stop an EBS Backet EC2 instance?
A: Yes.

Q: Can you stop an Instance Store Backet EC2 instance?
A: No, you can only reboot or terminate it.

Q: Can you detach an EBS Backed volume from an EC2 instance and attach it to some other instance?
A: Yes, even if it is the root volume.

Q: Can you detach an Instance Store Backed volume from an EC2 instance and attach it to some other instance?
A: No, is is actually not even a volume and doesn't appear in the volume list.

Q: How is the data for an EBS Backed Volume stored?
A: Redundantly across multiple physical servers within an AZ. It can survive the loss of a physical server.

Q: How is the data for an Instance Store Backed Volume stored?
A: Non-redundantly (ephemerally) only on the same physical server that hosts the EC2 instance. It cannot survive the loss of that physical server.

Q: Name 2 reasons for stopping an EC2 instance.
A: To take a snapshot, to move it to another hypervisor in an attempt to resolve a failed status check.

Q: What is the main reason that Instance Store Backed Volumes exist?
A: For historical reasons: this was the only type of volume that AWS used to support before EBS Backed Volumes were introduced later.

Q: How is an EBS Backed root volume created?
A: It is an EBS volume created from an EBS snapshot.

Q: How is an EBS Backed root volume created?
A: It is an Instance Store volume created from a template stored in S3.

Q: Which is created faster, an EBS Backed Volume or an Instance Store Backed Volume?
A: An EBS Backed Volume is created faster.

Q: What is another name for Ephemeral Storage?
A: Instance Store Backed Storage or Instance Store Backed Volumes or simply Instance Store Volumes.

Q: What happens if the host physical server fails for an EBS Backed EC2 Instance?
A: The data survives.

Q: What happens if the host physical server fails for an Instance Store Backed EC2 Instance?
A: The data is lost.

Q: What happens if you reboot an EBS Backed EC2 Instance?
A: The data survives.

Q: What happens if you reboot an Instance Store Backed EC2 Instance?
A: The data survives.

Q: What happens if you terminate an EBS Backed EC2 Instance?
A: By default the data is lost, but you can configure EC2 to keep the root device volume.

Q: What happens if you terminate an Instance Store Backed EC2 Instance?
A: The data is always lost, you cannot configure EC2 to keep the root device volume.

SubTopic: Lab: Load Balancers and Health Checks

Lab: Load Balancers and Health Checks
Step: Create an Amazon Linux t2.micro EC2 instance with an Apache web server that is configured to start at boot time.
Step: Create a simple webpage in index.html and verify it works.
Step: Create a healthcheck.html file.
Step: Create a classic load balancer
Step: Use healthcheck.html for the health check and lowest possible healthcheck intervals.
Step: Add the EC2 instance as a member.
Step: Verify that the load balancer reports the EC2 instance as in-service and healthy.
Step: Use a web browser to verify that the load balancer works.
Step: Remove the healthcheck.html file from the instance, and verify that the load balancer report the instance as out-of-service.
Step: Create an application load balancer verify it works.
Step: Clean up.

Q: What does ELB stand for?
A: Elastic Load Balancer.

Q: What EWS service provides load balancing?
A: Elastic Load Balancer (ELB).

Q: What are the 2 kinds of load balancers?
A: Application Load Balancer and Classic Load Balancer.

Q: Based on what layer does an Application Load Balancer make its routing decissions?
A: Layer 7: sophisticated routing based on the application layer (HTTP, HTTPS).

Q: Based on what layer does a Classic Load Balancer make its routing decissions?
A: Layer 4: the transport layer (TCP, SSL) and very basic routing based on the application layer (HTTP, HTTPS).

Q: Which type of load balancer supports path-based routing?
A: Application Load Balancer.

Q: What end-points can an Application Load Balancer route traffic to?
A: EC2 virtual machines and containers.

Q: What end-points can a Classic Load Balancer route traffic to?
A: EC2 virtual machines but not containers.

Q: What is the difference between an internal and external load balancer?
A: An external load balancer can serve traffic from the public Internet.

Q: Name the 4 paramaters that ELB uses for timing health checks.
A: Response timeout, Interval, Unhealthy threshold, Healthy threshold.

Q: What is the ELB healthcheck unhealthy threshold?
A: If the healthcheck fails N consecutive pings, the instance is declared unhealthy.

Q: What is the ELB healthcheck healthy threshold?
A: If the healthcheck passes N consecutive pings, the instance is declared healthy.

Q: What is the ELB healthcheck interval?
A: Send a healthcheck request this often.

Q: What is the ELB healthcheck timeout?
A: Wait this long for a healthcheck response.

Q: Are ELB load balancers free in the free tier?
A: No.

Q: How is the ELB load balancer publicly identified?
A: Using a public DNS name.

Q: Does an ELB load balancer have a public IP address?
A: Yes and no. An ELB load balancer will have a public IP address, but AWS manages it and doesn't tell you what it is on the console. It can change.

Q: Can you use your own DNS domain name for an ELB load balancer?
A: Yes, using Route53.

SubTopic: Lab: CloudWatch with EC2.

Lab: CloudWatch with EC2.
Step: Create an EC2 instance with basic monitoring and let it run for some time.
Step: Look at the monitoring graphs using the EC2 console.
Step: Go to the CloudWatch console.
Step: Create a dashboard.
Step: Add a text widget.
Step: Add a line widget for CPU utilization.
Step: Add a stacked area widget for network in and out.
Step: Add a number widget for CU utilization.
Step: Create an alarm (details in next step).
Step: Threshold is CPU utilization > 50% for 1 consecutive sample.
Step: Action is send an email in state alarm.
Step: Observe that the current alarm state is OK.
Step: Force high CPU on the instance using "dd if=/dev/zero of=/dev/null"
Step: Observe that an alarm is generated and an email is sent within 5 minutes.
Step: Note - you can play around with events but it is not an exam topic.
Step: Note - you can play around with logs but it is not an exam topic.
Step: Clean up.

Q: Name the 5 top-level services in the CloudWatch console.
A: Dashboards, Alarms, Events, Logs, Metrics.

Q: What is the polling interval for EC2 basic monitoring?
A: Every 5 minutes.

Q: What is the polling interval for EC2 detailed monitoring?
A: Every 1 minute.

Q: What language does a text widget in a CloudWatch dashboard use?
A: Markdown.

Q: What types of metrics are available by default for EC2?
A: CPU, Disk, Network, Status check.

Q: What CPU related metrics are available in CloudWatch by default for EC2?
A: CPU Credit Balance, CPU Credit Usage, CPU Utilization.

Q: What disk related metrics are available in CloudWatch by default for EC2?
A: Disk Read Bytes, Disk Read Ops, Disk Write Bytes, Disk Write Ops.

Q: What network related metrics are available in CloudWatch by default for EC2?
A: Network In, Network Out, Network Packets In, Network Packets Out.

Q: What status related metrics are available in CloudWatch by default for EC2?
A: Status Check Failed, Status Check Failed Instance, Status Check Failed System.

Q: Is memory (RAM) utilization available by default in CloudWatch?
A: No, you need to create a custom metric for that.

Q: What is a CloudWatch event?
A: A state change in an AWS resource that is fed into a CloudWatch event stream.

Q: What happens to CloudWatch events that are fed into an event stream?
A: CloudWatch rules select events of interest and trigger actions.

Q: What are CloudWatch logs?
A: They allow you to monitor EC2 instances at the application level by looking at the application logs.

Q: How does CloudWatch logs monitor applications logs inside the virtual machine?
A: You need to install an agent inside the instance.

Q: What is the difference between CloudWatch and CloudTrail?
A: CloudWatch monitors performance metrics, CloudTrail provides an audit trail for API calls.

SubTopic: Lab: The AWS Command Line and EC2

Lab: The AWS Command Line and EC2
Step: Install the AWS CLI ("aws") on the Mac (use Google for instructions).
Step: Install the AWS shell ("aws-shell") on the Mac (use Google for instructions).
Step: *IMPORTANT* If you already have AWS CLI configure, make a backup of ~/.aws/config and ~/.aws/credentials first.
Step: Create a new user for programmatic access and note its Access Key Secret.
Step: Do the initial configuration of the AWS CLI using the credentials of this new user.
Step: Execute some AWS CLI commands on the Mac (.e.g. "aws ec2 describe-instances" or "aws s3 ls")
Step: Create an EC2 instance running Amazon Linux.
Step: SSH into the instance and run the AWS CLI.
Step: Do the initial configuration of the AWS CLI using the credentials of the CLI user.
Step: Execute some AWS CLI commands in the instance (.e.g. "aws ec2 describe-instances" or "aws s3 ls")
Step: Restore of ~/.aws/config and ~/.aws/credentials if necessary.
Step: Clean up.

Q: Do Amazon Linux AMIs include the AWS Command Line Interface (CLI)?
A: Yes.

Q: What is the first step after installing the AWS command line tools?
A: aws configure.

Q: What do you need to run the command line "aws configure"?
A: The access key id and the access key secret.

Q: What can you do if you want to use the command line tools but don't have the access key secret?
A: Create a new user for the command line tools.

Q: Where are the credentials for the AWS CLI stored?
A: ~/.aws/credentials

Q: What is a more secure mechanism for running the AWS CLI from an instance than using an access key secret?
A: Roles.

Q: What should you do if you accidentally upload the access key secret to GitHub?
A: Immediately delete the user who owns that access key secret or regenerate the access key for that user.

SubTopic: Lab: Using IAM Roles with EC2.

Lab: Identity Access Management (IAM) Roles.
Step: Create a new service role for EC2 that provides full access to S3.
Step: Observe all the actions that the role allows to be performed.
Step: Create an Amazon Linux EC2 instance and assign the role to it.
Step: SSH into the instance
Step: Run the AWS CLI command to list all S3 buckets without first configuring the CLI. Observe it works.
Step: Verify that the access key is not stored on the instance.
Step: Clean up.

Q: Why are roles safer than access keys to control access to resources?
A: Someone could compromise the key and gain access.

Q: Name a scenario where access keys are the only way to go and roles cannot be used?
A: When accessing a resource from outside the AWS cloud (e.g. using the AWS CLI from a laptop).

Q: From which service are roles managed?
A: Identity and Access Management (IAM).

Q: Name 4 types of roles.
A: AWS Service Role, AWS Service-Linked Role, Role for Cross-Account Access, Role for Identity Provider Access.

Q: What is an AWS Service Role?
A: It allows some AWS service to perform actions on your (the user's) behalf.

Q: What is an AWS Service-Linked Role?
A: It allows some AWS service (currently only Lex) to control a bot on your behalf.

Q: What is a Cross-Account Access Role?
A: It allows users from some other account (owned by you or a 3rd party) to access resources in this account.

Q: What is an Identity Provider Access Role?
A: Allows user's that have been authenticated by an identity provider to access resources in this account (through the console or programmatically).

Q: What is the scope of a role?
A: Global.

Q: Is it possible to add or change a role on an already running EC2 instance?
A: Yes, it is, but this was only very recently added and the exam may be out of date (catch-22 situation).

SubTopic: Lab: S3 CLI and Regions.

Lab: S3 CLI and Regions.
Step: Create an Amazon Linux EC2 instance without any role.
Step: Create three buckets in three different regions: one the same as the EC2 instance, and two other regions.
Step: Upload an object to each bucket. 
Step: SSH into the instance and attempt to list the buckets using the CLI without configuring the CLI. Observe it does not work.
Step: Create a new service role for EC2 that provides full access to S3.
Step: Attach the role to the EC2 instance.
Step: SSH into the instance and attempt to list the buckets using the CLI without configuring the CLI. Observe that this time it works.
Step: Use the CLI to download the object in the 1st bucket in the region as the instance.
Step: Use the CLI to download the object in the other buckets in the region as the instance.
Step: Clean up.

Q: What is the AWS CLI command to lists all buckets?
A: aws s3 ls

Q: What is the AWS CLI command to download all objects from a bucket in the same region as the EC2 instance from where the CLI command is invoked?
A: aws s3 cp --recursive s3://<bucket-name> .

Q: What is the AWS CLI command to download all objects from a bucket in a different region from the EC2 instance from where the CLI command is invoked?
A: aws s3 cp --recursive --region <bucket-region> s3://<bucket-name> .

SubTopic: Lab: Using Bootstrap Scripts.

Lab: Using Bootstrap Scripts.
Step: Create a bucket.
Step: Create a simple index.html webpage and upload it to the bucket.
Step: Create a EC2 role that provides full access to S3.
Step: Launch an Amazon Linux instance... (continued)
Step: ... with the new role attached ... (continued)
Step: ... with a boot script that runs yum update ... (continued)
Step: ... and a security group that allows SSH, HTTP, and HHTP.
Step: As you are performing the next steps on the live instance, copy and paste each executed bash command into a notepad.
Step: Install the Apache webserver.
Step: Start the Apache webserver.
Step: Configure Apache to automatically start at boot time.
Step: Copy the index.html file from the S3 bucket to /var/www/html
Step: Use a browser to verify the webpage works.
Step: Terminate the instance.
Step: Launch a new instance, same as before, except use all the commands collected in the notepad as the bootup script.
Step: Use a browser to verify the webpage on the newly launched instance works.

Q: What is stored in the "user data" of an instance?
A: The boot script (aka configuration script).

Q: What is a boot script (aka configuration script)?
A: A set of commands that is run when the instance is launched.

Q: How do you indicate that the boot script is a bash script?
A: By making the first line #!/bin/bash

Q: At what priviledge level is the boot script run?
A: Root (you do not need sudo in the script).

Q: Where can you see the output of the boot script for debugging?
A: /var/log/cloud-init-output.log

SubTopic: Lab: Using Instance Metadata.

Lab: Using Instance Metadata.
Step: Launch an EC2 instance.
Step: SSH into the EC2 instance.
Step: Display the metadata index for the instace from inside the instance.
Step: Display the IPv4 public address of the intsance using the metadata.
Step: Display the boot script of the intsance using the metadata.
Step: Clean up.

Q: What is instance metadata?
A: Data about an instance that can be retrieved from the command line.

Q: What is the link-local IP address for retrieving the metadata?
A: 169.254.169.254

Q: What is the URL for retrieving the index of the latest metadata?
A: http://169.254.169.254/latest/meta-data/

Q: What is the command for retrieving the index the latest metadata?
A: curl http://169.254.169.254/latest/meta-data/

Q: What is the command for retrieving a specific metadata item, e.g. the public IPv4 address?
A: curl http://169.254.169.254/latest/meta-data/public-ipv4

SubTopic: Lab: Launch Configurations and Auto Scaling Groups

Lab: Launch Configurations and Auto Scaling Groups
Step: Create a bucket and upload a simple index.html and healthcheck.html into it.
Step: Create a load balancer with aggressive timeouts.
Step: Create a launch configuration that uses a bootstrap script to start a web server.
Step: Create an auto scaling group that ... (continued)
Step: ... starts with 3 instances (continued)
Step: ... uses all AZs in the region (continued)
Step: ... uses the load balancer we just created (continued)
Step: ... dynmically adjusts between 3 and 5 instances (continued)
Step: ... grows after 5 minutes of >90% CPU utilization (continued)
Step: ... shrinks after 5 minutes of <40% CPU utilization.
Step: Terminate an instance and verify a replacement is automatically launched.
Step: Force high CPU usage using "dd if=/dev/zero of=/dev/null" and verify that the auto scaling group behaves correctly.
Step: Clean up.

Q: What is an Auto Scaling Group?
A: A load balancer with a group of instances behind it that grows and shrinks automatically based on load.

Q: What is a Launch Configuration?
A: A configuration template that is used when a new instance is launched for an Auto Scaling Group.

Q: What does creating a Launch Configuration look like?
A: It looks exactly like launching an EC2 instance, except that the instance is not actually launched.

Q: Where will an Auto Scaling Group place the member instances?
A: It will automatically spread them out acress all member AZs as much as possible.

Q: What is the health check grace period?
A: The length of time (after launching the instance) before the auto scaling group starts checking the health.

Q: What are the two options for the auto scaling group scaling policy?
A: Keep group at initial size, or adjust capacity of group dynamically.

Q: What is used as the trigger to increase or decrease the auto scaling group size?
A: An alarm.

Q: What is the warm up period for an auto scaling group?
A: After growing the group size, wait this long before even considering another grow action.

Q: When you delete an auto scaling group, are the member instances automatically deleted as well?
A: Yes.

SubTopic: EC2 Placement Groups

Q: What are the two types of placement groups?
A: Clustered placement group, spread placement group.

Q: What is a clustered placement group?
A: A grouping of instances within a single AZ, minimizing network latency and maximizing network throughput.

Q: Can a clustered placement group span multiple AZs?
A: No.

Q: Name some typical use cases for clustered placement groups?
A: Big data, Cassandra, ...

Q: Can all types of instances be places in a clustered placement group?
A: No, only certain types of instances, typically large instance type, for example not t2.micro or t2.nano.

Q: What is a spread placement group?
A: A grouping of instances that are each placed on distinct underlying hardware.

Q: What is a typical use case for a spread placement group?
A: Applications that have a small number of separate instances that should be kept separate from each other (avoid fate sharing).

Q: When the exam talks about a placement group, what type of placement group is it generally talking about?
A: It probably talks about a clustered placement group; spread placement groups are very new.

Q: Can a spread placement group span multiple AZs?
A: Yes.

Q: The name of a placement group must be unique within what scope?
A: The name must be unique for the AWS account.

Q: Can you place instances of different types or sizes in a placement group?
A: Yes, but it is not recommended.

Q: Can you merge placement groups?
A: No.

Q: Can you move an already running instance into a placement group?
A: Not directly. But you can create an AMI and spin up a new instance from the AMI in the placement group.

SubTopic: Lab: Elastic File System

Lab: Elastic File System
Step: Go to the EFS console.
Step: Create an EFS file system with a mount target in each AZ.
Step: Create an EC2 instance in each AZ.
Step: Create an ELB load balancer with aggressive timers and assign all EC2 instances to it. Use healthcheck.html as the health check.
Step: For each instance do the following ... (continued)
Step: ... SSH into the instance
Step: ... Install Apache and start it
Step: ... Mount the EFS file system to the directory /var/www/html directory.
Step: On ONE of the instances, create the file /var/www/html/healthcheck.html and /var/www/html/index.html
Step: Verify that the files appear on all instances
Step: Verify that the load balancer declares all instances as healthy
Step: Clean up.

Q: What does EFS stand for?
A: Elastic File System.

Q: What storage does Elastic File System (EFS) provide?
A: Virtual file system.

Q: What protocol does EFS support?
A: Network File System version 4 (NFSv4).

Q: In EFS, do you pay for the pre-provisioned capacity or only for the actually used capacity?
A: Only for the actually used capacity. There is no need to pre-provision capacity.

Q: Do you need to pre-provision capacity for an EFS volume?
A: No.

Q: How far up can EFS scale?
A: Up to petabytes of storage capacity and thousands of concurrent NFS connections.

Q: Is EFS data stored in a single AZ or spread across multiple AZs?
A: Spread across multiple AZs within a region, but you need a separate mount target in each AZ.

Q: What is the durability SLA for EFS?
A: AWS currently does not provide a durability guarantee (yet).

Q: Can you mount a single EBS volume to different EC2 instances simultaniously?
A: No, use EFS instead if you need that.

Q: What consistency model does EFS provide?
A: Read after write consistency.

Q: What is an EFS mount target.
A: EC2 instances connect to an EFS file system using a mount target. A mount target has an IP address and is located in a specific AZ.

Q: Can you have multiple mount targets per EFS file system?
A: Yes, in fact this is common. You typically have one file system across all AZs, and one mount point per AZ.

Q: Is the IP address for an EFS mount point automatically chosed by AWS, or do you specify the IP address manually?
A: Both options are available.

Q: What is the security group requirement for an EC2 instance that is attached to an EFS file system?
A: The EC2 instance and the EFS file system must both be members of the same security group.

Q: How do you get help on how to mount an EFS file system?
A: Click on the mount instructions link for the file system in the console.

Q: How do you install an NFS client on Linux?
A: "sudo yum install -y nfs-utils" on Amazon Linux / Redhat / SuSE. "sudo apt-get install nfs-common" on Ubuntu. However, it is typically already pre-installed.

Q: How do you mount an NFS file system?
A: Create a directory (e.g. "sudo mkdir efs"). Execute the (complex) mount command provided in the help text.

Q: What is the main use case for EFS?
A: If you need a central repository of files (a file system) that needs to be simultaniously accessed by multiple EC2 instances.

Q: What file protections does EFS provide?
A: NFSv4 has per-file and per-directory user permissions that are synchronized and enforced across all attached instances.

SubTopic: Lambda Concepts

Q: What is Lambda?
A: Event-driven serverless compute as a service.

Q: What is the buzzword for the type of application that is built on AWS Lambda?
A: Serverless application.

Q: What is the main advantage of serverless (Lambda)?
A: You don't have to manage infrastructure anymore - neither physical nor virtual infrastructure. You don't worry about patching, scaling, etc.

Q: What are you responsible for managing and deploying into the cloud with Lambda?
A: You upload code to create Lambda functions.
 
Q: What causes Lambda functions to be executed?
A: Events or API calls.

Q: What generates events that cause Lambda functions to be executed?
A: Most AWS services generate a large repertoire of events, e.g. data changes in S3 buckets of Dynamo databases.

Q: What AWS service is responsible for invoking a Lambda function as a result of an HTTP API requirest?
A: API Gateway.

Q: Who manages Lambda scaling?
A: Amazon does.

Q: Are all Lambda triggers available in all regions?
A: No, some triggers are only available in certain regions. North Virginia will always have the most up-to-date features.

Q: Name 3 workflows for creating a Lambda function.
A: Author from scratch, Blueprints, Serverless Application Repository.

Q: Name 5 programming languages that are supported for writing Lambda functions.
A: Python (2.7 and 3.6), NodeJS, Java, Go, C#.

Q: What is the most common role template for a Lambda function?
A: Simple Microservice Permission.

Q: Name 11 services that can generate triggers for Lambda functions.
A: API gateway, AWS IoT, Alexa Skills Kit, Alexa Smart Home, CloudWatch Events, CloudWatch Logs, Cognito Sync Trigger, DynamoDB, Kinesis, S3, SNS.

Q: How is Lambda priced?
A: By number of requests, duration, memory

Q: What is the price per Lambda request?
A: First 1 million requests per month are free, after that $0.20 per 1 million requests.

Q: How is Lambda duration calculated?
A: Time interval from start of invocation to completion or termination, rounded up to nearest 100ms.

Q: How does the price depend on duration and memory?
A: Some extremely small amount ($0.00001667 currently) per Gigabyte-second used.

Q: What is the upper threshold for the duration of a single Lambda invocation?
A: 5 minutes.

Q: What if you want to have a Lambda function that runs longer than 5 minutes?
A: Break it up into 5 minute chunks, and have each chunk trigger the next one.

Q: Does lambda scale up or out?
A: It scales out (more resource instances, not bigger resource instances).

Q: How to event triggers relate to Lambda functions?
A: Each event trigger creates a new Lambda invocation.

Q: Can a lambda function trigger another Lambda function?
A: Yes.

Q: What is the main disadvantage of Lambda?
A: Architecture can get extremely complicated.

Q: What AWS service helps you debug serverless applications based on Lambda?
A: X-Ray.

SubTopic: Lab: Build a Serverless Webpage

Lab: Build a Serverless Webpage
Step: Download index.html, error.html, and hellocloudgurus.py from the ACloudGuru lesson resources.
Step: Author a Lambda function from scratch ... (continued)
Step: ... using Python 3.6 as the language (continued)
Step: ... with a new role from template Simple Microsservice Permissions.
Step: Copy the code in hellocloudgurus.py into the Lambda function.
Step: Add an API gateway trigger.
Step: Observe the URL for the newly created API gateway.
Step: In the API gateway, remove method ANY and replace it with method GET ... (continued)
Step: ... to call a Lambda function with proxy integration (continued)
Step: Deloy the API.
Step: Click on the invoke URL for the API and verify it works.
Step: Edit index.html to put the invoke URL in.
Step: Create a bucket and upload index.html and error.html (make them publicly readable).
Step: Test the website by clicking on the public URL for index.html in the bucket.

SubTopic: Lab: Using Polly To Help You Pass Your Exam

Lab: Using Polly To Help You Pass Your Exam
Step: Download the resources from ACloudGuru for this lab.
Step: Create a DynamoDB table for posts with primary key id.
Step: Create two S3 buckets: one for hosting the website and one for storing the MP3 files.
Step: Create an SNS topic for new posts.
Step: Create and IAM role for Lambda
Step: ... with a new user-created policy
Step: ... using a using the lambdapolicy.json in the resources to define the permissions.
Step: Create the 1st Lambda function to post a new posting
Step: ... from scratch 
Step: ... written in Python 2.7
Step: ... using the role we created above
Step: ... no trigger (yet)
Step: ... copy the newpost.py code from the resources (read and understand the code)
Step: ... set the environment variables DB_TABLE_NAME and SNS_TOPIC
Step: Create a test event for the new Lambda function
Step: ... using sample.json from the resources as the test event data
Step: Execute the test function, check the results, and check the contents of the DynamoDB table.
Step: Create the 2nd Lambda function to convert a posting to audio
Step: ... from scratch 
Step: ... written in Python 2.7
Step: ... using the role we created above
Step: ... using the SNS notification as the trigger
Step: ... copy the converttoaudio.py code from the resources (read and understand the code)
Step: ... set the environment variables DB_TABLE_NAME and BUCKET_NAME (for the mp3 bucket)
Step: ... set the timeout to 5 minutes
Step: Create the 3rd Lambda function to get posts
Step: ... from scratch 
Step: ... written in Python 2.7
Step: ... using the role we created above
Step: ... using the SNS notification as the trigger
Step: ... copy the getposts.py code from the resources (read and understand the code)
Step: ... set the environment variables DB_TABLE_NAME
Step: ... set the timeout to 5 minutes
Step: Create a test event for the new Lambda function
Step: ... using {"PostId": "*"} as the test event data
Step: Execute the test function and check the results.
Step: Create a new API in API Gateway for the application.
Step: Create a new GET method in the API
Step: ... integrate with the Lambda function to get posts
Step: ... add a PostId parameter to the URL query string
Step: ... set request body passthrough to when there are no templates defined
Step: ... add a mapping template for application/json using mappings.json from the resources
Step: Create a new POST method in the API
Step: ... integrating with the Lambda function to create a new posts
Step: Enable Cross Origin Resource Sharing (CORS) for the API
Step: Deploy the API
Step: ... save the invoke URL for the API in a note
Step: Create a bucket policy for the website bucket to make everything in the bucket publicly accessible
Step: ... use bucketpolicypermissions.json from the resources (edit the BUCKET_NAME)
Step: Edit the scripts.js file in the resources to edit the API endpoint (noted before)
Step: Upload the website files into the bucket
Step: ... files index.html, scripts.js, styles.css from the resources
Step: Test the website by clicking on the URL for the index.html object in S3
Step: Clean up OR continue with the Alexa Skill lab

Q: What does CORS stand for?
A: Cross Origin Resource Sharing.

Q: When is Cross Origin Resource Sharing (CORS) needed?
A: When one domain name accesses resources in another domain.

Q: Give a practical example of when Cross Origin Resource Sharing (CORS) is needed.
A: Website is stored in one bucket, and resources (e.g. images) in another bucket.

SubTopic: Lab: Build an Alexa Skill

# TODO: Add the Build an Alexa Skill lab (order an Echo first)

Q: What is Amazon Alexa?
A: Amazon's voice service.

Q: What is an Amazon Echo?
A: An Amazon speaker that supports Alexa.

Q: What is an Alexa skill?
A: A installable "app" for Alexa that provides a new capability. One skill contains N intents.

Q: What is an Alexa intent?
A: A specific request that Alexa can answer. An intent is part of a skill. An intent regognizes N utterances.

Q: What is an Alexa utterance?
A: A phrasing that Alexa can recognize. An utturance is part of an intent.

Q: What is an Alexa slot?
A: A step in a multi-step conversation with Alex.

Q: How long does it take to build the Alexa model?
A: A long time, up to 5 minutes.

Q: What happens when an Amazon skill is triggered?
A: An AWS Lambda function is invoked.

Topic: Route53

SubTopic: DNS 101

Q: What does DNS stand for?
A: Domain Name System (DNS).

Q: What does DNS do?
A: Resolve domain names to IP addresses.

Q: Does AWS support IPv6?
A: Yes, there has been good IPv6 support across most services since 2016.

Q: What is a top-level domain name ?
A: The last part of the domain name, e.g. .com in www.cnn.com

Q: What is a second-level domain name?
A: The optional second-to-last part in some domain names, e.g. .co in www.bbc.co.uk

Q: Who controls the database of top-level domains?
A: IANA which is a department of ICANN.

Q: What does IANA stand for?
A: Internet Assigned Numbers Authority

Q: What does ICANN stand for?
A: Internet Coorporation for Assigned Names and Numbers.

Q: What is a domain registrar?
A: An authority that registers domains names directly under one or more top-level domains.

Q: Who guarantees uniques of domain names across the Internet?
A: InterNIC (a service of ICANN).

Q: How does InterNIC guarantee the uniqueness of domain names?
A: By registering each domain name in the WHOIS database.

Q: What is WHOIS?
A: A database for registerd Internet resources (domain names, address blocks, AS numbers, ...) and a protocol for accessing it.

Q: What is a DNS zone?
A: A distinct, contiguous portion of the domain name space managed by a single manager.

Q: Name some types of DNS resource records.
A: SOA, NS, A, AAAA, CNAME, ALIAS, and others.

Q: What does SOA stand for in DNS?
A: Start of Authority

Q: What is the purpose of a SOA record in DNS?
A: It contains administrative information about a zone.

Q: What fields are in a SOA record in DNS?
A: Name, class, primary master name, administrator email, serial number, refresh interval, retry interval, expire interval, TTL.

Q: What is the purpose of a SOA serial number?
A: To detect changes (newer versions) and initiate a zone transfer.

Q: What does NS stand for in DNS?
A: Name Server

Q: What is the purpose of a NS record in DNS?
A: Delegate a subdomain to a set of authoritative name servers.

Q: Who provides DSN NS records to whom?
A: The owner of the domain provides the NS records to the registrar where the domain was registered.

Q: What is the purpose of an MX record in DNS?
A: Specifies the mail server (e.g. mail.example.com) for a domain (e.g. example.com).

Q: Does Route53 support MX records?
A: Yes.

Q: Which record types does Route53 support?
A: A, AAAA, CNAME, CAA, MX, NAPTR, NS, PTR, SOA, SPF, SRV, TXT (and ALIAS which is Route53 proprietary). More are expected.

Q: What is a DNS wildcard entry?
A: *.example.com where * will match and subdomain (e.g. www.example.com and subdomain.example.com)

Q: Does Route53 support wildcard entries?
A: Yes, except for NS records.

Q: Does Route53 support DNSSEC.
A: Partially. Yes for domain registration. But no, not currently for DSN queries.

Q: Is Amazon a domain registrar?
A: Yes.

Q: Can you buy domain names directly from Amazon?
A: Yes, Amazon is a domain registrar.

Q: Can you use a domain registered with a 3rd party registrar (e.g. GoDaddy) in Amazon?
A: Yes. Register the domain name with GoDaddy, create the Zone in AWS, get the NS records from AWS, provide the NS records to GoDaddy.

Q: What is the purpose of an A record in DNS?
A: Map a domain name to an IPv4 address 

Q: What is the purpose of an AAAA record in DNS?
A: Map a domain name to an IPv6 address 

Q: What fields are in an A or AAAA record in DNS?
A: Host name, Points to IP address, TTL.

Q: What is the purpose of the TTL field in a DNS record?
A: How long should the client cache the information.

Q: What is the advantage of a small TTL in DNS?
A: DNS changes propagate faster through the Internet.

Q: What is the advantage of a large TTL in DNS?
A: Fewer queries to DNS servers, the clients use cached information longer.

Q: What should you do before you migrate a service from (say) Azure to AWS?
A: Set the DNS TTL to a low value (e.g. 5 minutes) and wait for the current TTL to expire (typically 2 days) before doing the migration.

Q: What is the purpose of an CNAME record in DNS?
A: Maps a domain name to a canonical domain name (e.g. www.example.com -> example.com).

Q: Is a CNAME record allowed for a naked domain name (a zone apex)?
A: No, in a CNAME record, you must use an A or AAAA record for the naked domain name. Use an ALIAS record instead.

Q: What is the purpose of an ALIAS record in DNS?
A: Similar to CNAME, except it supports naked domains. Introduced by AWS to map naked domain names to ELB load balancers.

Q: Does an ELB load balancer have an IP address.
A: Yes, of course, but the address is not provided and can change. Always use the domain name of the load balancer instead.

Q: What happens if you used an ALIAS record to map your domain name to a load balancer domain name, and the IP address of the load balancer changes.
A: Amazon will automatically update the DNS responses for your domain name to the new address of the load balancer. You don't need to do anything.

Q: What is the difference between an ALIAS record and a CNAME record in terms of Route53 charging?
A: You are charged for queries to CNAME records, but not for queries to ALIAS records. If possible, always prefer ALIAS over CNAME.

Q: If it is possible to use either ALIAS or CNAME records in a given scenario, which should you pick?
A: ALIAS, since queries to ALIAS are free (queries to CNAME are not).

Q: Many many domain names can you have in a single Route53 account?
A: 50 maximum by default, but it can be increased by contacting support.

Q: Many many hosted zones can you have in a single Route53 account?
A: 500 maximum by default, but it can be increased by contacting support.

SubTopic: Lab: Route 53 Register a Domain Name

Lab: Route 53 Register a Domain Name
Step: Note - don't do this lab unless you are willing to spend real money (at least $12).
Step: Note - it takes up to 3 days to complete the registration of a domain.
Step: Register a new domain.
Step: Wait for the e-mail address confirmation mail, and confirm it.
Step: Wait for the registration complete confirmation mail.
Step: Observe that a hosted zone has automatically been created.
Step: Do NOT clean up (you paid for it!)

Q: What does registering a .com domain cost at Amazon (basic usage)?
A: $12 per year for the registration, plus the $0.50 per month for the hosted zone, plus $0.40 per million queries.

Q: Is auto-renew automatically enabled for a domain name registered in AWS?
A: Yes.

Q: Is privacy-protection automatically enabled for a domain name registered in AWS?
A: Yes, and unlike GoDaddy, AWS does not charge extra for this.

Q: How long does it take to complete registering a domain name in Amazon?
A: Up to 3 days, but typically much shorter (less than an hour).

Q: What does Amazon automatically create after registering a domain name?
A: A hosted zone.

Q: What are the types of the two records in the automatically created hosted zone?
A: One SOA record, one NS record.

Q: What is the scope of Route53 registered domains?
A: Global.

Q: What is the scope of Route53 hosted zones?
A: Global.

Q: Name 5 routing policies in Route53.
A: Simple, weighted, latency, failover, geolocation. 

Q: What is a Route53 record set?
A: A set of DNS records of the same type.

Q: Why does the default NS record set for the hosted zone point to 4 name servers in different top-level domains?
A: For maximum redundancy.

Q: What is the default routing policy when you create a new record set.
A: The simple routing policy.

Q: How do you force Chrome to "empty cache and hard refresh" on a Mac (to test Route53 routing policies).
A: View developer tools, click on the refresh icon with two fingers on the trackpad, select "empty cache and hard refresh".

SubTopic: Lab: Setup Our EC2 Instance

Lab: Setup Our EC2 Instance
Step: Create one instance 
Step: ... in region us-west-2 (Oregon)
Step: ... named web-server-1-oregon
Step: ... with the bootscript from the resources (change X to web-server-1-oregon)
Step: ... with a security group that allows SSH, HTTP, and HTTPS.
Step: ... test the server using a browser
Step: Create one instance 
Step: ... in region us-west-2 (Oregon)
Step: ... named web-server-2-oregon
Step: ... with the bootscript from the resources (change X to web-server-1-oregon)
Step: ... with a security group that allows SSH, HTTP, and HTTPS.
Step: ... test the server using a browser
Step: Create an ELB classic load balancer
Step: ... in region us-west-2 (Oregon)
Step: ... named load-balancer-oregon
Step: ... with a health check for index.html,timeout 5, interval 10, unhealthy threshol 2, healthy threashold 3
Step: ... with both instances as members
Step: ... test the load balancer using a browser
Step: Create one instance 
Step: ... in region us-east-1 (Virginia)
Step: ... named web-server-1-virginia
Step: ... with the bootscript from the resources (change X to web-server-1-virginia)
Step: ... with a security group that allows SSH, HTTP, and HTTPS.
Step: ... test the server using a browser
Step: Create one instance 
Step: ... in region us-east-1 (Virginia)
Step: ... named web-server-2-virginia
Step: ... with the bootscript from the resources (change X to web-server-2-virginia)
Step: ... with a security group that allows SSH, HTTP, and HTTPS.
Step: ... test the server using a browser
Step: Create an ELB classic load balancer
Step: ... in region us-east-1 (Virginia)
Step: ... named load-balancer-virginia
Step: ... with a health check for index.html,timeout 5, interval 10, unhealthy threshol 2, healthy threashold 3
Step: ... with both instances as members
Step: ... test the load balancer using a browser
Step: Do NOT clean up YET; we use these instances for the other Route53 labs.

SubTopic: Lab: Simple Routing Policy

Lab: Simple Routing Policy
Step: Open the hosted zone for your domain name in the Route53 console
Step: Create a new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-oregon
Step: ... with routing policy simple
Step: ... and which has evaluate target health disabled.
Step: Use a browser to test the domain name.
Step: Clean up: delete the record set that we just created.
Step: Clean up: also clean up instances and load balancers in oregon and virginia if this was the last Route53 lab.

Q: How are requests routed by the Route53 simple routing policy?
A: You are only allowed to enter one target, and all requests are routed to it.

Q: What is the typical use case for the Route53 simple routing policy?
A: You have a single server that serves the content; it should receive all requests.

SubTopic: Lab: Weighted Routing Policy

Lab: Weighted Routing Policy
Step: Open the hosted zone for your domain name in the Route53 console
Step: Create a new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-oregon
Step: ... with routing policy weighted, weight 70, and set ID Oregon
Step: ... and which has evaluate target health disabled.
Step: Create another new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-virginia
Step: ... with routing policy weighted, weight 30, and set ID Virginia
Step: ... and which has evaluate target health disabled.
Step: Use a browser to test the domain name (be patient)
Step: Clean up: delete the record sets that we just created.
Step: Clean up: also clean up instances and load balancers in oregon and virginia if this was the last Route53 lab.

Q: How are requests routed by the Route53 weighted routing policy?
A: Send a fixed percentage of requests to each target.

Q: What is the typical use case for the Route53 weighted routing policy?
A: A/B testing, gradual roll out of new web features.

Q: Why does it seem that my weighted routing policy does not work?
A: The distribution happes mostly across clients. For a given client, it can take more than 5 minutes to switch to a different target because an upstream ISP caches the result.

Q: What does WRR stand for?
A: Weighted Round Robin.

Q: Does Route53 support WRR routing?
A: Yes, use the weighted routing policy.

SubTopic: Lab: Latency Routing Policy

Lab: Latency Routing Policy
Step: Open the hosted zone for your domain name in the Route53 console
Step: Create a new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-oregon
Step: ... with routing policy latency, region us-west-2, and set ID Oregon
Step: ... and which has evaluate target health disabled.
Step: Create another new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-virginia
Step: ... with routing policy latency, region us-east-2, and set ID Virginia
Step: ... and which has evaluate target health disabled.
Step: Use a browser to test the domain name and verify it goes to the closer load balancer.
Step: Use a VPN to connect to a place close to the other load balancer.
Step: Use a browser to test the domain name and verify it goes to the other load balancer.
Step: Clean up: delete the record sets that we just created.
Step: Clean up: also clean up instances and load balancers in oregon and virginia if this was the last Route53 lab.

Q: How are requests routed by the Route53 latency routing policy?
A: Send the requests to the target that provides the lowest latency from the user.

Q: What is the typical use case for the Route53 latency routing policy?
A: A/B testing, gradual roll out of new web features.

Q: What does LBR stand for?
A: Latency Based Routing?

Q: Does Route53 support LBR?
A: Yes, use the latency routing policy.

SubTopic: Lab: Failover Routing Policy

Lab: Latency Failover Policy
Step: Open the hosted zone for your domain name in the Route53 console
Step: Create a health check for the Oregon load balancer
Step: ... with name health-check-oregon
Step: ... checking an end-point
Step: ... checking the domain name of load-balancer-oregon
Step: ... for path /index.html
Step: ... with a fast check interval (10 seconds)
Step: ... with failure threshold of 1
Step: ... without an alarm
Step: Create a health check for the entire website
Step: ... with name health-check-website
Step: ... checking an end-point
Step: ... checking the domain name of the entire website
Step: ... for path /index.html
Step: ... with a fast check interval (10 seconds)
Step: ... with failure threshold of 1
Step: ... with an alarm for a new SNS topic website-down
Step: Note: the health check for the entire website will be unhealthy because we don't have any record sets yet.
Step: Create a new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-oregon
Step: ... with routing policy failover, primary target
Step: ... and which uses health check health-check-oregon
Step: Create another new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-virginia
Step: ... with routing policy failover, secondary target
Step: ... and which uses no health check
Step: Use a browser to test the domain name and verify it goes to Oregon (be patient)
Step: Stop (don't terminate, but stop) both Oregon EC2 instances
Step: Observe the health checks in Route53 and observe that Oregon is down
Step: Use a browser to test the domain name and verify it goes to Virginia now
Step: Stop (don't terminate, but stop) both Virginia EC2 instances
Step: Observe the health checks in Route53 and observe that the website is down
Step: Verify you get an alarm e-mal
Step: Verify the website is back up
Step: Clean up: restart all stopped instances
Step: Clean up: delete the record sets that we just created.
Step: Clean up: delete the health checks and the SNS topic
Step: Clean up: also clean up instances and load balancers in oregon and virginia if this was the last Route53 lab.

Q: How are requests routed by the Route53 failover routing policy?
A: Send all requests to the primary target by default. If the healthcheck for the primary fails, send all traffic to the secondary target.

Q: Does the Route53 failover routing policy check the health of the primary target only?
A: No, it is possible to also check the secondary target.

Q: What is the typical use case for the Route53 failover routing policy?
A: Any sitation where you can have only one target, but you want a failover backup.

SubTopic: Lab: Geolocation Routing Policy

Lab: Geolocation Failover Policy
Step: Create another new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-oregon
Step: ... with routing policy geolocation, for location Europe
Step: ... with ID oregon-serves-europe
Step: ... without a healthcheck
Step: Create another new record set
Step: ... for the naked domain name
Step: ... of type A
Step: ... which is an Alias
Step: ... which has target load-balancer-virginia
Step: ... with routing policy geolocation, for location Default
Step: ... with ID oregon-serves-everything-else
Step: ... without a healthcheck
Step: Use a browser to test from the US and verify it goes to Virginia
Step: Use a browser and VPN to test from the Europe and verify it goes to Oregon
Step: Clean up: delete the record sets that we just created.
Step: Clean up: also clean up instances and load balancers in oregon and virginia if this was the last Route53 lab.

Q: How are requests routed by the Route53 geolocation routing policy?
A: Allows you to configure which geographic regions are router to which target.

Q: What is the typical use case for the Route53 failover routing policy?
A: When the content served by a particular server is customized for a geographical region (language, currency, ...)

Topic: Databases on AWS

SubTopic: Databases 101

Q: What is a relational database?
A: A database that uses the relational model with tables, rows and columns. It typically supports ACID transactions.

Q: What does RDS stand for?
A: Relational Database System.

Q: What does ACID stand for?
A: Atomicity, Consistentency, Isolation, Durability.

Q: Name 6 popular relational database products?
A: Commercial: Microsoft SQL Server, Oracle. Open source: MySQL, MariaDB, PostgreSQL. Amazon-only: Aurora.

Q: What services does AWS offer for relational databases?
A: Relational Database Service (RDS), DynamoDB.

Q: What database engines does AWS RDS support?
A: Aurora, MySQL, MariaDB, PostgreSQL, Oracle, Microsoft SQL Server.

Q: What is the relational database service heavily pushed by AWS?
A: Aurora, which is their own.

Q: What does RDS stand for?
A: Relational Database Service.

Q: What is the typical structure of a non-relational database?
A: Collections containing Documents containing Key Value Pairs.

Q: What service does AWS offer for non-relational databases?
A: DynamoDB.

Q: What is a Data Warehouse (DW or DWH) aka Enterprise Data Warehouse (EDW)?
A: A centralized repository of integrated data from one or more disparate sources, storing current and historical data, used for analytical reporting and business intelligence.

Q: Name some commercial products for business intelligence.
A: IBM Cognos, Jaspersoft, SQL Server Reporting Services, Oracle Hyperion, SAP NetWeaver.

Q: What service does AWS offer for data warehousing?
A: Redshift.

Q: What does OLTP stand for?
A: On Transaction Processing.

Q: What type of transaction processing does a relational database provide?
A: On Line Transation Processing (OLTP).

Q: What does OLAP stand for?
A: On Line Analytics Processing.

Q: What type of transaction processing does a data warehouse provide?
A: On Line Analytics Processing (OLAP).

Q: What is the difference between OLTP and OLAP?
A: OLTP typically uses a large volume of fast and simple on-line transactions. OLAP typically uses a low volume of very complex transaction involving aggregation.

Q: What do caching products such as Redis and Memcached do?
A: In-memory (RAM) key-value stores that typically used as a cache in front of an on-disk database.

Q: What service does AWS offer for caching?
A: ElastiCache.

Q: Which caching engines does ElastiCache support?
A: Redis and memcached.

Q: What is the complete list of database services in AWS?
A: RDS, DynamoDB, ElastiCache, Neptune, Redshift.

Q: What service does RDS provide?
A: Relational database.

Q: What service does DynamoDB provide?
A: Non-relational database.

Q: What service does ElastiCache provide?
A: Caching.

Q: What service does Neptune provide?
A: Graph database.

Q: What service does Redshift provide?
A: Data warehousing.

SubTopic: Lab: Create our first RDS instance

Lab: Create our first RDS instance
Step: Launch a DB instance in RDS:
Step: ... engine = MySQL
Step: ... use case = dev/test (free tier)
Step: ... DB instance identifier = acloudguru
Step: ... Master user name = acloudguru
Step: ... Master password = acloudguru
Step: ... Publicly accessible = no
Step: ... Database name = acloudguru
Step: ... and default values for everything else.
Step: Launch an Amazon Linux t2.micro instance in EC2:
Step: ... with the bootstrap script from the ACG resources that installs Apache, PHP, PHP MySQL, and a demo webpage.
Step: ... a security group that allows SSH, HTTP, and HTTPS
Step: ... and default values for everything else.
Step: SSH into the EC2 instance.
Step: Verify that the bootstrap script ran succesfully:
Step: ... check that Apache is running,
Step: ... check that index.php and connect.php are present in /var/www/html.
Step: Open a browser and enter the IP address of the EC2 instance. Verify you see the PHP info page.
Step: On the browser go to <ec2-ip-address>/connect.php. Verify you get a "Unable to connect to MySQL" error.
Step: On the EC2 instance, edit /var/www/html/connect.php and replace yourhostnameaddress with the endpoint domain name of the DB instance.
Step: Fix the security group of the DB instance to allow the EC2 instance to connect to it:
Step: ... Make a note of the security group of the EC2 instance
Step: ... Add an inbound rule to the security group of the DB instance to allow MySQL traffic from the security group of the EC2 instance
Step: On the browser go to <ec2-ip-address>/connect.php again. Verify it works this time.
Step: Clean up: delete the DB instance, the EC2 instance, and the RDS security group.

Q: What is the typical cost of a default parameters dev/test MySQL database in RDS?
A: Approximately $15 per month (eligible for free tier).

Q: Can you use magnetic storage for MySQL?
A: No, only SSD (general purpose SSD or provisioned IOPS SSD).

Q: What port does MySQL use?
A: Port 3306.

Q: What port does Aurora use?
A: Port 3306.

Q: Does MySQL support encryption at rest?
A: Yes, not not on all instance types, typically only on the larger ones (e.g. not on t2.micro).

Q: What is a convenient place to see all security groups?
A: In the VPC console.

Q: How many DB instances are you allowed to create?
A: 40 DB instances per account by default, but it can be increased using a support request.

SubTopic: Lab: RDS - Back Ups, Multi-AZ, and Read Replicas

Lab: RDS - Back Ups, Multi-AZ, and Read Replicas
Step: Launch a DB instance in RDS:
Step: ... engine = MySQL
Step: ... use case = dev/test (free tier)
Step: ... DB instance identifier = acloudguru
Step: ... Master user name = acloudguru
Step: ... Master password = acloudguru
Step: ... Public accessibility = no
Step: ... Database name = acloudguru
Step: ... and default values for everything else.
Step: Wait 5 minutes.
Step: Look at the snapshot list and observe that there is an automated snapshot.
Step: Go to the UI for restoring the DB to a specific point in time (but don't actually do it).
Step: Take a manual snapshot of the DB instance.
Step: Create an encrypted copy of the non-encrypted snapshot that we just created.
Step: Restore the encrypted snapshot, created a new encrypted DB instance.
Step: Create a read replica for the DB instance acloudguru:
Step: ... Public accessibility = no
Step: ... DB instance identifier = acloudguru-replica-1
Step: ... and default values for everything else.
Step: Modify DB instance acloudguru to enable multi-AZ.
Step: Clean up: delete DB instances, snapshots, EC2 instances.

Q: What are the two types of backups in RDS?
A: Automated backup and snapshot backup.

Q: What is an RDS automated backup?
A: A automatic and continuous backup your DB instance.

Q: To what point in time does an automated backup allow you to recover your database?
A: To any point in time within the retention period, down to a second precision. 

Q: What is the allowed range for the retention period for automated backups in RDS?
A: Between 1 and 35 days.

Q: How does automated backup store the backup data?
A: It takes a daily full snapshot and stores transaction logs throughout the day.

Q: Does does recovery of an automated backup reconstruct the database to any point in time?
A: It recovers the most recent previous full snapshot and then applies the transaction log up to the desired point in time.

Q: Are RDS automated backups enabled or disabled by default?
A: Enabled with a default retention period of 7 days.

Q: Where is the backup data for RDS automated backups stored?
A: In S3?

Q: Do you have to pay for the storage for RDS automated backups?
A: Usually not (depends on how big the transaction log is). You get as much free S3 storage as the size of your database.

Q: When does the full snapshot for the RDS automated backup take place?
A: In the defined backup window for the DB instance (not to be confused with the maintenance window)

Q: How does taking a full snapshot for RDS automated backup affect availability and performance?
A: The DB instance remains available to clients. Disk I/O is suspended, transactions are queued, and transaction latency may increase.

Q: Are RDS automated backups retained after the DB instance is deleted?
A: No.

Q: What is an RDS snapshot?
A: A user-initiated snapshot of a DB instance at a specific point in time.

Q: Are RDS manual snapshots retained after the DB instance is deleted?
A: Yes.

Q: What happens to the original DB instance when you restore an automatic backup or manual snapshot?
A: It continues to exist as-is. The restoration creates a new DB instance with a new DNS endpoint.

Q: Does RDS support encryption at rest of a DB instance?
A: Yes, for all DB engines.

Q: How does RDS manage keys for DB encryption?
A: Using the AWS Key Management Service (KMS).

Q: If the DB instance is encrypted, what about backups?
A: Underlying storage, automated backups, manual snapshots, and read replicas are all also encrypted.

Q: Can you encrypt an already running DB instance?
A: Currently, no. You must enable encryption at creation time. Or you can create a snapshot, copy it, encrypt the copy, and restore it.

Q: What is Multi-AZ in RDS?
A: Synchronously replicate changes to the primary DB instance in one AZ to a standby DB instance in another AZ in the same region.

Q: What is the use case for Multi-AZ in RDS?
A: Disaster recovery.

Q: What happens if the primary DB instance fails in Multi-AZ?
A: The clients are automatically switched over to the standby DB instance.

Q: What mechanism does AWS use to switch from the primary to the standby DB instance in Muti-AZ.
A: It automatically updates the DNS name for the DB instance endpoint. 

Q: Why do you never use an IP address for an DN instance endpoint?
A: You use a DNS name because it is automatically updated to the standby DB instance in case of a failure when Multi-AZ is enabled.

Q: With Multi-AZ, how close (how similar) is the data in the standby DB instance to the data in the primary DB instance?
A: It is an exact copy, the replication is synchronous.

Q: What RDS mechanism do you use for disaster recovery?
A: Multi-AZ.

Q: Does Multi-AZ improve performance?
A: No, use read replicas for that.

Q: For which RDS database types is Multi-AZ available?
A: All of them (technically not for Aurora, but the same functionality is implemented otherwise)

Q: What is an RDS read replica?
A: Asynchronously replicates changes to a primary DB instance to one or more replica DB instances, and directs reads to the replicas for improved read performance.

Q: How many read replicas can a DB instance have?
A: Up to 5.

Q: What RDS mechanism do you use for improving performance?
A: Read replicas.

Q: Can read replicas be used for disaster recovery?
A: No, use Multi-AZ for that.

Q: Is it possible to chain read replicas (have a read replica of a read replica)?
A: Yes, but it increases replication latency.

Q: Does the read replica have to be in same region as the DB instance from which it is replicated?
A: No, it can be in a different region.

Q: With read replicas, how close (how similar) is the data in the replica DB instance to the data in the primary DB instance?
A: It is close, but not an exact copy; the replication is asynchronous.

Q: For which database engines is read replicas available?
A: Available for MySQL, PostgreSQL, MariaDB, Aurora. Not available for Oracle and SQL Server.

Q: What is a pre-condition for enabling read replicas?
A: Automatic backups must be enabled.

Q: How does an RDS application chose whether it reads from the primary or a read replica?
A: Each replica has its own DNS endpoint.

Q: Can Multi-AZ be enabled for a replica?
A: Yes (this is a very recent feature).

Q: Can you enable read replicas for a primary DB instance that has Multi-AZ enabled?
A: Yes.

Q: What does promotion of a read replica mean?
A: It means turning a read replace into a fully stand-alone instance DB, which stops the replication.

SubTopic: Lab: DynamoDB

Lab: DynamoDB
Step: Create a DynamoDB table:
Step: ... Table name = students
Step: ... Primary key, partition key = StudentId (number)
Step: ... Disable auto-scaling
Step: ... Read capacity unit = 1
Step: ... Write capacity units = 1
Step: ... Leave everything else as default value.
Step: Create an item in the table:
Step: ... StudentId = 100
Step: ... FirstName (string) = John
Step: ... LastName (string) = Smith
Step: Create another item in the table:
Step: ... StudentId = 100
Step: ... FirstName (string) = Jane
Step: ... LastName (string) = Rogers
Step: ... Age (number) = 16
Step: Scan the table with filter LastName = Smith
Step: Remove the filter and show the whole table again
Step: Have a look at the metrics and see how the actual capacity compares to the provisioned capacity.
Step: Clean up: delete the table.

Q: What is AmazonDB?
A: It is the no-SQL (non-relational) database service provided by AWS.

Q: What data models does AmazonDB support?
A: Document and key-value.

Q: Can a DynamoDB be stored on magnetic storage?
A: No, only on SSD.

Q: Use a DynamoDB spread over multipe AZs?
A: Amazon does not use that language exactly; they say "across 3 geographically distinct data centers".

Q: What consistency models does DynamoDB support?
A: Eventual consistent reads (the default) and strongly consistent reads.

Q: Which consistency model in DynamoDB has the best performance?
A: Eventual consistent reads.

Q: What does eventual consistent reads consistency mean in DynamoDB?
A: After a write, read may return the old data for some time, but eventually return the new data.

Q: How long does it take for the data to become consistent in the DynamoDB eventual consistent reads model?
A: Usually within a second.

Q: What does strongly consistent reads consistency mean in DynamoDB?
A: After a write that received a succes response, a read will always return the new data, no matter how fast the read is after the completed write.

Q: DynamoDB pricing depends on which metrics?
A: Provisioned throughput capacity, used storage capacity, 

Q: Is there a difference in pricing for reading vs writing DynamoDBs?
A: Writing is 5x more expensive than reading.

Q: What is reserved capacity in DynamoDB
A: You enter into a 1 or 3 year contract to purchase DynamoDB capacity in advance at a greatly reduced price.

Q: Can you change the provisioned capacity of a DynamoDB table on the fly?
A: Yes.

Q: What does "push-button scaling" mean in DynamoDB?
A: You can increase the scaling of a DynamoDB database, without downtime, and without limits.

SubTopic: Redshift

Q: What service does Redshift provide?
A: Data warehousing and Online Analytics Processing (OLAP).

Q: What are the two possible configurations for Redshift?
A: Single node or multi-node.

Q: What is the size of a single node Redshift configuration?
A: Up to 160GB.

Q: What types of nodes exist in a multi-node Redshift configuration?
A: Leader node, compute node.

Q: What does the leader node do in a multi-node Redshift configuration?
A: Manage client connections and process queries.

Q: What does a compute node do in a multi-node Redshift configuration?
A: Store data, perform queuries and computations.

Q: How many compute nodes can there be in a multi-node Redshift configuration?
A: Up to 128.

Q: Why is the architecture for OLAP databases different than the architecture for OLTP databases?
A: OLTP tends to process many fields for one record, OLAP tends to process one field for many records.

Q: What is columnar data storage in Redshift?
A: Columns (rather than rows) are stored sequentially on disk, for faster OLAP processing.

Q: What is advanced compression in Redshift?
A: Columns (rather than rows) are stored sequentially on disk, for more similar data and hence better compression.

Q: What is Massively Parallel Processing (MPP) in Redshift?
A: Redshift automatically distributes a complex query across many compute nodes, resuling in faster query response time.

Q: Redshift pricing depends on which metrics?
A: Compute node hours, backups, data transfer within a VPC (not outside)

Q: In multi-node Redshift, are you charged for the leader node?
A: No, only for the compute nodes.

Q: How is Redshift data in-transit secured?
A: SSL

Q: How is Redshift data at-rest secured?
A: AES-256 encryption

Q: Who manages the keys for Redshift at-rest encryption?
A: By default, Redshift. Or you can manage your own keys using HSM or KMS.

Q: Can Redshift be distributed across multiple AZs for high availability?
A: Currently not.

Q: What can you do if the AZ in which you run Redshift goes down?
A: You can restore the Redshift snapshot to another AZ.

Q: What is a Redshift cluster.
A: A group of nodes.

SubTopic: Elasticache

Q: What service does Elasticache provide?
A: In-memory caching, to improve the performance of on-disk databases.

Q: What type of application is most suited for Elasticache?
A: Read-heavy applications that require high read throughput and low read latency, and where the data does not change often.

Q: What two caching engines are available in Elasticache?
A: Memcached and Redis.

Q: What mechanism does Elasticache Redis provide for multi-AZ high availability?
A: Master / Slave replication across multiple AZs.

Q: How do Memcached and Redis compare in terms of redundancy?
A: Redis provides multi-AZ redundancy using master / slave replication. Memcached does not.

Q: What Amazon services would you consider if the database is stressed due to heavy OLTP reads?
A: Elasticache or RDS read replicas or DynamoDB.

Q: What Amazon service would you use if the database is stressed due to heavy OLAP reads?
A: Redshift.

SubTopic: Lab: Aurora

Lab: Aurora
Step: Note this is an expensive lab, up to $5, not covered by free tier.
Step: Launch an Aurora DB instance:
Step: ... DB instance class = db.r3.large
Step: ... Multi-AZ deployment = no
Step: ... DB instance identifier = acloudguruaurora
Step: ... Master username = acloudguruaurora
Step: ... Master password = acloudguruaurora
Step: ... Failover priority = Tier-0
Step: ... DB cluster identifier = acloudguru-cluster
Step: ... Database name = acloudguruaurora
Step: ... defaults for everything else.
Step: Create an Aurora replica:
Step: ... Aurora replica source = acloudguruaurora
Step: ... DB instance identifier = acloudguru-replica
Step: ... Failover priority = Tier-1
Step: ... defaults for everything else.
Step: Manually force a failover.

Q: Who created Aurora?
A: Amazon did. It is only available as an AWS service. It is not an open source project.

Q: Is Aurora compatible with MySQL?
A: Yes. You can import a MySQL database into Aurora. An application can communicate with Aurora using the MySQL APIs and protocols.

Q: What are the minimum size and maximum size for Aurora storage?
A: It starts at 10GB and grows upto 6TB in 10GB increments.

Q: Do you manually manage the disk storage resources for an Aurora database?
A: No, it auto-scales.

Q: What are the maximum compute resources for an Aurora database?
A: Up to 32 vCPUs and 224GB of RAM.

Q: Do you manually manage compute resources for an Aurora database?
A: Yes. You manually change them and there are a few minutes of downtime when you do.

Q: How does Aurora replicate your data?
A: Two copies in each AZ, across at least 3 AZs, for a total of 6 copies.

Q: Does the fact that there are 6 copies of the data mean that Aurora is highly available?
A: It is not sufficient. The engine still run in a virtual machine which is a single point of failure. Create replicas to avoid this.

Q: How many failures can Aurora sustain?
A: Loss of 2 copies without affecting write availability, loss of 3 copies without affecting read availability.

Q: What does it mean that Aurora storage is self-healing?
A: Data blocks and disks are automatically and continuously scanned for errors and repaired automatically.

Q: What are the two types of replicas in Aurora?
A: Aurora replicas and MySQL read replicas.

Q: What is an Aurora replica?
A: A separte Aurora database which replicates a primary Aurora database.

Q: What is the maximum number of Aurora replicas?
A: 15.

Q: What is a MySQL read replica in Aurora?
A: A MySQL database instance which replates a primary Aurora database.

Q: What is the maximum number of MySQL replicas in Aurora?
A: 5.

Q: What is the key difference between an Aurora replica and an MySQL read replica in Aurora?
A: Failover is automatic for an Aurora replica, but not for a MySQL read replica.

Q: Is Aurora available in all regions?
A: No, it is only available in certain regions.

Q: What is an Aurora failover tier?
A: When the master DB instance fails, the standby DB instance with the lowest failover tier value becomes the new master.

Q: How long does it take to create a new Aurora database?
A: A long time, up to 5 minutes.

Q: What replication roles exist in Aurora?
A: Writer and reader.

Q: What is the difference between the cluster endpoint and the instance endpoint in Aurora?
A: There is only one cluster endpoint and it fails over automatically. Use the instance endpoint for reading from a specific read replica.

Topic: VPC

SubTopic: VPC Intoduction and Overview

Q: What does VPC stand for?
A: Virtual Private Cloud.

Q: What is a good metaphor for a VPC?
A: A virtual data center.

Q: You have one default VPC for every what?
A: For every region.

# TODO: I think all the topics discussed around offset 5:00 will be discussed in much greater detail later, so no questions yet

Q: Which prefixes does Amazon recommend you to use for subnets?
A: 10/8, 172.16/12, 192.168/16

Q: What is the maximum number of VPCs?
A: 5 per region by default, but it can be increased with a support request.

Q: What is the scope of a VPC?
A: A region.

Q: What is a subnet?
A: A network abstraction with an IP prefix (IP address range).

Q: What is the maximum number of subnets?
A: 200 per VPC by default, but it can be increased with a support request.

Q: Can a subnet span multiple AZs?
A: No.

Q: What are EC2 instances attached to, from a networking point of view?
A: Subnets.

Q: A subnet is contained in what, from a networking point of view?
A: In a VPC.

Q: What is the smallest (most specific) prefix AWS allows for a subnet?
A: /28

Q: How to you direct the flow of traffic between subnets?
A: With route tables.

Q: How do you connect a VPC to the Internet?
A: Using an Internet Gateway?

Q: What is an Internet Gateway?
A: It connects a VPC to the Internet.

Q: How many Internet Gateways can you have per VPC?
A: One.

Q: Is an Internet Gateway a single point of failure?
A: No, it is highly available and spread across all AZs the region.

Q: What is the scope of an Internet Gateway?
A: A region. It spans all AZs within that region.

Q: What is a security group?
A: A virtual stateful layer-4 firewall attached to EC2 instances.

Q: Can a security group span multiple AZs?
A: Yes.

Q: Can a security group span multiple subnsets?
A: Yes.

Q: Is a security group stateful or stateless?
A: Stateful.

Q: What do security groups protect?
A: EC2 instances.

Q: What does it mean for a security group to be stateful?
A: If an inbound rule allows a flow, the outbound reverse flow is automatically also allowed, even if there is no explicit rule. And vice versa.

Q: What is a Network Access Control List (NACL)?
A: A virtual stateless layer-4 firewall attached to subnets.

Q: What do NACLs protect?
A: Subnets.

Q: What does NACL stand for?
A: Network Access Control List.

Q: Is a NACL stateful or stateless?
A: Stateless.

Q: What is a route table?
A: A virtual layer-3 route table.

Q: What is the difference between a default VPC and a custom VPC in terms of how they are created?
A: AWS automatically creates one default VPC per region. You manually create custom VPCs.

Q: What is the difference between a default VPC and a custom VPC in terms of Internet reachability.
A: Default VPCs automatically have a default route to the Internet. In custom VPCs, you have to add one explicitly.

Q: What is VPC peering?
A: Connect one VPC to another VPC.

Q: Can VPC peering connect to a VPC owned by a different AWS account?
A: Yes.

Q: Can VPC peering be transitive (A -> B -> C)?
A: No.

SubTopic: Lab: Build your own custom VPC.

Lab: Build your own custom VPC.
Step: Go to the VPC console in the Oregon region.
Step: Create a VPC without using the wizard:
Step: ... Name tag = vpc-1
Step: ... IPv4 CIDR block = 10.0.0.0/16
Step: ... IPv6 CIDR block = Amazon provided
Step: ... everything else default.
Step: Create a subnet:
Step: ... Name tag = vpc-1-subnet-dmz
Step: ... VPC = vpc-1
Step: ... Availability Zone = us-west-2a
Step: ... IPv4 CIDR block = 10.0.1.0/24
Step: ... IPv6 CIDR block = Specify a custom IPv6 CIDR: 01
Step: Create a subnet:
Step: ... Name tag = vpc-1-subnet-backend
Step: ... VPC = vpc-1
Step: ... Availability Zone = us-west-2b
Step: ... IPv4 CIDR block = 10.0.2.0/24
Step: ... IPv6 CIDR block = Specify a custom IPv6 CIDR: 02
Step: Create an Internet gateway with name vpc-1-igw
Step: Attach Internet gateway vpc-1-igw to VPC vpc-1
Step: Edit the name of the main route table for VPC vpc-1 to be vpc-1-route-table-main
Step: Create a route table:
Step: ... Name tag = vpc-1-route-table-internet
Step: ... VPC = vpc-1
Step: Add an IPv4 default route to route table vpc-1-route-table-internet:
Step: ... Destination = 0.0.0.0/0
Step: ... Target = vpc-1-igw
Step: Add an IPv6 default route to route table vpc-1-route-table-internet:
Step: ... Destination = ::0/0
Step: ... Target = vpc-1-igw
Step: Associate subnet vpc-1-subnet-dmz with route table vpc-1-route-table-internet
Step: Enable auto-assign public IPv4 and IPv6 address for subnet vpc-1-subnet-dmz
Step: Launch an EC2 instance:
Step: ... AMI = Amazon Linux
Step: ... Instance type = t2.tiny
Step: ... Network = vpc-1
Step: ... Subnet = vpc-1-subnet-dmz
Step: ... Tag = Name: vm-web-server
Step: ... Create a new security group vpc-1-security-group-web-server that allows SSH, HTTP, and HTTPS
Step: Launch an EC2 instance:
Step: ... AMI = Amazon Linux
Step: ... Instance type = t2.tiny
Step: ... Network = vpc-1
Step: ... Subnet = vpc-1-subnet-backend
Step: ... Tag = Name: vm-db-server
Step: ... Security group = vpc-1-security-group-web-server
Step: ... Create a new keypair = keypair-brunorijsmanaws1-oregon-temporary
Step: Observe that vm-web-server gets a public IP address, but vm-2-private does not.
Step: SSH into vm-web-server. It works.
Step: Do a yum update to prove Internet connectivity. It works.
Step: Create a security group vpc-1-security-group-db-server that allows SSH, HTTP, HTTPS, MYSQL, and ICMP from subnet vpc-1-subnet-public only.
Step: Attach EC2 instance vm-db-server to the newly created security group vpc-1-security-group-db-server
Step: Verify that vm-web-server can ping vm-db-server
Step: Copy and paste the private key file for keypair-brunorijsmanaws1-oregon-temporary to ~/.ssh on vm-web-server and change permissions
Step: Verify that vm-web-server can SSH to vm-db-server
Step: Try a "sudo yum update" on vm-db-server (I does not work)
Step: Do not clean up: continue with lab "Network Address Translation (NAT) instance"

Q: Can you choose your own IPv4 CIDR block for a VPC?
A: Yes.

Q: Do VPCs support IPv6?
A: Yes.

Q: Is IPv6 enabled by default for VPCs?
A: No, it is disabled by default.

Q: Can you choose your own IPv6 CIDR block for a VPC?
A: No, Amazon assigns a /56 IPv6 CIDR block for you.

Q: What is the difference between default tenancy and dedicated tenancy?
A: Dedicated means that EC2 instances always use dedicated hadrware, regardless of what the EC2 instance tenancy says.

Q: What other objects are automatically also created when you create a VPC?
A: One route table, one Network Access Control List (NACL), and one security group.

Q: Is AZ us-east-1a in your account the same AZ as AZ us-east-1a in my account?
A: No, AZ names are randomized to avoid oversubscription of the first one (...-1a).

Q: Can you choose your own IPv4 CIDR block for a subnet?
A: Yes, as long as it is a subnet of the VPC CIDR block.

Q: Can you choose your own IPv6 CIDR block for a subnet?
A: Not quite, Amazon will select a /64 IPv6 CIDR for you that is a subnet of the VPC IPv5 CIDR, but you can choose one byte.

Q: What IP addresses in the subnet CIDR block are reserverd, and what for?
A: .0 network, .1 default router, .2 DNS server in primary subnet, .3 future use, .255 network broadcast (not supported, hence reserved).

Q: When you create an Internet gateway, to which VPC is it attached by default?
A: To none, it is detached by default, you have to explicitly attach it to a VPC.

Q: Can an Internet gateway be attached to multiple VPCs?
A: No.

Q: How many Internet gateways can be attachd to a VPC?
A: Zero or one.

Q: When you attach an Internet gateway to a VPC, does that automatically add a default route to the route table?
A: No, you have to manually add a default route (IPv4 and/or IPv6).

Q: What is a main route table?
A: The route table that was automatically created when the VPC was created. It has "Main = yes" in the summary.

Q: What does it mean if the target of a route in the route table is set to local?
A: Traffic is sent to a subnet associated with the route table.

Q: What route table is a subnet associated with by default if your don't create an explicit association?
A: With the main route table of the VPC.

Q: If a route table has a default route pointing to the Internet gateway, will all associated subnets be able to reach the Internet?
A: Yes.

Q: What if you only want certain subnets in a VPC to be able to reach the Internet?
A: Create a separate route table, add a default route to that route table, and associate the desired set of subnets with that route table.

Q: For automatically created default subnets, what is the default setting for auto-assign public IP address?
A: Yes (enabled) for IPv4 only (not for IPv6)

Q: For manually created custom subnets, what is the default setting for auto-assign public IP address?
A: No (disabled) for both IPv4 and IPv6.

Q: How to you enable auto-assign public IP addresses (IPv4 and/or IPv6) for a manually created custom subnet?
A: Using the Subnet Actions -> Modify auto-assign IP settings. Confusingly, it is not a field in the create subnet form.

Q: Do security groups span VPCs?
A: No, security groups are scoped within a VPC.

SubTopic: Lab: Network Address Translation (NAT)

Lab: Network Address Translation (NAT) instance
Step: This is a continuation of lab "Build your own custom VPC".
Step: Launch a NAT instance:
Step: ... Network = vpc-1
Step: ... Subnet = vpc-1-subnet-dmz
Step: ... Name tag = vm-nat
Step: ... Security group = vpc-1-security-group-web-server
Step: Disable source / destination check for instance vm-nat.
Step: Add a default route to the main route table for vpc-1, pointing to the NAT instance
Step: SSH into vm-web-server, and then SSH into vm-db-server
Step: Do a "sudo yum update -y". Now it works.
Step: Terminate the vm-nat instance.
Step: Do not clean up: continue with lab "Network Address Translation (NAT) gateway"

Lab: Network Address Translation (NAT) gateway
Step: This is a continuation of lab "Network Address Translation (NAT) instance".
Step: Create a NAT gateway:
Step: ... Subnet = vpc-1-subnet-dmz
Step: ... Create New Elastic IP
Step: Wait for the NAT gateway to become available (takes up to 15 minutes).
Step: In route table vpc-1-route-table-main, change the default route to point to the NAT gateway.
Step: On vm-db-server, verify that "sudo yum update -y" works.
Step: Do not clean up: continue with lab "Network Access Control Lists (NACL)"

Q: What are the two mechanisms for NAT?
A: NAT instance and NAT gateway.

Q: Which NAT mechanism is deprecated?
A: NAT instances; they are being replaced by NAT gateways.

Q: What does NAT stand for?
A: Network Address Translation.

Q: What is a typical use case for NAT?
A: Give EC2 instances on private subnets outbound access to the public Internet.

Q: What is source / destination check?
A: Only allow traffic whose source or destination address is the IP address of the EC2 instance.

Q: What must you not forget to do after you launch a NAT instance?
A: Disable source / destination check.

Q: What subnet should you put a NAT instance in?
A: A public subnet; the NAT instance needs to be reachable from the public Internet.

Q: How should routing be configured for a NAT instance?
A: The route table for the private subnets that want outbound reachability to the Internet should have a default route to the NAT instance.

Q: Why do you need to disable source / destination check for NAT instances?
A: Because it is forwarding traffic on behalf of other EC2 instances.

Q: What happens if a NAT instance fails?
A: You lose Internet connectivity; the NAT instance is a single point of failure and a throughput bottleneck (unless you use complex scripts).

Q: What is the difference between a NAT gateway and an Egress Only Internet Gateway?
A: A NAT gateway is for IPv4, an Egress Only Internet Gateway is for IPv6 (which doesn't need NAT).

Q: What would you use instead of a NAT gateway for IPv6?
A: An Egress Only Internet Gateway.

Q: Is a NAT gateway a single point of failure?
A: No, NAT gateways are highly available with redundancy within a single AZ but not across AZs.

Q: Do NAT gateways span AZs?
A: No. For high availability across AZs, you need to instantiate a NAT gateway in each AZ.

Q: How should routing be configured for a NAT gateway?
A: The route table for the private subnets that want outbound reachability to the Internet should have a default route to the NAT gateway.

Q: Can you use a NAT gateway as a bastion server?
A: No, use a NAT instance for that.

Q: What is the difference between a NAT instance and NAT gateway in terms of patching and upgrading?
A: You are responsible for patching and upgrading NAT instances. Amazon is responsible for patching and upgrading NAT gateways.

Q: What is the difference between a NAT instance and NAT gateway in terms of bandwidth.
A: The bandwidth of a NAT instance depends on the instance type. A NAT gateway supports bursts of up to 10Gbps.

Q: What is the difference between a NAT instance and NAT gateway in terms of security groups?
A: You associate a security group with a NAT instance. You do not associate a security group with a NAT gateway (associate it with the resources behind the NAT gateway instead.)

SubTopic: Lab: Network Access Control Lists (NACL)

Lab: Network Access Control Lists (NACL)
Step: This is a continuation of lab "Network Address Translation (NAT) gateway".
Step: Create a NACL:
Step: ... Name tag = vpc-1-nacl-dmz
Step: ... VPC = vpc-1
Step: Observe that by default all inbound and outbound traffic is denied.
Step: Associate NACL vpc-1-nacl-dmz with subnet vpc-1-subnet-dmz.
Step: Observe that we cannot ping or SSH to vm-web-server anymore.
Step: Add an inbound rule to NACL vpc-1-nacl-dmz to allow ICMP.
Step: Observe that we still cannot ping or SSH to vm-web-server anymore.
Step: Add an outbound rule to NACL vpc-1-nacl-dmz to allow ICMP.
Step: Observe that we can ping vm-web-server, but we can still not SSH to it.
Step: Add both an inbounad and outbound rule to NACL vpc-1-nacl-dmz to allow SSH.
Step: Observe that we still cannot (!) SSH into vm-web-server.
Step: Clean up. There is no continuation for this lab.

Q: What is the difference between a Security Group and a NACL in terms of statefulnes?
A: A Security Group is stateful, a NACL is stateless.

Q: What is the difference between a Security Group and a NACL in terms of what they protect?
A: A Security Group protects EC2 instances (first level of defence), a NACL protects subnets (second level of defence).

Q: What is the difference between a Security Group and a NACL in terms of types of rules?
A: A Security Group only has allow rules, a NACL has allow and deny rules.

Q: What is the difference between a Security Group and a NACL in terms of rule ordering?
A: A Security Group always applies all rules, a NACL applies rules in a numbered order and stops at the first matching rule.

Q: What is the difference between a Security Group and a NACL in terms of which EC2 instances they apply to?
A: A Security Group has to be excplitly associated with an EC2 instance, a NACL applies to all EC2 instances attached to the subnet.

Q: What is the difference between a Security Group and a NACL in terms of default bevavior?
A: Both an empty Security Group and an empty NACL deny everything by default. However, the default NACL for VPC comes pre-populated with allow-everything rules.

Q: Can you associate a subnet with multiple NACLs?
A: No, it can only be associated with a single NACL.

Q: Can you have a subnet that is not associated with a NACL?
A: No, every subnet must have exactly one NACL associated with it. If you don't choose one explicitly, the subnet is associated with the VPC's default NACL.

Q: Can you associate a single NACL with multiple subnets?
A: Yes.

Q: Which NACLs are created automatically and what is their default behavior?
A: One NACL is automatically created for each VPC. It allows all inbound and outbound traffic.

Q: What common mistake in NACL configuration prevents client-server TCP connections from working?
A: Add a custom TCP rule allowing ephemeral ports (1024-65535) for inbound and/or outbound traffic depending on which side the client is.

Q: In what order are the rules in a NACL applied?
A: In numerical order, lowest number first, stopping at the first match.

Q: For inbound traffic, which is applied first: the Security Group or the NACL?
A: NACL first, it is associated with the subnet.

Q: For outbound traffic, which is applied first: the Security Group or the NACL?
A: Security Group first, it is associated with the EC2 instance.

Q: If you want to block a specific block of IP addresses, would you use a Security Group or NACL?
A: NACL.

SubTopic: Custom VPCs and ELBs

Q: Can you attach a load balancer to a single subnet?
A: No, it is mandatory to attach it to at least two subnets (and hence two AZs) to achieve high availability.

Q: Can you attach a load balancer to a private subnet?
A: No, the subnet must be public, i.e. it must have an Internet Gateway.

SubTopic: Lab: VPC Flow Logs

Lab: VPC Flow Logs
Step: Create an EC2 instance:
Step: ... Name = vm
Step: ... Security group = new group security-group-web-server-oregon, allowing SSH, HTTP, HTTPS, and ICMP.
Step: Create a log group with name log-group
Step: Create a flow log for the default VPC
Step: Generate some traffic to and from EC2 instance vm (e.g. ping, ssh, yum update, yum install, etc.)
Step: What for a log stream to appear.
Step: Observe the traffic flows in the log stream.
Step: Clean up.

Q: What is VPC Flow Logs?
A: Capture IP traffic flow information in a log that can be viewed using CloudWatch Logs.

Q: At what three levels can VPC Flow Logs be created?
A: At the VPC level, at the subnet level, at the interface level.

Q: Can Flow Log also log the rejected flow, or only the accepted flows?
A: It can do both, you choose when you create the flow log.

Q: What can you stream flow logs to?
A: To AWS Lamba and AWS Elastic Search to real-time analysis of the flows.

Q: Can you create a flow log for a VPC that is peered with your VPC?
A: Only if that VPC is in your account.

Q: Can you tag a flow log?
A: No (not yet).

Q: Can you change the configuration of a flow log after you have created it?
A: No.

Q: Which traffic is NOT monitered by flow log?
A: Traffic to the Amazon DNS server, Windows license traffic, Metadata traffic to 169.254.169.254, traffic to the default VPC router.

SubTopic: NATs vs Bastions

Q: Does a NAT instance allow inbound TCP connections from the Internet to an EC2 instance behind the NAT?
A: No, only outbound TCP connections can be initiated from the EC2 instance.

Q: Does a bastion server allow inbound SSH or RDP session from the Internet to an EC2 instance behind the bastion server?
A: Yes, indirectly. First SSH/RDP to the bastion server, and then from there SSH/RDP to the EC2 instance behind it.

Q: Should a bastion server be in a public or a private subnet?
A: The bastion server itself should be in a public subnet, the EC2 instances behind it should be in a private subnet.

Q: Should the EC2 instances behind a bastion server be in a public or a private subnet?
A: The EC2 instances behind it should be in a private subnet, the bastion server itself should be in a public subnet.

Q: What is another word for a bastion server?
A: Jump box.

Q: What is another word for a jump box?
A: Bastion server.

Q: What is the advantage of using a bastion server?
A: You only have to harden one server, the bastion server, instead of all EC2 instances.

Q: How do you make a bastion server highly available?
A: Multiple instances, each in a different AZ (subnet), potentially auto-scaling group to keep a minimum number up, Route53 health-checks.

SubTopic: Lab: VPC Endpoints

Lab: VPC Endpoints
Step: Create a role named role-ec2-full-access-to-s3 that provides EC2 full access to S3.
Step: Create an s3 bucket named bucket-bruno-rijsman-test
Step: Create a VPC:
Step: ... Name tag = vpc-1
Step: ... CIDR block = 10.0.0.0/16
Step: Create a subnet:
Step: ... Name tag = vpc-1-subnet-public
Step: ... VPC = vpc-1
Step: ... Availability zone = us-west-2a
Step: ... CIDR block = 10.0.1.0/24
Step: Modify Auto-assign Public IP for subnet vpc-1-subnet-public to yes for IPv4.
Step: Create a subnet:
Step: ... Name tag = vpc-1-subnet-private
Step: ... VPC = vpc-1
Step: ... Availability zone = us-west-2b
Step: ... CIDR block = 10.0.2.0/24
Step: Create an Internet Gateway:
Step: ... Name tag = vpc-1-internet-gateway
Step: Attach the Internet Gateway to VPC vpc-1
Step: Create a Route Table:
Step: ... Name tag = vpc-1-route-table-internet
Step: ... VPC = vpc-1
Step: Add a route to Route Table vpc-1-route-table-internet
Step: ... Destination = 0.0.0.0/0
Step: ... Target = vpc-1-internet-gateway
Step: Associate Route Table vpc-1-route-table-internet with subnet vpc-1-subnet-public
Step: Create an EC2 instance:
Step: ... Network = vpc-1
Step: ... Subnet = vpc-1-public
Step: ... Role = role-ec2-full-access-to-s3
Step: ... Name tag = vm-public
Step: ... Security group = create new vpc-1-security-group (allows SSH, HTTP, HTTPS, ICMP)
Step: ... Keypair = brunorijsmanaws1-oregon
Step: Create an EC2 instance:
Step: ... Network = vpc-1
Step: ... Subnet = vpc-1-private
Step: ... Role = role-ec2-full-access-to-s3
Step: ... Name tag = vm-private
Step: ... Security group = vpc-1-security-group
Step: ... Keypair = brunorijsmanaws1-oregon-temporary
Step: Turn vm-public into a jump server for vm-private
Step: SSH into vm-public and list all S3 buckets using the "aws s3 ls --region us-west-2" (it works).
Step: SSH into vm-private using vm-public as a jump server and attempt to list all S3 buckets using "aws s3 ls --region us-west-2" (it does not work).
Step: Create a VPC Endpoint:
Step: ... Service category = AWS Services
Step: ... Service name = com.amazonaws.us-west-2.s3
Step: ... Type = gateway
Step: ... VPC = vpc-1
Step: ... Configure Route Table = route table associated with vpc-1-subnet-private
Step: ... Policy = Full access
Step: Observe that the route table vpc-1-route-table-main now contains a "service route (pl-xxx)" to the end point (vpce-xxx)
Step: SSH into vm-private using vm-public as a jump server and attempt to list all S3 buckets using the "aws s3 ls --region us-west-2" (now it does work).
Step: Clean up

Q: What is a VPC endpoint
A: A virtual gateway that allows EC2 instances to access other AWS services (e.g. S3) without going over the public Internet (e.g. via a NAT gateway or Internet gateway).

Q: What are the two types of VPC Endpoints?
A: Interface Endpoints and Gateway Endpoints

Q: What is an Interface Endpoint?
A: An Elastic Network Interface (ENI) that is directly attached to S3 instances and that serves as a service entry point.

Q: What is a Gateway Endpoint?
A: A gateway that serves as a service entry point; you must create a route in a route table that points to it.

Q: What does ENI stand for?
A: Elastic Network Interface.

Topic: Application Services

SubTopic: Simple Queue Service (SQS)

Q: What does SQS stand for?
A: Simple Queue Service.

Q: What service does SQS provide?
A: A distribute message queue that allows application components to reliably queue messages to each other.

Q: What was the first AWS service?
A: SQS

Q: Is SQS pull-based or push-based.
A: Pull-based, it uses polling.

Q: Which service would you use if you want a push-based message queueing service?
A: Simple Notification Services (SNS) or Message Queue (MQ).

Q: What is the SNS visibility time-out window?
A: When a message is delivered to a consumer, it is marked invisible. If the consumer fails to process it within the timeout, it is marked visible again and re-delivered.

Q: What is the maximum visbility time-out?
A: 12 hours.

Q: What is the main purpose of SQS in terms of application systems architecture?
A: Decouple the components of an application from each other, so that they can run independently.

Q: What is the maximum size of an SQS message?
A: The maximum size is configurable per queue between 1024 bytes and 256K. 

Q: What kind of data does an SQS message contain?
A: Text data in any format (XML, JSON, unformated text, ...)

Q: Does an SQS message contain binary data?
A: No, it contains text data.

Q: How does SQS interact with EC2 auto-scaling?
A: EC2 auto-scaling groups can grow based on the number of messages in an SQS queue.

Q: How are SQS messages delivered to an application?
A: Applications use the SQS API to poll a message queue and retrieve messages.

Q: How can SQS help to provide elasticity for bursty workloads?
A: You can create an auto-scaling group of EC2 instances that consume the messages and make the auto-scaling group grow when the queue becomes too long.

Q: What are the two types of SQS queues?
A: Standard queues and FIFO queues.

Q: What is the default queue type in SQS?
A: Standard queue.

Q: How does an SQS standard queue differ from a FIFO queue?
A: Maximum throughput, delivery guarantee, ordering guarantee

Q: How does an SQS standard queue differ from a FIFO queue in terms of number of maximum throughput?
A: Standard queues have no pre-determined limit on the throughput, FIFO queues limit throughput to 300 transaction per second (TPS).

Q: How does an SQS standard queue differ from a FIFO queue in terms of delivery guarantee?
A: Standard queues deliver the message at least one (but sometimes multiple times), FIFO queues guarantee exactly one delivery. 

Q: How does an SQS standard queue differ from a FIFO queue in terms of ordered guarantee?
A: Standard queues usually deliver the messages in-order (but sometimes out-of-order), FIFO queues guarantee in-order delivery.

Q: What is a message group in SQS?
A: Messages within a message group are delivered in-order. Messages in different message groups may be delivered out-of-order.

Q: Do SQS standard queues support message groups?
A: No, only FIFO queues.

Q: How long can an SQS message stay in the queue?
A: You can configure the retention time between 1 minute and 14 days; the default is 4 days. 

Q: What is the SQS retention time?
A: The maximum time a message can spend in a queue. One the retention limit is reached, the message is deleted.

Q: What is the difference between SQS short polling and long polling?
A: Short polling returns immediately, even if there is no message. Long polling blocks util a message is available (or until a time-out occurs).

SubTopic: Simple Workflow Service

Q: What does SWF standfor?
A: Simple Work Flow.

Q: What service does Simple WorkFlow (SWF) provide?
A: Manage the workflow of tasks that include various processing steps: execute code, call web service, invoke script, human action.

Q: What is a SWF domain?
A: A scope of workflow types, activity types, and workflow executions within an AWS domain.

Q: What is a SWF workflow?
A: A set of actitivities plus the logic that coordinates those activities.

Q: What is the maximum duration of an SWF workflow?
A: One year.

Q: What is a SWF activity type (or simply activity)?
A: An atomic step that is part of a workflow (e.g.) along with its attributes (name, version, time-out values, etc.)

Q: What is a SWF activity task (or simply task)?
A: An execution of an activity type along with a set of input parameters.

Q: What is a SWF workflow execution (or simply execution)?
A: An execution of a workflow.

Q: What is a SWF event?
A: A milestone in the workflow execution that happens at a particular moment in time and can be logged.

Q: What is a SWF decider?
A: A decider interacts with SWF to orchestrate the execution of activities, i.e. decide ordering, concurrency, etc. of tasks according to application logic.

Q: What is a SWF activity work (or simply worker)?
A: A worker imlements acitivities: it gets tasks from SWF, performs processing, and provides results.

Q: What are the responsibilities of the SWF infrastructure?
A: Store tasks, assign tasks to workers, guarantees tasks are executed exactly once, monitors task progress, provides consistent view of task to deciders.

Q: How does SQS (standard queue) differ from SWF in terms of abstract concepts?
A: SWF manages workflows of tasks; SQS manages queues of messages.

Q: How does SQS (standard queue) differ from SWF in terms of execution guarantees?
A: SWF assigns every task exactly once (it never loses or dupplicates tasks); SQS may lose or dupplicate message delivery.

Q: Name 3 SWF actors.
A: Workflow starter, Deciders, Activity Workers.

SubTopic: Simple Notification Service (SNS)

Q: What service does Simple Notification Service (SNS) provide?
A: Send messages to subscribing endpoints (e.g email or SMS).

Q: What service sends messages to subscribing endpoints (e.g. email or SMS)?
A: Simple Notification Service (SNS).

Q: What does SNS stand for?
A: Simple Notification Service.

Q: Is SNS push-based or pull-based?
A: Push based. SNS uses the pub-sub paradigm and pushes notifications to subscribers. Subscribers do not need to poll.

Q: What is the difference between SQS and SNS in terms of push- or pull-based model?
A: SQS is pull-based (polling), SNS is push-based (pub-sub).

Q: Name 7 types (protocols) of SNS subscribers.
A: HTTP, HTTPS, E-mail, E-mail JSON, SQS, Appliction, Lambda.

Q: What types of devices does SNS support?
A: Apple, Google, FireOS, Windows, Baidu.

Q: Is SNS highly available?
A: Yes, SNS messages are stored redundantly across multiple AZs.

Q: What is an SNS topic?
A: A topic is an "access point" allowing multiple recipients to dynamically subscribe to notifications published on the topic.

Q: Do all subscribers to a topic use the same delivery method?
A: No, a mixture of multiple delivery methods can be used (e.g. SMS messages, e-mail, etc.)

Q: How is SNS priced?
A: Per request ($0.50 per million). Per delivery notification (price depends on delivery type: HTTP, SMS, e-mail, etc.)

SubTopic: Elastic Transcoder

Q: What service does Elastic Transcoder provide?
A: File-based media transcoding.

Q: What services provide file-based media transcoding?
A: Elastic Transcoder and MediaConvert.

Q: What is transcoding?
A: Convert a media content file from one format to another format?

Q: Why would you want to transcode content?
A: To optimize it for a particular delivery platform (smartfone, tablet, PC, TV, etc.)

Q: What is the pricing model for Elastic Transcode?
A: Based on content duration (minutes) and content resolution.

SubTopic: API Gateway

Q: What service does API gateway provide?
A: Publish, maintain, monitor, and secure public APIs to access data, logic, or functionality on back-end applications.

Q: With what backends can Amazon API Gateway communicate?
A: Function in AWS Lambda, State machine in AWS Step Functions, HTTP endpoint hosted on EC2, Beanstalk, or 3rd party server.

Q: How does API Gateway support mocking?
A: Return static content.

Q: What is a resource in API Gateway?
A: A typed object in the API domain. It has a data model, relations with other resources, and can respond to methods.

Q: What is a method in API Gateway?
A: The a method implements the execution for one of more verbs (GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS) for a resource.

Q: What is the pricing model for API gateway?
A: Number of API calls, amount of data transferred, size of cache.

Q: What is usage plan in API gateway?
A: Defines allowed API usage (subset of APIs, throttling, quota limits) for users based on API key. Also can generate usage reports.

Q: What is an API lifecycle in API gateway?
A: The stages an API goes through (dev, test, prod, ...)

Q: Does API gateway support versioning of APIs?
A: Yes, multiple versions of the same API (v1, v2, ...) can run concurrently.

Q: Can Amazon API Gateway work within an Amazon VPC?
A: No. Amazon API Gateway endpoints are always public to the Internet. However, you can use private integrations or require client-side certificates.

Q: How do I authorize access to my APIs?
A: You can optionally enable authorization on API methods, using AWS signature version 4 or Lambda authorizers.

Q: How does AWS signature version 4 work?
A: Sign a request using the access key ID and secret, or using temporary credentials provided by Amazon Cognito.

Q: What is caching in API gateway?
A: An optional cache for storing API call results.

Q: How does API caching protect your backend application?
A: It reduces the number of calls to the backend application by returning cached results.

Q: How does API caching improve the user experience?
A: By reducing latency.

Q: What can you configure about an API cache?
A: The cache size and the TTL.

Q: What is the scope for enabling or disabling API caching?
A: Per deployment stage.

Q: Can API gateway log all API calls for an audit trail?
A: Yes, for auditing API executions use CloudWatch, for auditing API gateway management actions use CloudTrail.

Q: What is the same-origin policy?
A: Browsers only allows scripts in a web page to access resources in another web page if the other web page is from the same origin.

Q: What is an origin?
A: URI scheme + hostname + port number.

Q: What is Cross Origin Resource Sharing (CORS)?
A: A mechanism that allows the server (not the client) to relax same-origin policy requirements.

Q: What does CORS stand for?
A: Cross Origin Resource Sharing.

Q: Why would you need CORS in the context of API gateway?
A: Allows APIs to be called from a domain other than the API's own domain.

Q: How do you fix error message "Origin policy cannot be read at the remote resource" in API Gateway.
A: Enable CORS.

SubTopic: Kinesis

# TODO: Read the FAQ and update this

Lab: Kinesis
Step: Set region to us-east-1 (North Virginia) - the CloudFormation template from the resources depends on it.
Step: Create a new CloudFormation stack:
Step: ... Specify an Amazon S3 template URL = copy from resources (https://s3.amazonaws.com/kinesis-demo-bucket/amazon-kinesis-data-visualization-sample/kinesis-data-vis-sample-app.template)
Step: ... Stack Name = MyKinesisStack
Step: Wait 10 to 15 minutes until the stack reaches state CREATE_COMPLETE
Step: Observe the outputs tab of the stack, and open a browser window for URL stored in key URL. You will see a graph.
Step: In EC2 observe the EC2 instance that was created; it both produces and consumes the data for Kinesis.
Step: In Kinesis:
Step: ... Observe the Kinesis Stream list
Step: ... Observe the details of the one and only created Kinesis Stream
Step: ... Observe the monitoring tab for the Kinesis Stream
Step: In DynamoDB observe the database in which the data is stored
Step: Clean up: Delete the stack in CloudFormation.

Q: What service does Kinesis provide?
A: Real-time collection, processing, and analysis of data streams.

Q: What is streaming data?
A: Continuously generated data, typically generated by thousands of sources simultaniously in small sizes (kilobytes).

Q: What are the three core Kinesis services?
A: Kinesis Streams, Kinesis Firehose, and Kinesis Analytics.

Q: What is Kinesis Streams?
A: Producers stream data into Kinesis Streams, Kinesis Streams stores it in shards, and consumers read data from Kinesis Streams.

Q: What do Kinesis Streams consist of?
A: Shards.

Q: What is a Kinesis shard?
A: @@@

Q: What are the performance limits for a Kinesis shard?
A: Read: 5 transactions per second, 2 MB per second. Write: 1000 records per second, 1 MB per second (including partition keys).

Q: How is the capacity of a Kinesis stream determined?
A: Sum of the shards.

Q: How long is data stored in Kinesis Streams?
A: Up to 7 days, 24 hours by default.

Q: What is Kinesis Firehose?
A: @@@

Q: How is Kinesis Streams different from Kinesis Firehose in terms of shards?
A: In Kinesis Streams you manually need to configure shards to manage the capacity of the stream. In Kinesis Firehose there are no shards or streams @@@; capacity is automatically managed by AWS.

Q: How is Kinesis Streams different from Kinesis Firehose in terms of processing?
A: In Kinesis Streams, EC2 instance consume, process, and store the data. In Kinesis Firehose, Kinesis itself processes the data and the results go directly to storage from there.

Q: How is Kinesis Streams different from Kinesis Firehose in terms of data retention?
A: In Kinesis Streams, data is stored for up to 7 days. In Kinesis Firehose, data is not stored inside Kinesis, but processed directly.

Q: Can Kinesis Firehose store data directly into Redshift?
A: No, it has to go through S3 first.

Q: Can Kinesis Firehose store data directly into Elastic Search?
A: Yes.

Q: What is Kinesis Analytics?
A: Kinesis Analytics allows you to run SQL queries on the data stored in Kinesis Streams or Kinesis Firehose and store the results in S3, Redshift, or ElasticSearch.

Topic: Lab: Creating a fault tolerant Word Press Site

Lab: Creating a fault tolerant WordPress Site
Step: Note, use the us-east-1 (North Virginia) region for this lab; the ACG scripts assume this.
Step: Create a role, named S3-Admin-Access that provides EC2 with full access to S3.
Step: Create a security group in the default VPC, named Web-DMZ that allows inbound SSH and HTTP from anywhere   
Step: Create a security group in the default VPC, named RDS-SG that allows MySQL from Web-DMZ
Step: Create an application load balancer:
Step: ... in the default VPC
Step: ... named My-ALB
Step: ... in every AZ
Step: ... in security group Web-DMZ
Step: ... with target group name MyWebServers
Step: ... with /healthy.html for the healthcheck
Step: Create a bucket named brunorijsman-wpcode
Step: Create a bucket named brunorijsman-wpmedia
Step: Create a CloudFront web distribution:
Step: ... with the wpmedia S3 bucket as the origin
Step: ... restrict bucket access = yes
Step: ... origin access identity = create new identity
Step: ... update the S3 policy to grant read permissions
Step: Create a RDS MySQL instance:
Step: ... make it a production instance (we need multi-AZ)
Step: ... DB instance class = t2.micro
Step: ... Storage type = General Purpose SSD
Step: ... DB instance identifier = acloudguru
Step: ... Master username = acloudguru
Step: ... Master password = acloudguru
Step: ... In the default VPC
Step: ... Publicly accessible = No
Step: ... VPC security group = RDS-SG
Step: ... Database name = acloudguru
Step: Configure Route53 to point your domain name to the Application Load Balancer
Step: Launch an EC2 instance:
Step: ... AMI = Amazon Linux
Step: ... Instance Type = t2.micro
Step: ... IAM Role = S3-Admin-Access
Step: ... Optional: Boostrap script = copy from ACG resources (if you do, you can skip steps marked [*])
Step: ... Tag Name = MyEC2WebServer
Step: ... Security group = Web-DMZ
Step: SSH into MyEC2WebServer and escalate priviledges
Step: [*] Do an update: yum update -y
Step: [*] Install PHP, Apache, and stress: yum install -y php php-mysql httpd stress
Step: [*] Go to the Apache configuration directory: cd /etc/httpd/conf (have a look at httpd.conf)
Step: [*] Create a backup of the configuration file: cp httpd.conf httpd.conf.backup
Step: [*] Edit httpd.conf as follows (needed for URL rewrites to serve media out of S3): 
Step: ... [*] <<Directory "/var/www/html">
Step: ... [*]     Options FollowSymLinks
Step: ... [*]     AllowOverride All
Step: ... [*] </Directory>
Step: Go to the web server content directory: cd /var/www/html
Step: [*] Edit healthy.html to contain "I am healthy"
Step: [*] Install WordPress: wget https://wordpress.org/latest.tar.gz
Step: [*] Untar WordPress: tar -xzf latest.tar.gz
Step: [*] Move the WordPress files to the top level: cp -r wordpress/* /var/www/html
Step: [*] Cleanup: rm -rf wordpress latest.tar.gz
Step: [*] Set the permissions: chmod -R 755 wp-content
Step: [*] Set the owner: chown -R apache.apache wp-content
Step: [*] Start Apache: service httpd start
Step: [*] Configure Apache to start at boot time: chkconfig httpd on
Step: Modify load balancer target group MyWebServers:
Step: ... Set health check: healthy threshold 2, unhealthy theshold 2, timeout 2, interval 5, status code 200
Step: ... Add EC2 instance MyEC2WebServer to the registered target list
Step: Using a browser, go to your domain name. You should see the WordPress screen, asking you to configure the database:
Step: ... Click Let's Go!
Step: ... Configure the database:
Step: ...   Database name = acloudguru
Step: ...   Username = acloudguru
Step: ...   Password = acloudguru
Step: ...   Database host = Copy and past the RDS endpoint domain name
Step: ...   Table prefix = wp_
Step: ... Copy and past the generated PHP code
Step: ... In the terminal for the EC2 instance, edit wp-config.php, and paste the PHP code
Step: ... Click on Run Installation
Step: ... Configure the blog:
Step: ...   Site Title = Hello Cloud Gurus
Step: ...   Wordpress Address (URL) = http://remoteautnomy.com
Step: ...   Site Address (URL) = http://remoteautnomy.com
Step: ...   Username = acloudguru 
Step: ...   Password = acloudguru
Step: ...   Your email = foo@bar.com
Step: ... Login to WordPress and configure it.
Step: Create a backup of the website to S3 using the AWS CLI on MyEC2WebServer: aws s3 cp --recursive /var/www/html s://brunorijsman-wpcode
Step: Go to the WordPress website and upload an image, and observe that the file appears in /var/www/html/wp-content/uploads
Step: Insert the image in a Post, open the post, and copy the URL for the embedded image. Observe that the image is served out of the EC2 instance.
Step: Manually copy all WordPress media uploads to S3 bucket brunorijsman-wpmedia: aws s3 cp --recursive /var/www/html/wp-content/uploads s3://brunorijsman-wpmedia
Step: Go to the WordPress website and upload another image
Step: Manually copy all WordPress media uploads to S3 bucket brunorijsman-wpmedia again
Step: Go to the WordPress website and upload a third image
Step: Synchronize the uploads directory with the S3 bucket (including deletes): aws s3 sync --delete /var/www/html/wp-content/uploads s3://brunorijsman-wpmedia
Step: Look at an uploaded image by manually editing the URL in the browser: http://34.201.33.13/wp-content/uploads/2018/06/621k-airplane.jpg
Step: Create URL rewrite files by:
Step: ... Copy the ACG resource file into /var/www/html/.htaccess 
Step: ... Replace the CloudFront URL in the .htaccess file with ours
Step: Restart Apache: service httpd restart
Step: Rivisit an image in your browser, and observe the URL is automatically rewritten to use CloudFront
Step: Create a cron job to sync the media files automaticall:
Step: ... cd /etc
Step: ... Edit crontab
Step: ... */1 * * * * root aws s3 sync --delete /var/www/html/wp-content/uploads s3://brunorijsman-wpmedia
Step: ... */5 * * * * root aws s3 sync --delete /var/www/html/wp-content s3://brunorijsman-wpcode
Step: (optional) Force cron to restart: service crond restart
Step: We now want to create to load balancer targets: a read-write WordPress target and a read-only WorkPress target.
Step: Remove MyWebServer from the MyWebservers target group for My-ALB 
Step: Create a new classic load balancer:
Step: ... named MyWriteELB
Step: ... security group WebDMZ
Step: ... healthcheck ping path = /healthy.html
Step: ... Response timeout 5, interval 6, unhealthy threshold 2, healthy threshold 3
Step: ... MyEC2WebServer as a member instance
Step: ... Tag Name = MyWriteELB
Step: In Route53 create an A record as an alias for write.yourdomainname.com pointing to the new load balancer.
Step: Stop the MyWebServer instance, take a snapshot named MyWP-Write-Image, wait for it to be available, and restart the instance.
Step: Temporarily add MyWebServer back the MyWebservers target group for My-ALB
Step: Go to the admin portal for the wordpress site, and in general settings change the WordPress and Site address URL both to http://write.remoteautonomy.com
Step: Remove MyWebServer from the MyWebservers target group for My-ALB again
Step: Launch another EC2 instance from the AMI MyWP-Write-Image we created earlier:
Step: ... AMI = Amazon Linux
Step: ... Instance Type = t2.micro
Step: ... IAM Role = S3-Admin-Access
Step: ... Tag Name = WP-PROD-WEB-SERVER
Step: ... Security group = Web-DMZ
Step: Add the new instance WP-PROD-WEB-SERVER to target group My-ALB
Step: Rename the original EC2 instance WP-CONTENT-TEAM
Step: SSH into WP-PROD-WEB-SERVER and change the cron job to download changes instead of uploading them:
Step: ... cd /etc
Step: ... Edit crontab
Step: ... Delete the two lines are replace them with:
Step: ... aws s3 sync --delete s3://brunorijsman-code s3: /var/www/html/wp-content
Step: ... aws s3 sync --delete s3://brunorijsman-wpmedia s3: /var/www/html/wp-content/uploads 
Step: Go to http://remoteautonomy.com and verify the website works
Step: Make some site changes in http://write.remoteautnomy.com/wp-admin and verify they are synced to the production website
Step: On the production server,go into the wp-admin portal for write.remoteautonomy.com and change the WordPress and Site URL back to autonomy.com (@@@@ WHY???)
Step: Stop the production instance, take a snapshot named My-Prod-Web-Server, wait for it to be available, and restart the instance.
Step: @@@ continue from here

Topic: Whitepapers & The Well Architected Framework

SubTopic: Whitepapers & The Well Architected Framework: Security

Q: Name 5 business benefits of using cloud infrastructure.
A: Almost zero upfront infrastructure investment, just-in-time infrastructure, more efficient resource utilization, usage-based costing, reduced time to market

Q: Name 7 technical benefits of using cloud infrastructure.
A: Automation ("scriptable infrastructure"), auto-scaling, pro-active scaling, more efficient development lifecycle, improved testability, disaster recovery and business continuity, can overflow traffic to the cloud.

Q: Name 3 economic benefits of elasticity.
A: Avoid huge capital outlays, avoid opportunity cost of unused capacity, avoid losing customer due to insufficient capacity.

Q: What does design for failure mean?
A: Assume everything will fail. Design, implement, and deploy for automatic recovery from failure.

Q: Name 3 component failure modes you should consider when designing for failure.
A: Components that die (fail), sleep (no response), or are overloaded (slow response).

Q: What approach should you use to build a reliable system out of unreliable component.
A: Loose coupling (e.g. using SQS) with asynchronous interactions.

Q: How does loose coupling help to increase reliability?
A: One component failure does not affect other components directly. Components can be scaled and recovered independently from each other.

Q: Name 3 types of elasticity.
A: Proactice cyclic scaling, proactive event-based scaling, auto-scaling based on demand.

SubTopic: The Well Architected Framework, Pillar One: Security

Q: Name 5 design principles for security.
A: Apply security at all layers, enable traceability, automate responses to security incidents, focus on securing your system, automate security best practices.

Q: What is the crux of the shared responsibility model?
A: Amazon is responsible for certain aspects of security (security OF the cloud), and you are responsible for other aspects (security IN the cloud).

Q: What aspects of security is Amazon responsible for?
A: Security OF the cloud: AWS global infrastructure (regions, AZs, edge locations), compute, storage, database, networking.

Q: What aspects of security are you responsible for?
A: Security IN the cloud: customer data, applications, platform, IAM, operating systems, network and firewall configuration, client-side data encryption and integrety, server-side encryption, in-transit encryption.

Q: Names 4 areas for security in the cloud?
A: Data protection, privilege management, infrastructure protection, detective controls.

Q: For data protection, what is the best practice for data classification?
A: Put basic data classifiction in place (who is allowed to access each class of data). Implement a least-priviledge access system (people are only allowed to access what they need).

Q: For data protection, what is the best practice for encryption.
A: Encrypt all data both at-rest and in-transit. AWS makes it easy to encrypt data and manage keys (KMS) either by the user or by Amazon.

Q: For data protection, what mechanisms are in place to ensure data is not lost.
A: AWS customers maintain full control over their data. Amazon storage systems (S3, Glacier, ...) are resislient (e.g. 5 nines durability). Versionong and lifecycle management protect agains accidental overwrites etc.

Q: For data protection, what mechanism allows you to keep track of what is goig one?
A: Detailed logging is available (CloudTrail). 

Q: For data protection, how can you be sure data is stored in the region where you want it?
A: You chose the region, Amazon never moves data to another region unless excplitly requested by the user.

Q: For data protection, what question should you ask yourself related to encryption?
A: How are you ecrypting your data at-rest and in-transit? How do you manage keys and key rotation?

Q: What is priviledge management?
A: Ensure that only authenticated and authorized users have access to the resources, and only in a manner that is intended.

Q: For privilege management, name 3 mechanisms that AWS provides.
A: IAM user authentication mechanisms (e.g. 2FA, password rotation policies), role based access controls, access control lists.

Q: For privilege management, what questions should you ask yourself about root access?
A: How are you protecting access and use of the AWS root credentials (e.g. MFA).

Q: For privilege management, what questions should you ask yourself about users?
A: What groups, policies, and roles are you defining to provide users with least privilege access to the console and to APIs?

Q: For privilege management, what questions should you ask yourself about resources?
A: What mechanisms (e.g. roles, security grous, ACLs, ...) are you putting in place to provide resources (e.g. an EC2 instance) with least privilege access to other resources (e.g. S3 buckets).

Q: For privilege management, what question should you ask yourself about secrets?
A: How are you manageming keys and credentials (e.g. the access key secret)?

Q: For infrastructure protection, who is responsible for managing the security of the physical infrastructure?
A: Amazon is.

Q: For infrastructure protection, what is your role?
A: You are responsible for protecting the security of infrastructure at the VPC level.

Q: For infrastructure protection, what should you ask yourself about boundary protection?
A: How are you protection network and host-level boundaries (security groups, NACLs, public or private subnets, WAF, NAT, bastion hosts, etc.)

Q: For infrastructure protection, what should you ask yourself about AWS services and resources?
A: How are you enforcing AWS service and resource level protection (user groups, MFA, roles, etc.)

Q: For infrastructure protection, what should you ask yourself about guest OSs?
A: How are you protecting the integrety of the guest OS on EC2 instances (patching, anti-virus scanning, etc.)

Q: For detective controls, name 5 services that you can use to detect or identify a security breach.
A: CloudTrail, CoudWatch (alarms), Config (history of config changes), S3 (?), Glacier (?)

Q: For detective controls, what question should you ask yourself about audit trails?
A: How are you capturing and analyzing logs?

Q: What are security considerations for IAM
A: Groups, password rotation, MFA

Q: What are security considerations for EC2 instancs
A: Security groups, patching and virus scanning

Q: What are security considerations for EC2 EBS
A: Encryption

Q: What are security considerations for S3
A: Encryption

Q: What are security considerations for Glacier
A: Encryption

Q: What are security considerations for RDS
A: Encryption

Q: What are security considerations for VPC subnets
A: Public or private, Internet gateway, NAT gateway, Service gateway, Security Groups, ACLs, Bastion hosts

SubTopic: Whitepapers & The Well Architected Framework: Reliability

Q: An application in AWS is considered reliable if it exhibits which 2 characteristics?
A: The ability to recover from infrastructure or service outages. The ability to dynamically acquire resources to meet demand.

Q: What is the main design principle to make sure your application actually has the reliability that it was designed for?
A: Test the recovery procedures for outages and overload (e.g. Netflix Simian army). Automate the tests.

Q: What is the main design principle when you design your recovery processes?
A: Recovery should be automated, triggered by KPI violations.

Q: What is the main design principle for scaling your system?
A: Scale horizontally to increase aggregate system availability. Multiple small resources instead of one large resource.

Q: How do you reduce the blast radius of a failure.
A: Scale horizontally to increase aggregate system availability. Multiple small resources instead of one large resource.

Q: What is the best way to guess or predict required capacity.
A: Don't guess or predict. Measure.

Q: Name 3 areas for achieving reliability in the cloud.
A: Foundation, change management, failure management.

Q: For reliability, what is the main consideration in terms of foundations?
A: That you have enough capacity. 

Q: Who is responsible to providing enough physical capacity for all of the services.
A: Amazon is responsible, and provides essentially limitless physical capacity.

Q: What is your responsibility to ensure that you have enough capacity?
A: You are responsible for allocating the right number and size of resources (e.g. EC2 instancs, databases) for the required capacity.

Q: What do you need to be careful of when you attempt to allocate the right number and size of resources to meet your required capacity?
A: Amazon has soft limits on the number and size of certain resources to protect you against accidental over-provisioning. You can raise these using a support request but it takes time.

Q: What is a reliability practice related to service limits?
A: Someone should be responsible for monitoring whether you are getting close to the service limits and for raising tickets if necessary.

Q: What is a reliability practice related to techincal issues?
A: You should have well defined processes and owners for escalations and for raising AWS tickets.

Q: Name 3 services that can help you automate change management.
A: CloudWatch, EC2 auto-scaling, Lambda.

SubTopic: Whitepapers & The Well Architected Framework: Performance Efficiency

Q: What does performance efficiency mean?
A: To use computing resources efficiently to meet your requiremets, and to maintain that efficiency over time as demand changes and technology evolves.

Q: Name @@@ design principles for achieving performance efficiency.
A: Democratize advanced technologies, go global in minutes, use serverless architectures, experiment more often.

Q: How does "democratizing advanced technologies" help performance efficiency?
A: Making new technologies easily consumable makes it more likely that applications migrate to more efficient technologies when they become available.

Q: What does the phrase "go global in minutes" refer to?
A: Once you have established your application in one or a few regions, it is very easy to scale globally.

Q: What recent technology allows you to build extremely efficient applications that scale virtually infinitely with no need to manage infrastructure?
A: Serverless (AWS Lambda)

Q: How does experimenting more often help performance efficiency?
A: Predicting is difficult, measuring tells you what will actually happen if you try something different. Cloud makes experimenting easy and cheap.

Q: What 4 areas does performance efficiency consists of?
A: Compute, storage, database, space-time trade-off.

Q: For compute performance effiency, what two things should you consider when launching EC2 instances?
A: Use the right type and size of EC2 instance that is optimized for the task (e.g. compute optimized). Consider using Lambda instead of EC2.

Q: Name 7 factors that you need to take into consideration to choosing the most performance efficient storage option.
A: Access method (block, file, object), access pattern (random, sequential), throughput, access frequency (online, offline, archival), update frequency (WORM, frequently), availability constraints, durability constraints.

Q: Name 7 factors that you need to take into consideration to choosing the most performance efficient database option.
A: SQL or no-SQL, consistency requirements, high availability requirements, disaster recovery requirements.

Q: What does AWS typically mean with space-time tradeoff?
A: Often you can deploy more resources (e.g. multiple RDS read replicas) or additional services (e.g. caching) to improve performance (e.g. reduce read latency).

Q: Give an example of space-time tradeoff in compute.
A: With auto-scaling you can deploy more EC2 instances to improve performance.

Q: Give an example of space-time tradeoff in networking.
A: You can deploy direct connect to improve network performance.

Q: Give an example of space-time tradeoff for global coverage.
A: You can deploy your service on more regions or deploy CloudFront caching for better performance.

Q: Give an example of space-time tradeoff for databases.
A: You can deploy ElastiCache to improve database performance.

SubTopic: Whitepapers & The Well Architected Framework: Cost Optimization

Q: Name 5 design principles for cost optimization.
A: Transparently attribute expenditure, use managed services to reduce the cost of ownership, trade capital expense for operating expense, benefit from economies of scale, stop spending money on datacenter operations.

Q: How does transparently attributing expenditure help optimize cost?
A: Driving the cost of each application to the business owner provides an incentive to optimize the application based on cost-benefit analysis.

Q: How does using managed services reduce the cost of ownership?
A: You don't have to pay for the operational burden (time, staff, training) of maintaining the infrastructure for the service.

Q: Why is paying Amazon for managing a service cheaper than managing it yourself?
A: Because Amazon benefits from vast economies of scale.

Q: What does Amazon mean when they say "trade capital expense for operational expense"?
A: Don't pay up-front for equipment and software, but pay-as-you-go for AWS services.

Q: Cost optimization in the cloud consists of which 4 areas?
A: Matched supply and demand, cost-effective resources, expenditure awareness, optimizing over time.

Q: For cost optimization, what does matched and supply mean?
A: Don't over-provision, and don't under-provision.

Q: What AWS service helps you track demand?
A: CloudWatch.

Q: What AWS services can help you match compute supply to demand.
A: Auto-scaling and lambda.

Q: How does choosing the EC2 instance type and size affect the cost-effectiveness of resource usage?
A: Using and EC2 instance type or size that is too big wastes money. However, using a specialized instance type can save you money because it can run shorter to achieve the same task.

Q: How does choosing the pricing model affect the cost-effectiveness of resource usage?
A: Using reserved or spot instances can drive down costs. However, chosing the wrong pricing model can increase cost because of unused capacity or service interruptions.

Q: How does the choice of service influence the cost-effectiveness of resource usage?
A: Using a managed service (e.g. RDS) may or may not be cheaper than using a self-hosted service (e.g. MySQL in an EC2 instance).

Q: Why is expenditure awareness such a big issue for cloud services?
A: Because it is so easy to instantiate new virtual resources, it is easy to lose track of how much you are spending and for what purpose.

Q: Name 3 mechanisms to help you achieve expenditure awareness.
A: Cost allocation tags for resources, billing alerts, consolidated billing.

Q: What is a specific cost that often surprises?
A: Data transfer charges.

Q: Name 2 mechanisms to help you stay on top of the latest service offerings from Amazon and make sure you use the best service for each business goal.
A: AWS blog, Trusted Advisor service.

SubTopic: Whitepapers & The Well Architected Framework: Operational Excellence

Q: What does operational excellence cover?
A: Operational practices and procedures used to manage production workloads, including both planned changes and reacting to unplanned incidents.

Q: Name 4 best practices that apply to both planned changes and incident responses.
A: Automate as much as possible, document all processes, test all processes, and regularly review all processes.

Q: Name 6 design principles for operational excellence.
A: Perform operations with code, align operations process with business objectives, make regular small incremental changes, test for response to unexpected events, learn from operational events and failures, keep procedures current.

Q: How does "perform operations with code" help achieve operational excellence?
A: Easier to automate, fewer mistakes.

Q: Give a concrete exmaple of aligning operations processes with business objective.
A: Monitor metrics that are meaningful to business objectives.

Q: What are the 3 best practice areas for operational excellence in the cloud?
A: Preparation, operation, response.

Q: What are runbooks and playbooks?
A: A runbook is a documented operations guide for running the service normally. A playbook is a documented guide for responding to unexpected incidents (including escalation and notification plans)

Q: What AWS services help you with preparation for operational excellence?
A: CloudFormation, auto-scaling, config, tagging. 

Q: How does CloudFormation help you to prepare for operational excellence?
A: Templates ensure that all resources needed for an application will be available, that only tested configurations are used, and reduces the chance of human error.

Q: How does auto-scaling help you to prepare for operational excellence?
A: Auto-scaling (and other automated scaling mechanisms) allow workloads to automatically respond to changes in demand without need for human intervention. 

Q: How does AWS Config help you to prepare for operational excellence?
A: Provides mechanisms to automatically track and respond to changes.

Q: How does tagging help you to prepare for operational excellence?
A: Allows you to easily identify all resources that are related to a particular application.

Q: What is an operations best practice in terms of what mechanism should be used to roll out changes?
A: An automated mechanism should be used to roll out changes, including automated checking of correct operations, and automated roll-back if necessary.

Q: What is an operations best practice in terms of what types of changes should be rolled out?
A: Changes should be small and frequent (as opposed to large and infrequent).

Q: What is an operations best practice in terms of scheduled downtime?
A: There should be no scheduled downtime.

Q: What is an operations best practice in terms of monitoring?
A: A wide range of logs and metrics should be collected and reviewed to ensure continuous operations. 

Q: What does CI/CD stand for?
A: Continuous Integration / Continuous Delivery.

Q: What is best practice for how responses to unexpected events should take place?
A: They should be automated as much as possible.

Q: Responses for unexpected events should not only cover alerts, but also what?
A: Mitigation, remediation, rollback, and recovery.

Q: Alerts are only useful if they are what?
A: Timely.

Q: How does Service Catalog help prepare for operational excellence?
A: By creating a standardized set of service offerings.

Q: What AWS services help you build a CI/CD pipeline?
A: CodeCommit, CodeDeploy, CodePipeline, CloudTrail.

Topic: Additional Exam Tips

SubTopic: Exam Tips Based on Student Feedback

Q: What is Kinesis?
A: A managed service for processing streaming data at massive scale (consume "big data" e.g. clickstreams or social media feeds).

Q: After how much time is data written into Kinesis available to readers?
A: Less than a second.

Q: What service would you use to consume and process large streams of data such as social media streams?
A: Kinesis.

Q: What service would you use to consume and process large volumes of data for business intelligence?
A: RedShift

Q: What service would you use to consume and process large volumes of data big data processing?
A: Elastic Map Reduce (EMR).

Q: What is the difference between Kinesis and EMR?
A: Kinesis processes large streams of in-flight data. EMR provides large volumes of stored data.

Q: Are EBS-backed volumes persistent or ephemeral?
A: They are persistent. If delete-on-termination is set to false, the EBS volume continues to exists after the EC2 instance has been terminated.

Q: Are instance store backed volumes persistent or ephemeral?
A: They are ephemeral. The instance store volume ceases to exist when the EC2 instance is terminated.

Q: What type of EC2 volume can be detached and reattached to other EC2 instances?
A: Only EBS-backed volumes, not instance store backed volumes.

Q: What happens if you stop an EC2 instance with a EBS-backed volume?
A: The volume and the data on it continue to exist.

Q: What happens if you stop an EC2 instance with a instance store backed volume?
A: You cannot stop an EC2 instance with instance-backed root store. You can only reboot or terminate it. If the instance store back volume is secondary it will be lost (is this even possible?)

Q: If you want the data stored on an EC2 volume to persist longer than the life of the EC2 instance itself, which type of storage should you use?
A: EBS-backed volume (not an instance store backed volume)

Q: What service does OpsWorks provide?
A: Orchestration using Chef.

Q: What Chef (OpsWorks) cookbooks and recipes?
A: The code that describes how to orchestrate infrastructure.

Q: What service does Elastic Transcoder provide?
A: Convert media files from their original format to other format that are optimized for particular devices (phone, tablet, laptop, TV, ...)

Q: What level of detailed parameters do you need to specify for Elastic Transcoder to convert a file?
A: It has presets for pupular devices so that you don't have to guess about which settings work best.

Q: What is the pricing model for Elastic Transcode?
A: You are charged for the duration (minutes) and resolution of the transcoded video file.

Q: Name 3 SWF actors.
A: Workflow starter, Deciders, Activity Workers.

Q: What is an SWF workflow starter?
A: An application that initiates a workflow.

Q: What is an SWF decider?
A: Controls the flow of activity tasks in a workflow.

Q: What is an SWF activity worker?
A: Carries out an activity task.

Q: What is the URL for retrieving the instance meta-data from inside the instance?
A: http://169.254.169.254/latest/meta-data/

SubTopic: AWS organizations and consolidated billing

Q: What is an AWS organization?
A: An account management service that enables you to consolidate multiple AWS accounts into a centrally managed organization.

Q: What are the two feature sets for AWS organizations?
A: Consolidated billing and all features.

Q: What additional features are available in "all features" above and beyond consolidated billing?
A: Hierarchical organizational units, and policy-based controls.

Q: What an AWS Organization policy?
A: It allows (whitelist) or blocks (blacklists) a specified set of actions for a specified set of services in the accounts to which the policy is attached.

Q: What are the 3 types of nodes in an organizational tree in AWS Organizations?
A: The root, Organizational Units (OUs), and accounts.

Q: What can policies be attached to in AWS Organizations?
A: The root, Organizational Units (OUs), and accounts.

Q: What are the 2 types of accounts in consolidated billing?
A: The paying account (aka root account) and linked accounts.

Q: How many bills do you received when consolidated billing is enabled?
A: One bill with a single total amount to pay, but broken out by each linked account.

Q: Can the paying account access the resources owned by the linked account?
A: No.

Q: Can one linked account access the resources of another linked account?
A: No.

Q: What is the maximum number of linked accounts per paying account?
A: 20, but you can request more.

Q: What are the 2 advantages of consolidated billing?
A: Simpler billing (one bill) and better volume discounts (over the grand total across all linked accounts).

Q: In consolidated billing, what is special about the billing related to reserved instances?
A: If you create an on-demand instance in linked account A, and you have an unused reserved instance in account B, you will not be charged for the on-demand instance in A.

Q: Name 3 practices for securting the paying account (root account)?
A: Use strong passwords. Use MFA. Use the paying account only for billing, not for deploying resources.

Q: If you want a billing alert for the total spent in the organization, where should you create it?
A: On the paying account.

Q: If you want a billing alert for amount spent in a single department, where should you create it?
A: On the linked account for that department.

Q: What is the scope of CloudTrail audit logs?
A: Per account and per region.

Q: How can you get a consolidated CloudTrail log across all linked accounts in an S3 bucket
A: Turn on CloudTrail in the paying account, create a bucket policy that allows cross-account access, turn on CloudTrail in the linked accounts, and use the bucket in the paying account.

SubTopic: Cross Account Access

Q: What is cross-account access?
A: It allows you to loging to the console using one account, and then switch to another account without having to log out and in again.

Q: How can you allows a user group in account A to access the files in a bucket in account B?
A: In account B, create a policy that allows access to the bucket, create a cross-account access role for account A and attach the policy to it. In account A, create an in-line custom policy for the user group that allows action assume-role for the role in account B.

Q: Once the proper cross-account access has been setup, how does a user actually access resources in another account using the console?
A: Click on the account link in the top right of the menu bar, select switch role, and select the other account and role.

SubTopic: Lab: Tagging and resource groups

Lab: Tagging and resource groups
Step: Create an instance with tags Name = vm-1, Department = Development, Team = TeamA
Step: Create a resource group:
Step: ... Group name = Development team A resources
Step: ... Tag = Department, Value = Development
Step: ... Tag = Team, Value = TeamA
Step: Observe all the resources in the resource group (there should be an EC2 instance)
Step: Export the list of resources in the resource group as a CSV file.
Step: Start the tag editor to explore tags and resources.

Q: What is a tag?
A: A name-value pair attached to a resource, also known as meta-data.

Q: When are tags inherited?
A: In cases where resources are created automatically, e.g. auto-scaling, CloudFormation, Elastic Beanstalk, etc.

Q: What is a resource group?
A: A grouping of resources based on one or more tags.

Q: Can you create a resource group for all untagged resources?
A: Yes.

Q: What is a convenient tool to explore and edit the tagging of resources?
A: The tag editor.

Q: Name 3 good tools to help you not lose track of resources that you are paying for?
A: Tags, resource groups, and the tag editor.

SubTopic: VPC peering

Q: What is VPC peering?
A: A connection between to VPCs that allows you to route traffic between them using private IP addresses.

Q: Can you create a VPC peering across different regions?
A: The course says no, but Amazon recently announced that this is now supported.

Q: Can you create a VPC peering between a VPC in your account and a VPC in another account?
A: Yes, but only if they are in the same region.

Q: Is there a gateway for VPC peering?
A: No, there is no abstract or physical resource to represent the VPC peering. It happens "under the hood".

Q: Is there a single point of failure for VPC peering?
A: No.

Q: Is there a single bandwidth bottleneck for VPC peering?
A: No.

Q: Is it possible to create a VPC peering between two VPCs with overlapping private address blocks?
A: No.

Q: Is VPC peering transitive? If A peers with B, and B peers with C, can A talk to C?
A: No, for this to work, there must be an explicit VPC peering between A and C.

Q: Name 3 limitations for VPC peering.
A: Not across regions, not between VPCs with overlapping private IP address blocks, not transitive.

SubTopic: Direct Connect 

Q: What is Direct Connect?
A: A dedicated network connection from your premises to the AWS cloud.

Q: Name 3 benefits of direct connect over Internet-based connections.
A: Reduce cost, increase throughput, hiher reliability.

Q: What is the difference between Direct Connect and a VPN Connection in terms of setup time?
A: A VPN connection can be established on-demand in a matter of minutes; it can take months to setup the dedicated line for Direct Connect.

Q: What is the difference between Direct Connect and a VPN Connection in terms of bandwidth and reliability?
A: A VPN connection provides most and variable bandwidth because it runs over the public Internet, Direct Connect can provide guaranteed and high bandwidth because it uses a private connection.

Q: What is the difference between Direct Connect and a VPN Connection in terms of underlying transport?
A: A VPN connection is a secure tunnel over the public Internet, Direct Connect uses a dedicated transport connection separate from the Internet.

Q: Does Amazon provide the private transport link that is needed for Direct Connect?
A: No, you have to get this from your Telco.

Q: How is the Direct Connect terminated at the Amazon site?
A: You put your router in a cage at an Amazon Direct Connect (DX) facility to terminate the circuit. Amazon will cross-connect it to an Amazon router in a different cage. The Amazon router in the DX facility connects to an Amazon datacenter over dark fiber.

Q: In what capacities is Direct Connect available?
A: 10 Gbps and 1 Gbps directly from Amazon. Below 1 Gbps from Amazon direct connect partners.

Q: What transport is used to cross-connect your router to the Amazon router for Direct Connect?
A: Ethernet VLAN trunking (802.1Q).

Q: What service would you use to connect to the AWS cloud without traversing the public Internet?
A: Direct Connect.

SubTopic: Security Token Service

Q: What does STS stand for?
A: Security Token Service.

Q: What service does Security Token Service (STS) provide?
A: It grants users limited and temporary access to AWS resources.

Q: Name 3 possible sources for users in STS:
A: Federation (uses SAML, typically Active Directory), Federation with mobile apps (Uses OpenID, typically Facebook, Amazon, Google, ...), Cross-account access.

Q: What does SAML stand for?
A: Security Access Markup Language

Q: Does STS federation require that the user exists in IAM?
A: No.

Q: Using STS federation can you login to the console using single sign-on without providing IAM credentials?
A: Yes.

Q: What does federation mean?
A: Combining a list of users in one domain (e.g. IAM) with the list of users in another domain (e.g. Active Director or Facebook).

Q: What is an Identity Broker?
A: A service that allows you take an identify from point A and joint it (federate it) to point B.

Q: What is an identity store?
A: A place where user credentials are stored, e.g. IAM, Active Directory, Facebook, Google, etc.

Q: What is an identity?
A: A user who can be authenticated.

Q: Who provides the Identity Broker (aka Federation Proxy)?
A: You have to implement it yourself because it is specific to your environment, but Amazon provides examples.

Q: What is the difference between delegation and federation?
A: Delegation provides users in other AWS accounts access to resources in your AWS account. Federation provides users in other identity stores access to resources in your AWS account.

Q: Does IAM federation support access to the console or to the APIs?
A: Both.

Q: What are the two types of identities in IAM federation?
A: Corporate identities and social identities.

Q: What is the use case for corprorate identities in IAM federation?
A: Allow corporate users to access resources in your AWS account using single sign-on.

Q: What technologies are (typically) used for corporate identities in IAM federation?
A: Active Directory, SAML, a custom federation proxy.

Q: What is the use case for social identities in IAM federation?
A: Allow apps to access resource in your AWS account using social (Facebook, Google, etc.) identities.

Q: What technologies are (typically) used for social identities in IAM federation?
A: OpenID, Amazon Cognito.

Q: What are the two types of policies that you can set on roles?
A: Trust policies: who (which principal) do you trust (e.g. all identities asserted by a SAML provider). Access policy: what actions are allowed (e.g. read an S3 bucket).

Q: What is a session in the context of STS?
A: A session grants temporary access to AWS resources.

Q: Who generates sessions?
A: The Simple Token Service (STS).

Q: What causes STS to generate a session?
A: The application calls an STS API (e.g. GetFederationToken).

Q: Name the 4 elements in an STS session.
A: Access key ID, access key secret, session token, expiration.

Q: How does AWS know which identity providers to trust?
A: The meta-data of identity providers is stored in IAM.

Q: What are the three main steps for identity federation?
A: You build identity broker (IB). App or user requests temporary AWS resources access from IB. IB authenticas user using identity provides (e.g. AD). IB requests session token from AWS STS and passes it on to app or user. App or user provides session token to AWS services.

SubTopic: Active Directory integration

Q: Can you authenticate for the AWS console using Active Directory?
A: Yes, using Active Directory Federation Services (ADFS) and SAML (Security Assertion Markup Language).

Q: When you login to the AWS console using AD, do you authenticate with AD first or do you get the temporary security credential from AWS first?
A: You authhenticate with AD first.

SubTopic: Workspaces

Q: What service does AWS Workspaces provide?
A: Virtual Desktop Infrastructure (VDI).

Q: How does a user access AWS Workspaces?
A: Using a free thin-client application that runs on PC, Mac, Chromobook, iPad, Kindle Fire, Android tablet, ...

Q: What does AWS Workspaces provide on the server side?
A: A complete desktop environment including compute, storage, and multiple applications. (Note: AppStream 2.0 provides a single application.)

Q: How does AWS Workspaces authenticate users?
A: Using credentials configured by the administrator, or using Active Directory integration.

Q: Does an end-user need an AWS IAM account to access Workspaces applications?
A: No, Active Directory integration allows them to login using their company credentials.

Q: What operating system expedience does Workspaces provide to the end-user?
A: Windows 7 (provided by Windows Server 2008 R2 on the backend).

Q: Can Workspaces end-users customize their preferences (wallpaper, icons, shortcuts, etc.)?
A: By default yes, can be disabled by the administrator.

Q: Dp Workspaces end-users have administrator privileges to install new applications?
A: By default yes, can be disabled by the administrator.

Q: Are Workspaces instances persistent or ephemeral?
A: Persistent.

Q: How is Workspaces data backed up?
A: Data on the D:\ drive is automatically backed up every 12 hours.

SubTopic: Elastic Container Service (ECS)

Q: What does ECS stand for?
A: Elastic Container Service.

Q: What service does Elastic Container Service (ECS) provide?
A: Docker containers.

Q: Name the 3 layers of an application stack.
A: Operating system, dependencies, and application.

Q: What underlying technology is docker based on?
A: Linux Containers (LXC)

Q: What is the difference between a Virtual Machine (VM) and a container?
A: A VM contains an independent copy of the OS (the guest OS), the container uses the Linux host OS.

Q: What is a benefit of containers over VMs in terms of resource usage?
A: Containers are lighter-weight than VMs; the use less disk, RAM, and they startup faster.

Q: What is a benfit of containers over running applications natively in terms of dependencies?
A: The dependencies are packaged along with the application, thus simplifying dependency management. Applications are more portable.

Q: What is a benfit of containers over running applications natively in terms of reliability?
A: The running applications are strongly isolated from each other.

Q: What is a benefit of containers in terms of deployment pipelines?
A: You can use the exact same container image in development, test, and production.

Q: What mechanisms are used to isolated containers from each other?
A: Linux namespaces and cgroups.

Q: What architecture style are containers associated with?
A: Micro-services.

Q: What is a Docker image?
A: An immutable file that is a snapshot of a container, containg the application and all its dependencies (but no guest OS).

Q: What is a Docker container?
A: A running instantition of a Docker image.

Q: What is the difference between a Docker image and a Docker container?
A: A Docker image is a non-running file, a Docker container is a running instance of a Docker image. There can be multiple containers for an image.

Q: What are Docker layers?
A: Each Docker layer contains a set of changes on top of the layer below it. All layers except the top one are immutable. 

Q: What is the underlying technology for Docker layers?
A: The Union File System (UFS).

Q: What does UFS stand for?
A: Union File System.

Q: What is a DockerFile?
A: A text document that contains instructions on how to assemble a Docker image.

Q: What is a Docker instruction?
A: A DockerFile contains a sequence of instructions (e.g. FROM, RUN, ADD, COPY), each of which adds a layer to the Docker image.

Q: What is a Docker build?
A: The Docker build process executes the instructions in a DockerFile and constructs a DockerImage.

Q: What is the Docker daemon?
A: A long running process that manages the lifecycle of Docker resources (images, containers, networks, etc.)

Q: What is the Docker engine?
A: A client-server application that hosts the Docker daemon, provides a CLI and an API.

Q: What host OS does the Docker engine run on natively?
A: On Linux.

Q: Is Docker supported on Windows and MacOS?
A: Yes, in those cases the Docker engine runs in a VM that runs Linux, and the Docker containers are nested within that VM.

Q: What is the Docker client?
A: A Command Line Interface (CLI) that you use to interact with the Docker engine (start and stop container, add and delete images, etc.)

Q: What is a Docker registry?
A: A central repository where you can store and retrieve Docker images, available in multiple tagged versions.

Q: Are Docker registries public or private?
A: Both are availble.

Q: What does ECR stand for?
A: Elastic Container Registry.

Q: What service does AWS Elastic Container Registry (ECR) povide?
A: It is the container registry in AWS ECR.

Q: What is the Docker Hub?
A: A cloud-based Docker registry run by docker.com.

Q: What does EKS stand for?
A: Elastic Kubernetes Service.

Q: What is Kubernetes?
A: An orchestration system for containers.

Q: What is the difference between ECS and EKS?
A: ECS is docker containers as a service does not come with Kubernetes but instead provides some AWS-proprietary orchestration features. EKS is AWS Kubernetes-as-a-Service integrated with other AWS services.

Q: What is AWS Fargate?
A: Amazon's proprietary container orchestration system. It is the technology behind ECS and EKS.

Q: What is the scope of ECS?
A: Region.

Q: In ECS, who manages the cluster configuration and management system?
A: Amazon does.

Q: What are the main ECS abstractions?
A: Clusters, services, task definition, task.

Q: What is an ECS cluster?
A: A pool of compute resources, available to host a logical grouping of services and tasks.

Q: What is the scope of an ECS cluster?
A: Region.

Q: What are the 2 launch type for ECS clusters
A: Fargate and EC2.

Q: What is an ECS service?
A: A logical grouping of tasks that collectively provide a service in micro services architecture. The desired number of tasks is determined by the scaling and redundancy requirements.

Q: What is an ECS task definition?
A: All the information that is needed to launch a task (which docker image, how much memory and CPU, what networking mode, etc.)

Q: What is a task?
A: A grouping of running container (defined by a task definition, and running as part of a service hosted in a cluster).

Q: How is a task started?
A: It can be started manually (for batch jons) or automatically "scheduled" by a scheduler (for long-running services).

Q: What are the two types of task schedulers in ECS?
A: The Amazon-provided service scheduler or custom (3rd party) schedulers.

Q: What the the Amazon-provided service scheduler do?
A: It ensures that the appropriate number of tasks is running to provide a long-running service. It can dynamically restart failed tasks and scale up or down.

Q: How does ECS integrated with ELB?
A: The Service Scheduler can automatically register tasks in a service with a load balancer.

Q: What happens if a task fails?
A: The service scheduler can automatically restart the task to maintain the desired count of tasks in the service

Q: What is the ECS Container Agent?
A: An agent that must be installed in the Virtual Machine (i.e. EC2 instance) that hosts the containers. The agent communicates with Amazon's cluster management system.

Q: Is the ECS Container Agent open source?
A: Yes, it is written in Go and available on Github.

Q: For which EC2 instances does Amazon officially support the Container Agent?
A: Amazon only supports running the unmodified Container Agent on Linux EC2 instances (not Windows). The agent is included in certain Amazon-provided AMIs.

Q: Can you attach a security group to an individual container or task or service?
A: No, security groups are applied to EC2 instances that host the containers.

Q: What are the ECS soft limits (and their defaults)?
A: Clusters per region (1000), instances per cluster (1000), services per cluster (500).

Q: What are the ECS hard limits?
A: One load balancer per service, 1000 desired taks per service, 10 containers per task, 10 tasks per instance.

